{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31a75a1-680b-42f7-a979-b3fc38bd326f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72bbd0-2eff-4e39-a363-90aca421ec6e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e65463-c950-47ce-a195-f61b5fc3faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a903e-0d78-4fb9-9b5d-9386721b584a",
   "metadata": {},
   "source": [
    "### 2. Define the 'ecrest' class using functions from CREST.py\n",
    "\n",
    "An instance of this object will be able to:\n",
    "- open an neuroglancer viewer for proofrieading (see \"Proofread using CREST\")\n",
    "    - add-remove segments (using graph feature for efficiency)\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "- convert from neuroglancer json (see \"Convert From Neuroglancer to eCREST\")\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "    \n",
    "Run the following code cell to define the crest_json class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e9a0f6-7de4-458d-acf7-ce841ef7f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ecrest:\n",
    "    \n",
    "    def __init__(self,settings_dict, segment_id = None, segment_list = None, filepath = None, launch_viewer=False):\n",
    "        \n",
    "        '''\n",
    "        At some point, store these initialization values (ie addresses, keys lists) as a 'params' file that can be provided to the init function instead of hard-coding\n",
    "        \n",
    "        main_base_id : base segment ID from neuroglancer list\n",
    "        \n",
    "        db_path : filepath to agglomeration database sql file locally on computer\n",
    "        \n",
    "        '''\n",
    "        #####\n",
    "        \n",
    "        '''\n",
    "        set up local stuff\n",
    "        '''\n",
    "        \n",
    "        self.import_from_settings_dict(settings_dict)\n",
    "        self.launch_viewer = launch_viewer\n",
    "        \n",
    "        # Create the connection to the database (right now just for 'Cell Reconstruction')\n",
    "        self.connect_db(self.db_paths)\n",
    "        \n",
    "        # Set up addresses\n",
    "        # addresses are stored in the agglomo SQL file        \n",
    "        required_addresses = ['agglo_address', 'base_address', 'em_address', 'cloud_storage_address']\n",
    "        [self.agglo_seg, self.base_seg, self.em, self.cloud_storage_address]  = self.get_addresses(required_addresses)\n",
    "       \n",
    "        self.cell_pos = 0\n",
    "        self.start_time = time()\n",
    "        self.link_opened = False\n",
    "\n",
    "        self.get_vx_sizes()\n",
    "        self.added_keybindings = set()\n",
    "        \n",
    "        if segment_id!=None: \n",
    "            # initialize from segment ID\n",
    "            self.load_from_segment_id(segment_id,segment_list)\n",
    "            \n",
    "        if filepath!=None:\n",
    "            # initialize from file (crest .json state)\n",
    "            self.load_from_file(filepath)\n",
    "        #####\n",
    "        \n",
    "        '''\n",
    "        Set up neuroglancer viewer\n",
    "        '''\n",
    "        \n",
    "        if launch_viewer==True:\n",
    "            self.viewer = neuroglancer.Viewer()\n",
    "            self.viewer.set_state({})\n",
    "\n",
    "            # Add keybindings:\n",
    "            pr_keybindings = {\n",
    "                'change-structure': lambda s: self.change_cell_structure(),\n",
    "                'change-anchor-seg': self.change_anchor_seg,\n",
    "                'add-or-remove-seg': self.add_or_remove_seg,\n",
    "                'mark-branch-in-colour': self.mark_branch_in_colour,\n",
    "                'change-point' : lambda s: self.change_point()\n",
    "                # 'grow-graph': lambda s: self.grow_graph(), ### WHY IS GROW GRAPH DISABLED? SEEMS USEFUL FOR LABELING CELL STRUCTURES AFTER ADDING SEGMENTS?\n",
    "                # 'increase-threshold': lambda s: self.increase_threshold(),\n",
    "                # 'decrease-threshold': lambda s: self.decrease_threshold(),\n",
    "                # 'start-branch-focus': self.branch_focus,\n",
    "                # 'accept-new-segs': lambda s: self.accept_new_segs(),        \n",
    "            }\n",
    "\n",
    "            self.add_keybindings_no_duplicates(pr_keybindings)            \n",
    "\n",
    "            with self.viewer.config_state.txn() as s:\n",
    "                s.input_event_bindings.viewer['keyc'] = 'change-structure'\n",
    "                s.input_event_bindings.data_view['dblclick0'] = 'add-or-remove-seg'\n",
    "                s.input_event_bindings.data_view['alt+mousedown0'] = 'mark-branch-in-colour'\n",
    "                s.input_event_bindings.data_view['shift+mousedown2'] = 'change-anchor-seg'\n",
    "                s.input_event_bindings.data_view['keyp'] = 'change-point'\n",
    "                # s.input_event_bindings.viewer['keyg'] = 'grow-graph'\n",
    "                # s.input_event_bindings.viewer['keyk'] = 'increase-threshold'\n",
    "                # s.input_event_bindings.viewer['keyj'] = 'decrease-threshold'\n",
    "                # s.input_event_bindings.viewer['keya'] = 'accept-new-segs'\n",
    "                # s.input_event_bindings.data_view['shift+mousedown0'] = 'start-branch-focus'\n",
    "\n",
    "            with self.viewer.config_state.txn() as s:\n",
    "                s.show_layer_panel = True ###\n",
    "                \n",
    "            # setup point annoations\n",
    "            self.set_endpoint_annotation_layers()\n",
    "            self.set_base_seg_merger_layer()\n",
    "            self.point_pos = -1\n",
    "            self.change_point()\n",
    "\n",
    "            self.set_seg_colours()\n",
    "            self.cell_structure_pos = -1\n",
    "            self.change_cell_structure()\n",
    "\n",
    "            loc = self.get_locations_from_base_segs([self.cell_data['metadata']['main_seg']['base']])[self.cell_data['metadata']['main_seg']['base']]\n",
    "            self.change_view(loc, css=0.22398, ps=389.338)\n",
    "            self.reset_seg_pr_layers()\n",
    "\n",
    "            b = self.cell_data['base_segments']\n",
    "            second_part = ', '.join([f'{x}: {len(b[x])}' for x in b.keys()])\n",
    "            print(f'updating viewer status message: Current Base Segment Counts: {second_part}')\n",
    "            with self.viewer.config_state.txn() as s:\n",
    "                s.status_messages['current_seg_count'] = f'Current Base Segment Counts: {second_part}'\n",
    "\n",
    "            self.open_ng_link()\n",
    "            # self.assert_segs_in_sync()\n",
    "\n",
    "    def open_ng_link(self):\n",
    "\n",
    "        if not self.link_opened:\n",
    "            wb_open(str(self.viewer))\n",
    "            self.link_opened = True\n",
    "\n",
    "    def import_from_settings_dict(self,settings_dict):\n",
    "        # self.settings_dict = settings_dict\n",
    "        self.db_paths = Path(settings_dict['db_path'])\n",
    "        self.point_types = settings_dict['annotation_points']\n",
    "        self.cell_structures = settings_dict['cell_structures']\n",
    "        self.max_num_base_added = settings_dict['max_num_base_added']\n",
    "        self.save_dir = Path(settings_dict['save_dir'])\n",
    "\n",
    "    def add_keybindings_no_duplicates(self, dict):\n",
    "\n",
    "        for k in dict:\n",
    "\n",
    "            if k not in self.added_keybindings:\n",
    "\n",
    "                self.viewer.actions.add(k, dict[k])\n",
    "                self.added_keybindings.add(k)           \n",
    "                \n",
    "    def load_from_segment_id(self,main_base_id,segment_list = None):\n",
    "        '''\n",
    "        initializes the graph after loading all the base segments in the agglomeration segment with the main_base_id\n",
    "        '''\n",
    "        agglo_seg_id = self.get_agglo_seg_of_base_seg(str(main_base_id))\n",
    "        \n",
    "        self.cell_data = {\n",
    "            'graph_edges': [],\n",
    "            'graph_nodes': [],\n",
    "            'base_locations': {},\n",
    "            'added_graph_edges': [], \n",
    "            'added_graph_edges_pre_proofreading': [],\n",
    "            'end_points': {key: [] for key in self.point_types},\n",
    "            'base_seg_merge_points': [],\n",
    "            'removed_base_segs': set(),\n",
    "            'anchor_seg' : str(main_base_id),\n",
    "            'metadata': {   \n",
    "                'main_seg' : {'agglo' : {self.agglo_seg : agglo_seg_id}, 'base' : str(main_base_id)},\n",
    "                'data_sources': {\n",
    "                    'em' : self.em, \n",
    "                    'base': self.base_seg, \n",
    "                    'agglo': self.agglo_seg,\n",
    "                    },\n",
    "                'timing' : [],\n",
    "                'completion' : [],\n",
    "                'cell-type' : {'manual': [], 'auto': []}\n",
    "                },\n",
    "            'base_segments' : {dtype: set() for dtype in self.cell_structures}\n",
    "        }\n",
    "        \n",
    "        if segment_list!=None: # Then a list of base_segments has been provided and should override getting all base segments from agglomo\n",
    "                                # For example, this would be the case if converting from a neuroglancer-direct json state reconstruction\n",
    "            self.cell_data['base_segments']['unknown']=set(segment_list)\n",
    "\n",
    "            '''\n",
    "            TODO\n",
    "\n",
    "            CHANGE SEGMENT LIST TO BE A DICTIONARY OF {CELL STRUCTURE : LIST} \n",
    "            so can import segments for specific parts of cells\n",
    "\n",
    "            '''\n",
    "\n",
    "        if segment_list==None: # Then a list of base segments was not provided, and need to get all base segments associated with main_base_seg in its agglo segment\n",
    "            segment_list = self.get_base_segs_of_agglo_seg(agglo_seg_id)\n",
    "            self.cell_data['base_segments']['unknown']=set(segment_list)\n",
    "        \n",
    "        # Initialize graph of base_segments (can be across different cell structures)\n",
    "        self.create_pr_graph()\n",
    "        \n",
    "        # Initialize the CREST json file\n",
    "        # self.save_cell_graph()\n",
    "        \n",
    "        print(f'Created a CREST instance for NEW Reconstruction of {main_base_id}. No file saved yet -- save manually.')                                            \n",
    "        \n",
    "    def load_from_file(self,filepath):\n",
    "    \n",
    "        with open(filepath, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "            cell_data=myfile.read()\n",
    "            self.cell_data = json.loads(cell_data)\n",
    "        \n",
    "        for dtype in self.cell_data['base_segments']:\n",
    "            self.cell_data['base_segments'][dtype] = set(self.cell_data['base_segments'][dtype])\n",
    "    \n",
    "        self.cell_data['removed_base_segs'] = set(self.cell_data['removed_base_segs'])\n",
    "        \n",
    "        main_base_id = self.cell_data['metadata']['main_seg']['base']\n",
    "        # print(f'Loading a CREST instance for LOADED Reconstruction of {main_base_id}')\n",
    "        \n",
    "        self.load_graph_from_celldata()\n",
    "        self.resolving_seg_overlap()\n",
    "        # self.adjust_annotations_structures()\n",
    "        \n",
    "\n",
    "    def get_addresses(self, required_addresses):\n",
    "        \n",
    "        '''\n",
    "        req_addresses = ['agglo_address', 'base_address', 'em_address', 'cloud_storage_address']\n",
    "        '''\n",
    "        a = ', '.join(required_addresses)\n",
    "\n",
    "        self.db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')\n",
    "\n",
    "        results = self.db_cursors.fetchall()[0]\n",
    "\n",
    "        return results\n",
    "        \n",
    "    def connect_db(self, db_path):\n",
    "\n",
    "        self.db_cursors = sqlite3_connect(db_path, check_same_thread=False).cursor()\n",
    "        \n",
    "    def update_msg(self, msg, layer='status'):\n",
    "        \n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.status_messages[layer] = msg\n",
    "\n",
    "    def get_vx_sizes(self):\n",
    "               \n",
    "        self.db_cursors.execute('SELECT * FROM voxel_sizes_table')\n",
    "\n",
    "        self.vx_sizes = {}\n",
    "\n",
    "        for dtype, x, y, z, x_size, y_size, z_size in self.db_cursors.fetchall():\n",
    "\n",
    "            self.vx_sizes[dtype] = [x, y, z]\n",
    "\n",
    "            if dtype == 'em':\n",
    "                self.starting_location = [int(x_size/2), int(y_size/2), int(z_size/2),]\n",
    "\n",
    "    def set_base_seg_merger_layer(self):\n",
    "\n",
    "        self.point_types.append('Base Segment Merger')\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            s.layers['Base Segment Merger'] = neuroglancer.AnnotationLayer()\n",
    "            s.layers['Base Segment Merger'].filterBySegmentation = [\"segments\"]\n",
    "            s.layers['Base Segment Merger'].linkedSegmentationLayer = {\"segments\": 'base_segs'}\n",
    "            s.layers['Base Segment Merger'].annotationColor = '#ffa500'\n",
    "            s.layers['Base Segment Merger'].tool = \"annotatePoint\"\n",
    "\n",
    "            for pos, point in enumerate(self.cell_data['base_seg_merge_points']):\n",
    "\n",
    "                point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                pa = neuroglancer.PointAnnotation(id=f'bm_{pos}', point = point_array, segments=[[point[3]]])\n",
    "                s.layers['Base Segment Merger'].annotations.append(pa)                \n",
    "\n",
    "    def change_point(self):\n",
    "\n",
    "        if self.point_pos == len(self.point_types)-1:\n",
    "            self.point_pos = 0\n",
    "        else:\n",
    "            self.point_pos += 1\n",
    "\n",
    "        selected_layer = self.point_types[self.point_pos]\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            s.selectedLayer.layer = selected_layer\n",
    "            s.selected_layer.visible = True\n",
    "            s.layers[selected_layer].tab = 'Annotations'\n",
    "        \n",
    "        self.update_msg(f'Current Point Annotation Type (P): {selected_layer}', layer='current point type')\n",
    "\n",
    "    def change_cell_structure(self):\n",
    "     \n",
    "        if self.cell_structure_pos == len(self.cell_structures)-1:\n",
    "            self.cell_structure_pos = 0\n",
    "\n",
    "        else:\n",
    "            self.cell_structure_pos += 1\n",
    "            \n",
    "        self.update_msg(f'Current Cell Structure (C): {self.cell_structures[self.cell_structure_pos]}', layer='Current Cell Structure')\n",
    "            \n",
    "    def adjust_annotations_structures(self):\n",
    "        '''\n",
    "        when loading a cell from a file, add necessary annotations and structures if do not exist\n",
    "        '''     \n",
    "        \n",
    "        for p in self.point_types:\n",
    "            if p not in self.cell_data['end_points']:\n",
    "                self.cell_data['end_points'][p] = [] # create the entry for that annotation point\n",
    "        self.point_types = list(set(self.point_types + list(self.cell_data['end_points'].keys())))\n",
    "        self.point_types = [x for x in self.point_types if not ('base' in x.lower() and 'merge' in x.lower())]\n",
    "        \n",
    "        self.set_endpoint_annotation_layers() # reset annotations layers to include any adjustments\n",
    "\n",
    "        existing_struc = [x for x in self.cell_data['base_segments'].keys() if x!= 'unknown']\n",
    "        for dtype in self.cell_structures:\n",
    "            if dtype not in self.cell_data['base_segments'].keys():\n",
    "                self.cell_data['base_segments'][dtype] = set() # create the entry for that annotation point\n",
    "        self.cell_structures = list(set(self.cell_structures) | set(existing_struc))\n",
    "        \n",
    "        self.set_seg_colours() # reset colors for segments\n",
    "        \n",
    "    def set_endpoint_annotation_layers(self): \n",
    "\n",
    "        self.point_types = list(set(self.point_types + list(self.cell_data['end_points'].keys())))\n",
    "        self.point_types = [x for x in self.point_types if not ('base' in x.lower() and 'merge' in x.lower())]\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for point_type in self.point_types:\n",
    "\n",
    "                s.layers[point_type] = neuroglancer.AnnotationLayer()\n",
    "                \n",
    "                if point_type == 'post-synaptic':\n",
    "                    s.layers[point_type].annotationColor = '#ff00ff'\n",
    "                    s.layers[point_type].linkedSegmentationLayer = {\"segments\": 'base_segs'} # set it up linked to base_segs\n",
    "                elif point_type == 'pre-synaptic':\n",
    "                    s.layers[point_type].annotationColor = '#00EEEE'\n",
    "                    s.layers[point_type].linkedSegmentationLayer = {\"segments\": 'base_segs'} # set it up linked to base_segs\n",
    "                elif (point_type == 'natural end') | (point_type == 'exit volume'):\n",
    "                    s.layers[point_type].annotationColor = '#FFFF00'\n",
    "                elif point_type == 'uncertain':\n",
    "                    s.layers[point_type].annotationColor = '#EE0000'\n",
    "                else:\n",
    "                    s.layers[point_type].annotationColor = '#ffffff'\n",
    "\n",
    "                s.layers[point_type].tool = \"annotatePoint\"\n",
    "                s.layers[point_type].tab = 'Annotations'\n",
    "\n",
    "                # If data already exists for this point type:\n",
    "\n",
    "        self.load_annotation_layer_points()\n",
    "        \n",
    "    def load_annotation_layer_points(self):\n",
    "        \n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            for point_type in self.point_types:\n",
    "\n",
    "                # If data already exists for this point type:\n",
    "                if point_type in self.cell_data['end_points'].keys():\n",
    "\n",
    "                    for pos, point in enumerate(self.cell_data['end_points'][point_type]):\n",
    "\n",
    "                        if len(point)==3: # then there is no segment ID associated with the annotation point\n",
    "                        \n",
    "                            point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                            point_id = f'{point_type}_{pos}'\n",
    "                            pa = neuroglancer.PointAnnotation(id=point_id, point = point_array)\n",
    "                            s.layers[point_type].annotations.append(pa)\n",
    "\n",
    "                        if len(point)==4: # then include the segment ID with the annotation point\n",
    "                            point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                            point_id = f'{point_type}_{pos}'\n",
    "                            segment_id = point[3]\n",
    "                            pa = neuroglancer.PointAnnotation(id=point_id, point = point_array, segments = [[segment_id]])\n",
    "                            s.layers[point_type].annotations.append(pa)                     \n",
    "\n",
    "    def save_point_types_successfully(self):\n",
    "\n",
    "        for t in self.point_types:\n",
    "\n",
    "            this_type_points = []\n",
    "     \n",
    "            for x in self.viewer.state.layers[t].annotations:\n",
    "                if t == 'Base Segment Merger' and x.segments == None:\n",
    "                    c = [int(y) for y in x.point]\n",
    "                    self.update_mtab(f'Error, no segment for point {c}, for point layer {t}, correct and re-save', 'Cell Reconstruction')\n",
    "                    return False\n",
    "\n",
    "                else:\n",
    "                    co_ords = [float(x) for x in list(x.point)]\n",
    "                    co_ords_and_id = [co_ords[x]*self.vx_sizes['em'][x] for x in range(3)]\n",
    "\n",
    "                    if x.segments != None:\n",
    "                        if len(x.segments[0]) > 0:\n",
    "                            co_ords_and_id.append(str(x.segments[0][0]))\n",
    "\n",
    "                    this_type_points.append(co_ords_and_id)\n",
    "\n",
    "            if t == 'Base Segment Merger':\n",
    "                self.cell_data['base_seg_merge_points'] = this_type_points\n",
    "            else:\n",
    "                self.cell_data['end_points'][t] = this_type_points\n",
    "\n",
    "        return True                            \n",
    "\n",
    "    def set_seg_colours(self):\n",
    "        chosen_col = '#D2B48C'\n",
    "        self.chosen_seg_colours = {'unknown': '#D2B48C'} # tan\n",
    "\n",
    "        # acceptable_colours = set(['#FFFF00', '#800080', '#008000', '#FF00FF', '#00FF00', '#FF69B4', '#FF8C00'])\n",
    "        # used_colours = set()\n",
    "\n",
    "        for x in self.cell_structures:\n",
    "\n",
    "            # available_colours = acceptable_colours - used_colours\n",
    "\n",
    "            # if len(available_colours) == 0:\n",
    "            #     available_colours = acceptable_colours\n",
    "            \n",
    "            if x=='multiple':\n",
    "                chosen_col = '#9C661F' # white\n",
    "\n",
    "            if x=='axon':\n",
    "                chosen_col = '#008000' # green\n",
    "\n",
    "            if x=='dendrite':\n",
    "                chosen_col = '#FFFF00' # yellow\n",
    "\n",
    "            if x=='basal dendrite': # orange-red\n",
    "                chosen_col = '#CD4B00'\n",
    "\n",
    "            if x=='apical dendrite': # orange\n",
    "                chosen_col = '#FF8000'\n",
    "    \n",
    "            if x not in self.cell_data['base_segments'].keys():\n",
    "                chosen_col = '#708090' # if not one of the explicitly chosen structures, make it slate gray\n",
    "\n",
    "            # used_colours.add(chosen_col)\n",
    "            self.chosen_seg_colours[x] = chosen_col\n",
    "    \n",
    "    def import_base_segments(self,base_segments):\n",
    "        \n",
    "        '''\n",
    "        base_segments is the list of segments from neuroglancer json (which is why get put in \"unknown\")\n",
    "        '''\n",
    "        # Turn lists back to sets:\n",
    "        self.cell_data['base_segments']['unknown'] = set([str(x) for x in base_segments])\n",
    "                \n",
    "    \n",
    "    def create_pr_graph(self):\n",
    "\n",
    "        seg_id = self.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "        print(f'Creating base segment graph for cell {seg_id}', 'Cell Reconstruction')\n",
    "\n",
    "        all_base_segs = [str(a) for b in self.cell_data['base_segments'].values() for a in b]\n",
    "        \n",
    "        self.update_base_locations(all_base_segs)\n",
    "\n",
    "              \n",
    "        ####\n",
    "        # Correct base segment locations that got left out \n",
    "        '''td:\n",
    "        figure out why they are like this.\n",
    "        for example, for one the segment id returned '0' even though there was a location returned\n",
    "        '''\n",
    "        no_loc_base_segs = [str(x) for x in all_base_segs if x not in self.cell_data['base_locations']]\n",
    "        if no_loc_base_segs != []:\n",
    "            for s in no_loc_base_segs:\n",
    "                try:\n",
    "                    results_dict = self.get_locations_from_base_segs(s)\n",
    "                    k = list(results_dict.keys())[0] # get key for this segment ID in queried segment location\n",
    "                    self.cell_data['base_locations'][s] = self.get_corrected_xyz(results_dict[k], 'seg') # manually log its location with given segment ID\n",
    "                except: \n",
    "                    print(f'{s} actually no base segment location in SQL... will attach without location later')\n",
    "                    continue\n",
    "            self.cell_data['no_loc_base_segs'] = no_loc_base_segs # did not add this until after some conversions already done\n",
    "        ####\n",
    "        \n",
    "        \n",
    "        print(f'all base locations for {len(all_base_segs)} obtained from SQL database')\n",
    "        \n",
    "        possible_edges = []\n",
    "        agglo_segs_done = set()\n",
    "        base_segs_done = set()\n",
    "\n",
    "        for base_seg in all_base_segs:\n",
    "\n",
    "            if base_seg in base_segs_done: continue # if the base segment has been included, go to next\n",
    "            # if the base segment has not been included yet,\n",
    "\n",
    "            agglo_seg = self.get_agglo_seg_of_base_seg(base_seg) # get its agglomeration segment\n",
    "            children_base_segs = self.get_base_segs_of_agglo_seg(agglo_seg) # and all of the other base segments also in that agglo seg\n",
    "            base_segs_done.update(children_base_segs) # mark all of these base segments as included\n",
    "\n",
    "            if not agglo_seg in agglo_segs_done: # connect the agglomeration segment for those bases if it has not already been done\n",
    "\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg)\n",
    "\n",
    "                agglo_segs_done.add(agglo_seg)\n",
    "                possible_edges.extend(edges)\n",
    "\n",
    "        all_bs_set = set(all_base_segs)\n",
    "        possible_edges = [x for x in possible_edges if x[0] in all_bs_set] # only include edges between connect base segments in the reconstruction\n",
    "            # note that this is what probably creates so many disconnected clusters... if a base segment is missing from the agglo, \n",
    "            #then the edges from that segment will not be included and will need to be connected manually\n",
    "        chosen_edges = [x for x in possible_edges if x[1] in all_bs_set]\n",
    "\n",
    "        self.pr_graph = ig_Graph(directed=False)\n",
    "        self.pr_graph.add_vertices(all_base_segs)\n",
    "        self.pr_graph.add_edges(chosen_edges)\n",
    "\n",
    "        print('graph created among all_base_segs')\n",
    "        \n",
    "\n",
    "        self.add_cc_bridging_edges_pairwise()\n",
    "        print('weak clusters connected')\n",
    "        \n",
    "        self.attach_noloc_segs()\n",
    "        print('segments without a location connected')\n",
    "        \n",
    "        self.cell_data['graph_nodes'] = [x['name'] for x in self.pr_graph.vs]\n",
    "        self.cell_data['graph_edges'] = [(self.pr_graph.vs[x.source]['name'], self.pr_graph.vs[x.target]['name']) for x in self.pr_graph.es]\n",
    "\n",
    "\n",
    "        '''\n",
    "        # removed assertion of pr_graph.clusters==1 because importing from a neuroglancer json might \"break\" this and it is ok...\n",
    "        \n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1\n",
    "        '''\n",
    "        \n",
    "        n_clusters = len(self.pr_graph.clusters(mode='weak'))\n",
    "        \n",
    "        print(f'{n_clusters} clusters in graph (note should/would be only 1 if loaded base ID from agglomo fresh)')\n",
    "        \n",
    "        # self.assert_segs_in_sync()\n",
    "        \n",
    "        # print(f'successful assertion that graph segments and segments listed in base_segments match')\n",
    "        \n",
    "    def load_graph_from_celldata(self):\n",
    "\n",
    "        self.pr_graph = ig_Graph()\n",
    "        self.pr_graph.add_vertices(self.cell_data['graph_nodes'])\n",
    "        self.pr_graph.add_edges(self.cell_data['graph_edges'])\n",
    "        \n",
    "    def save_cell_graph(self, directory_path = None, file_name=None, save_to_cloud=False):\n",
    "        \n",
    "        timestamp = str(datetime.now())[:-7].replace(':','.')\n",
    "        main_base_id = self.cell_data['metadata']['main_seg']['base']\n",
    "                \n",
    "        cell_data = deepcopy(self.cell_data)\n",
    "\n",
    "        # Convert sets to lists for saving in json file:\n",
    "        for dtype in cell_data['base_segments'].keys():\n",
    "            cell_data['base_segments'][dtype] = list(cell_data['base_segments'][dtype])\n",
    "        \n",
    "        cell_data['removed_base_segs'] = list(cell_data['removed_base_segs'])\n",
    "        \n",
    "        cell_data['graph_nodes'] = [x['name'] for x in self.pr_graph.vs]\n",
    "        cell_data['graph_edges'] = [(self.pr_graph.vs[x.source]['name'], self.pr_graph.vs[x.target]['name']) for x in self.pr_graph.es]\n",
    "\n",
    "        completion_list = list(set(cell_data['metadata']['completion']))\n",
    "        completion_list.sort()\n",
    "        completion_string = ','.join(completion_list).replace('_', ' ')\n",
    "            \n",
    "        cell_data['metadata']['data_sources']['agglo'] = self.agglo_seg\n",
    "        \n",
    "        if directory_path==None:\n",
    "            directory_path = self.save_dir\n",
    "            \n",
    "        if file_name == None:\n",
    "            file_name = f'cell_graph_{main_base_id}_{completion_string}_{timestamp}.json'\n",
    "            \n",
    "#         with open(f'{self.save_dir}/{file_name}', 'w') as fp:\n",
    "#             json_dump(cell_data, fp)\n",
    "        with open(directory_path / file_name, 'w') as fp:\n",
    "            json.dump(cell_data, fp, indent=4)\n",
    "\n",
    "        print(f'Saved cell {main_base_id} reconstruction locally at {timestamp}')\n",
    "\n",
    "    def update_base_locations(self, seg_list):\n",
    "\n",
    "        seg_list = [x for x in seg_list if x not in self.cell_data['base_locations'].keys()]\n",
    "\n",
    "        result_dict = self.get_locations_from_base_segs(seg_list)\n",
    "\n",
    "        for r in result_dict:\n",
    "            self.cell_data['base_locations'][r] = self.get_corrected_xyz(result_dict[r], 'seg')\n",
    "\n",
    "    def get_locations_from_base_segs(self, base_segs, batch_size = 1000):\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        if len(base_segs) > 0:\n",
    "        \n",
    "            num_batches = int(len(base_segs)/batch_size)\n",
    "            \n",
    "            for batch in range(num_batches+1):\n",
    "\n",
    "                q = ','.join([str(x) for x in base_segs[batch*batch_size:(batch+1)*batch_size]])\n",
    "                \n",
    "                query = f\"\"\"SELECT seg_id, x, y, z FROM base_location WHERE seg_id IN ({q})\"\"\"\n",
    "\n",
    "                self.db_cursors.execute(query)\n",
    "\n",
    "                this_batch = {str(x[0]): (int(x[1]), int(x[2]), int(x[3])) for x in self.db_cursors.fetchall()}\n",
    "\n",
    "                results.update(this_batch)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_corrected_xyz(self, xyz, adj_key, rel_to_em=False):\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for pos, coord in enumerate(xyz):\n",
    "            result.append(coord*self.vx_sizes[adj_key][pos])\n",
    "            \n",
    "        if rel_to_em==True:\n",
    "            result = [int(result[x]/self.vx_sizes['em'][x]) for x in range(3)]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_agglo_seg_of_base_seg(self, base_seg):\n",
    "\n",
    "        base_seg = str(base_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT agglo_id FROM agglo_base_resolved WHERE base_id = {base_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        agglo_segs = [str(x[0]) for x in self.db_cursors.fetchall()]\n",
    "\n",
    "        assert len(agglo_segs) <= 1\n",
    "\n",
    "        if agglo_segs == []:\n",
    "            return base_seg\n",
    "        else:\n",
    "            return agglo_segs[0]\n",
    "\n",
    "    def get_base_segs_of_agglo_seg(self, agglo_seg):\n",
    "\n",
    "        agglo_seg = str(agglo_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT base_id FROM agglo_base_resolved WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        base_segs = [str(x[0]) for x in self.db_cursors.fetchall()]\n",
    "        base_segs.append(agglo_seg)\n",
    "\n",
    "        return base_segs\n",
    "\n",
    "    def get_edges_from_agglo_seg(self, agglo_seg):\n",
    "\n",
    "        agglo_seg = str(agglo_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT label_a, label_b FROM agglo_to_edges WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        edges = [(str(x[0]), str(x[1])) for x in self.db_cursors.fetchall()]\n",
    "\n",
    "        return edges\n",
    "    \n",
    "    def add_cc_bridging_edges_pairwise(self):\n",
    "        \n",
    "        '''\n",
    "        con_comms = \"connected components\" abbreviation\n",
    "        '''\n",
    "\n",
    "        con_comms = list(self.pr_graph.clusters(mode='weak'))\n",
    "        print(f'{len(con_comms)} clusters of connected components. Connecting these clusters with nearest base segments.')\n",
    "        while len(con_comms) > 1:\n",
    "\n",
    "            candidate_edges = []\n",
    "\n",
    "            for cc1, cc2 in combinations(con_comms, 2): # gets all possible pairwise combinations between segments\n",
    "                \n",
    "                # get the name of each base segment\n",
    "                cc1_base_segs = [self.pr_graph.vs[x]['name'] for x in cc1]\n",
    "                cc2_base_segs = [self.pr_graph.vs[x]['name'] for x in cc2]\n",
    "\n",
    "                cc1_list = [x for x in cc1_base_segs if x in self.cell_data['base_locations']]\n",
    "                cc2_list = [x for x in cc2_base_segs if x in self.cell_data['base_locations']]\n",
    "\n",
    "                if cc1_list == [] or cc2_list == []:\n",
    "                    continue\n",
    "\n",
    "                sel_cc1, sel_cc2, dist = self.get_closest_dist_between_ccs(cc1_list, cc2_list)\n",
    "                candidate_edges.append([sel_cc1, sel_cc2, dist])\n",
    "\n",
    "            if candidate_edges == []: \n",
    "                return\n",
    "\n",
    "            origin, target, dist = min(candidate_edges, key = lambda x: x[2])\n",
    "\n",
    "            self.pr_graph.add_edges([(origin, target)])\n",
    "            self.cell_data['added_graph_edges_pre_proofreading'].append([origin, target, dist])\n",
    "#             self.update_mtab(f'Added an edge between segments {origin} and {target}, {dist} nm apart', 'Cell Reconstruction')\n",
    "\n",
    "            con_comms = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "    def get_closest_dist_between_ccs(self, cc1_node_list, cc2_node_list):\n",
    "\n",
    "        cc1_node_locs = [self.cell_data['base_locations'][x] for x in cc1_node_list]\n",
    "        cc2_node_locs = [self.cell_data['base_locations'][x] for x in cc2_node_list]\n",
    "\n",
    "        f = cdist(cc1_node_locs, cc2_node_locs, 'euclidean')\n",
    "\n",
    "        min_indices = unravel_index(argmin(f, axis=None), f.shape)\n",
    "\n",
    "        sel_cc1 = cc1_node_list[min_indices[0]]\n",
    "        sel_cc2 = cc2_node_list[min_indices[1]]\n",
    "        dist = int(f[min_indices])  \n",
    "\n",
    "        return sel_cc1, sel_cc2, dist\n",
    "            \n",
    "    def attach_noloc_segs(self):\n",
    "        ''' NOTE that this does not run (it returns) if self.pr_graph.clusters(mode='weak') == 1\n",
    "        This is a case that is asserted in oringinal CREST.py in '''\n",
    "        \n",
    "        # For isolated segments without locations, attach to largest connected component:\n",
    "        remaining_cc = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "        if len(remaining_cc) == 1: return\n",
    "\n",
    "        if len(remaining_cc) > 1:\n",
    "            no_loc_base_segs = set([x['name'] for x in self.pr_graph.vs if x['name'] not in self.cell_data['base_locations']])\n",
    "            largest_cc = max(remaining_cc, key = lambda x: len(x))\n",
    "\n",
    "            '''\n",
    "            #### Raises TypeError: unsupported operand type(s) for &: 'list' and 'set'\n",
    "            for cc in remaining_cc:\n",
    "                no_loc_this_cc = cc & no_loc_base_segs\n",
    "                if cc != largest_cc and no_loc_this_cc != set():\n",
    "                    rand_seg1 = random_choice(list(no_loc_this_cc))\n",
    "                    rand_seg2 = random_choice(list(largest_cc))\n",
    "                    self.pr_graph.add_edges([(rand_seg1, rand_seg2)])\n",
    "                    self.cell_data['added_graph_edges_pre_proofreading'].append([rand_seg1, rand_seg2, 'unknown'])\n",
    "#                     print(f'Added an edge between segments {rand_seg1} and {rand_seg2}', 'Cell Reconstruction')\n",
    "            '''\n",
    "            # I think the following block replaces the commented out above with the correct intension?\n",
    "            nodes_names = [x['name'] for x in self.pr_graph.vs]\n",
    "            for cc in remaining_cc:\n",
    "                # no_loc_this_cc = cc & no_loc_base_segs # raises TypeError: unsupported operand type(s) for &: 'list' and 'set'\n",
    "                no_loc_this_cc = set([nodes_names[i] for i in remaining_cc[1]])& set(no_loc_base_segs) # I think this is what Alex was going for?\n",
    "                if cc != largest_cc and no_loc_this_cc != set():\n",
    "                    rand_seg1 = random_choice(list(no_loc_this_cc))\n",
    "                    rand_seg2 = random_choice(list(largest_cc))\n",
    "                    self.pr_graph.add_edges([(rand_seg1, rand_seg2)])\n",
    "                    self.cell_data['added_graph_edges_pre_proofreading'].append([rand_seg1, rand_seg2, 'unknown'])\n",
    "            #                     print(f'Added an edge between segments {rand_seg1} and {rand_seg2}', 'Cell Reconstruction')\n",
    "\n",
    "\n",
    "    def assert_segs_in_sync(self, return_segs=False):\n",
    "        \n",
    "        displayed_segs = set([str(x) for x in self.viewer.state.layers['base_segs'].segments])\n",
    "        graph_segs = set([x['name'] for x in self.pr_graph.vs])\n",
    "        listed_segs = set([a for b in [self.cell_data['base_segments'][cs] for cs in self.cell_data['base_segments'].keys()] for a in b])\n",
    "\n",
    "        assert listed_segs == graph_segs\n",
    "\n",
    "        if not displayed_segs == graph_segs:\n",
    "            self.update_displayed_segs()\n",
    "        \n",
    "\n",
    "        if return_segs:\n",
    "            return displayed_segs\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "    def get_ds_segs_of_certain_col(self, base_seg, colour):\n",
    "\n",
    "        ds = self.get_downstream_base_segs(base_seg)[0]\n",
    "\n",
    "        # If any of the downstream segments doesn't have a colour, set it to tan:\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in ds:\n",
    "                if int(bs) not in s.layers['base_segs'].segment_colors.keys():\n",
    "                    s.layers['base_segs'].segment_colors[int(bs)] = '#D2B48C'\n",
    "\n",
    "            ds = set([x for x in ds if s.layers['base_segs'].segment_colors[int(x)] == colour])\n",
    "        \n",
    "        return ds\n",
    "\n",
    "    def update_displayed_segs(self):\n",
    "\n",
    "        displayed_segs = set([str(x) for x in self.viewer.state.layers['base_segs'].segments])\n",
    "        listed_segs = set([x for y in self.cell_data['base_segments'].values() for x in y])\n",
    "        graph_segs = set([x['name'] for x in self.pr_graph.vs])\n",
    "\n",
    "        assert listed_segs == graph_segs\n",
    "\n",
    "        # Identify segments that failed to be removed from the viewer:\n",
    "        segs_to_remove = displayed_segs - listed_segs\n",
    "\n",
    "        # Identify segments that failed to be added to the viewer:\n",
    "        missing_segs = listed_segs - displayed_segs\n",
    "        # missing_focus_segs = self.focus_seg_set - set([str(x) for x in self.viewer.state.layers['focus_segs'].segments])\n",
    "\n",
    "        if not missing_segs == set():\n",
    "            # Correct the viewer:\n",
    "            with self.viewer.txn(overwrite=True) as s:\n",
    "                \n",
    "                layer = 'base_segs'\n",
    "            \n",
    "                for bs in missing_segs:\n",
    "                    s.layers[layer].segment_colors[int(bs)] = '#D2B48C'\n",
    "                    s.layers[layer].segments.add(int(bs)) \n",
    "\n",
    "                for bs in segs_to_remove:\n",
    "                    if int(bs) in s.layers[layer].segments:\n",
    "                        s.layers[layer].segments.remove(int(bs))\n",
    "                            \n",
    "    def add_or_remove_seg(self, action_state):  \n",
    "\n",
    "        rel_layer = 'base_segs'\n",
    "        \n",
    "        base_seg = self.check_selected_segment(rel_layer, action_state, banned_segs = [self.cell_data['anchor_seg']])\n",
    "\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        # Otherwise, add or remove to main layer:\n",
    "        \n",
    "        displayed_segs = self.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        if base_seg in displayed_segs:\n",
    "\n",
    "            self.remove_downstream_base_segs(base_seg)\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "            # Adding a segment:\n",
    "\n",
    "            agglo_seg = self.check_selected_segment('agglo', action_state)\n",
    "  \n",
    "            if agglo_seg == 'None': return\n",
    "\n",
    "            constituent_base_ids = self.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {self.max_num_base_added}')\n",
    "\n",
    "            if len(constituent_base_ids) > self.max_num_base_added:\n",
    "                base_ids = [base_seg]\n",
    "                #self.large_agglo_segs.add(agglo_seg)\n",
    "            else:\n",
    "                base_ids = constituent_base_ids\n",
    "\n",
    "            current_segs = self.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "            num_base_segs_this_agglo_seg = len(base_ids)\n",
    "            base_ids = [x for x in base_ids if x not in current_segs]\n",
    "            num_base_segs_not_already_included = len(base_ids)\n",
    "\n",
    "            if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "                base_ids = [x for x in base_ids if x not in self.cell_data['removed_base_segs']]\n",
    "\n",
    "                if not base_seg in base_ids:\n",
    "                    base_ids.append(base_seg)\n",
    "    \n",
    "            self.update_base_locations(base_ids)\n",
    "            self.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "            if len(base_ids) > 1:\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg)\n",
    "                edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "                self.pr_graph.add_edges(edges)\n",
    "\n",
    "            join_msg = self.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "\n",
    "            # Update lists of base segments and displayed segs:\n",
    "            self.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "\n",
    "            with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "                for bs in base_ids:\n",
    "                    s.layers['base_segs'].segment_colors[int(bs)] = '#D2B48C'\n",
    "                    s.layers['base_segs'].segments.add(int(bs))\n",
    "\n",
    "\n",
    "            self.update_displayed_segs() \n",
    "            self.assert_segs_in_sync()\n",
    "\n",
    "            print(f'Added {len(base_ids)} base segments from agglomerated segment {agglo_seg}{join_msg}')\n",
    "\n",
    "    def remove_downstream_base_segs(self, base_seg):\n",
    "\n",
    "        segs_to_remove, n_con_com = self.get_downstream_base_segs(base_seg)\n",
    "\n",
    "        self.assert_segs_in_sync()\n",
    "\n",
    "        # Remove from lists and segmentation layer:\n",
    "        for cs in self.cell_data['base_segments'].keys():\n",
    "            self.cell_data['base_segments'][cs] -= set(segs_to_remove)\n",
    "\n",
    "        self.pr_graph.delete_vertices(segs_to_remove)\n",
    "        # self.focus_seg_set -= set(segs_to_remove)\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in segs_to_remove:\n",
    "\n",
    "                if int(bs) in s.layers['base_segs'].segments:\n",
    "                    s.layers['base_segs'].segments.remove(int(bs))\n",
    "\n",
    "        self.assert_segs_in_sync()\n",
    "            \n",
    "        self.cell_data['removed_base_segs'].update(set(segs_to_remove))\n",
    "        print(f'{len(segs_to_remove)} base segments removed from {n_con_com} connected components')\n",
    "        self.cell_data['added_graph_edges'] = [x for x in self.cell_data['added_graph_edges'] if (x[0] not in segs_to_remove) and (x[1] not in segs_to_remove)]\n",
    "\n",
    "    def get_downstream_base_segs(self, base_seg):\n",
    "\n",
    "        edge_backup = [(self.pr_graph.vs[p_ix]['name'], base_seg) for p_ix in self.pr_graph.neighbors(base_seg)]\n",
    "\n",
    "        self.pr_graph.delete_vertices([base_seg])\n",
    "\n",
    "        current_cc = list(self.pr_graph.clusters(mode='weak'))\n",
    "        current_cc_seg_ids = [[self.pr_graph.vs[i]['name'] for i in c] for c in current_cc]\n",
    "        ccs_to_remove = [cc for cc in current_cc_seg_ids if self.cell_data['anchor_seg'] not in cc]\n",
    "        segs_to_remove = [str(x) for y in ccs_to_remove for x in y if str(x) != '0']\n",
    "        segs_to_remove.append(base_seg)\n",
    "\n",
    "        self.pr_graph.add_vertices([base_seg])\n",
    "        self.pr_graph.add_edges(edge_backup)\n",
    "\n",
    "        return segs_to_remove, len(current_cc)\n",
    "    \n",
    "    def add_closest_edge_to_graph(self, new_segs, seg_to_link):\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 2\n",
    "\n",
    "        # Some segments do not have locations recorded:\n",
    "        current_cell_node_list = [x['name'] for x in self.pr_graph.vs if x['name'] not in new_segs]\n",
    "        current_cell_node_list = [x for x in current_cell_node_list if x in self.cell_data['base_locations']]\n",
    "        \n",
    "        # Then determine new segments that are acceptable as partners\n",
    "        if seg_to_link in self.cell_data['base_locations'].keys():\n",
    "            new_segs = [seg_to_link]\n",
    "        else:\n",
    "            new_segs = [x for x in new_segs if x in self.cell_data['base_locations']]\n",
    "\n",
    "        sel_curr, sel_new, dist = self.get_closest_dist_between_ccs(current_cell_node_list, new_segs)\n",
    "        \n",
    "        self.pr_graph.add_edges([(sel_curr, sel_new)])\n",
    "        self.cell_data['added_graph_edges'].append([sel_curr, sel_new, dist])\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1     \n",
    "\n",
    "        return f', linked base segments {sel_curr} and {sel_new}, {round(dist)}nm apart, '\n",
    "\n",
    "    def resolving_seg_overlap(self):\n",
    "\n",
    "        for p1, p2 in combinations(self.cell_data['base_segments'].keys(), 2):\n",
    "\n",
    "            common_segments = set(self.cell_data['base_segments'][p1]) & set(self.cell_data['base_segments'][p2])\n",
    "\n",
    "            if common_segments != set():\n",
    "\n",
    "                self.update_mtab(f\"Base segments {common_segments} are present in both {p1} and {p2} layers, moving to 'unknown'\", 'Cell Reconstruction')\n",
    "\n",
    "                for dtype in p1, p2:\n",
    "                    if dtype != 'unknown':\n",
    "                        self.cell_data['base_segments'][dtype] -= common_segments\n",
    "\n",
    "                self.cell_data['base_segments']['unknown'].update(common_segments)\n",
    "\n",
    "    def mark_branch_in_colour(self, action_state):\n",
    "\n",
    "        base_seg = self.check_selected_segment('base_segs', action_state, banned_segs = [self.cell_data['anchor_seg']])\n",
    "\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        if base_seg not in [x['name'] for x in self.pr_graph.vs]:\n",
    "            print(f'Base segment {base_seg} was not in the base segment graph, updating displayed segments ...')\n",
    "            self.update_displayed_segs()\n",
    "            return\n",
    "\n",
    "        col = self.viewer.state.layers['base_segs'].segment_colors\n",
    "\n",
    "        if int(base_seg) not in col.keys(): return\n",
    "\n",
    "        current_colour = col[int(base_seg)]\n",
    "        downstream_segs = self.get_ds_segs_of_certain_col(base_seg, current_colour)\n",
    "\n",
    "        if current_colour != '#D2B48C':\n",
    "            cell_part = 'unknown'\n",
    "        else:\n",
    "            cell_part = self.cell_structures[self.cell_structure_pos]\n",
    "        \n",
    "        new_colour = self.chosen_seg_colours[cell_part]\n",
    "\n",
    "        for cs in self.cell_data['base_segments'].keys():\n",
    "\n",
    "            if cs == cell_part:\n",
    "                self.cell_data['base_segments'][cs].update(downstream_segs)\n",
    "            else:\n",
    "                self.cell_data['base_segments'][cs] -= downstream_segs\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            for bs in downstream_segs:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = new_colour\n",
    "\n",
    "    def check_selected_segment(self, layer, action, banned_segs = [], acceptable_segs='all'):\n",
    "\n",
    "        if layer not in action.selectedValues: \n",
    "            return 'None'\n",
    "\n",
    "        selected_segment = str(action.selected_values.get(layer).value)\n",
    "        banned_segs.extend(['None', '0'])\n",
    "\n",
    "        if selected_segment in banned_segs:\n",
    "            return 'None'\n",
    "        else:\n",
    "            if acceptable_segs != 'all':\n",
    "                if selected_segment not in acceptable_segs:\n",
    "                    print(f'Segment {selected_segment} not in current graph')\n",
    "                    return 'None'\n",
    "\n",
    "            return selected_segment\n",
    "        \n",
    "    def change_anchor_seg(self, action_state):  \n",
    "\n",
    "        base_seg = self.check_selected_segment('base_segs', action_state, banned_segs=[self.cell_data['anchor_seg']])\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            s.layers['base_segs'].segment_colors[int(self.cell_data['anchor_seg'])] = '#D2B48C'\n",
    "            s.layers['base_segs'].segment_colors[int(base_seg)] = '#1e90ff'\n",
    "            \n",
    "        self.cell_data['anchor_seg'] = deepcopy(base_seg)\n",
    "        \n",
    "    def change_view(self, location, css=None, ps=None):\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            dimensions = neuroglancer.CoordinateSpace(\n",
    "                scales=self.vx_sizes['em'],\n",
    "                units='nm',\n",
    "                names=['x', 'y', 'z']   )\n",
    "\n",
    "            s.showSlices = False\n",
    "            s.dimensions = dimensions\n",
    "            s.position = array(location)\n",
    "            s.layout = \"xy-3d\"\n",
    "\n",
    "            if css != None:\n",
    "                s.crossSectionScale = css\n",
    "            \n",
    "            if ps != None:\n",
    "                s.projectionScale = ps\n",
    "                \n",
    "    def reset_seg_pr_layers(self, two_d_intensity = 0.5):\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            s.layers['em'] = neuroglancer.ImageLayer(source = self.em)\n",
    "\n",
    "            s.layers['agglo'] = neuroglancer.SegmentationLayer(source = self.agglo_seg, segment_colors={})\n",
    "            s.layers['agglo'].pick = False\n",
    "            s.layers['agglo'].visible = True\n",
    "            s.layers['agglo'].ignoreNullVisibleSet = False\n",
    "            s.layers['agglo'].selectedAlpha = two_d_intensity\n",
    "            s.layers['agglo'].objectAlpha = 1.00\n",
    "            \n",
    "            all_segs = [a for b in self.cell_data['base_segments'].values() for a in b]\n",
    "\n",
    "            s.layers['base_segs'] = neuroglancer.SegmentationLayer(source = self.base_seg, segments=all_segs, segment_colors={})\n",
    "            s.layers['base_segs'].ignoreNullVisibleSet = False\n",
    "            s.layers['base_segs'].pick = False\n",
    "            s.layers['base_segs'].selectedAlpha = two_d_intensity #For 2D\n",
    "\n",
    "            for dtype in self.cell_data['base_segments'].keys():\n",
    "\n",
    "                for seg in self.cell_data['base_segments'][dtype]:\n",
    "                    s.layers['base_segs'].segment_colors[int(seg)] = self.chosen_seg_colours[dtype]\n",
    "\n",
    "            s.layers['base_segs'].segment_colors[int(self.cell_data['anchor_seg'])] = '#1e90ff'\n",
    "\n",
    "    def import_annotations(self,neuroglancer_data, neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "        for n, c in zip(neuroglancer_layer_name,crest_layer_name):\n",
    "            \n",
    "            # get the 'layers' dictionary that has that name\n",
    "\n",
    "            neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == n), None)\n",
    "\n",
    "            # create the annotation list for CREST and put it into cell_data\n",
    "\n",
    "            annotation_list = []\n",
    "\n",
    "            for v in neuroglancer_layer['annotations']:\n",
    "                # print(v)\n",
    "                corrected_location = self.get_corrected_xyz(v['point'], 'seg')\n",
    "\n",
    "                if 'segments' not in v.keys():\n",
    "                    annotation_list.extend([corrected_location])\n",
    "                if 'segments' in v.keys():\n",
    "                    annotation_list.extend([corrected_location + v['segments'][0]])\n",
    "\n",
    "            self.cell_data['end_points'][c].extend(annotation_list)\n",
    "\n",
    "    def define_ctype(self,ctype, method):\n",
    "        '''\n",
    "        method = \"manual\" or \"auto\" \n",
    "        ctype = \"lg/lf/mg1/mg2/mgx/gc/mli/uk...\"\n",
    "        '''\n",
    "        try:\n",
    "            self.cell_data['metadata']['cell-type'][method] = ctype\n",
    "        except KeyError:\n",
    "            self.cell_data['metadata']['cell-type']={'auto':'','manual':''}\n",
    "            self.cell_data['metadata']['cell-type'][method] = ctype\n",
    "\n",
    "    def get_ctype(self,method):\n",
    "        '''\n",
    "        method = \"manual\" or \"auto\" \n",
    "        '''\n",
    "        ctype = ''\n",
    "        \n",
    "        try:\n",
    "            ctype = self.cell_data['metadata']['cell-type'][method]\n",
    "        except KeyError:\n",
    "            self.cell_data['metadata']['cell-type']={'auto':'','manual':''}\n",
    "\n",
    "        try:\n",
    "            ctype = self.cell_data['metadata']['cell-type'][method]\n",
    "        except Exception:\n",
    "            print('cell type not defined for this cell yet -- use cell_type.define(ctype,method)')\n",
    "\n",
    "        return ctype\n",
    "    \n",
    "def import_settings(dict_json):\n",
    "    with open(dict_json, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "        settings_dict=myfile.read()\n",
    "        settings_dict = json.loads(settings_dict)\n",
    "    return settings_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c2185-2363-4dd2-a4ec-ed4c691e794b",
   "metadata": {},
   "source": [
    "### Import settings\n",
    "\n",
    "If you save a copy of settings_dict.json (found in the \"under construction\" directory of eCREST repo) locally somewhere outside the repo (like in your save_dir), then you can use the following code cell to import. This avoids needing to re-type the save_dir and db_path each time you \"git pull\" updates from the repo to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e594867-f9ad-4514-aae8-78127c6afb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee76f1-7249-4add-9d08-ebba36c4d6c9",
   "metadata": {},
   "source": [
    "## Build connectivity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66307f56-b982-42bf-acf6-2f878db555d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aad7187-2ce8-4145-9a73-8920508de0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [child.name.split('_')[2] for child in sorted(Path(dirpath).iterdir()) \n",
    "         if (child.name[0]!='.') & (child.is_file())] # ignore hidden files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0067d9f0-3b06-4352-ba0b-9c7ad87e9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefiles = dict()\n",
    "for child in sorted(Path(dirpath).iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ca4fa4-40af-4f4d-8e5a-2e0b811bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ell = ig_Graph() \n",
    "ell.add_vertices(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab17c50-b195-4950-99ae-6d2c25d2a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cell types to each node\n",
    "for x in ell.vs:\n",
    "    cell = ecrest(settings_dict,filepath = nodefiles[x['name']],launch_viewer=False)\n",
    "    x['cell_type'] = cell.get_ctype('manual') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e275a77-3027-4054-b2ad-671bfabfd42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base_segments dictionary of all cells\n",
    "\n",
    "base_segments = {}\n",
    "for x in ell.vs:\n",
    "    cell = ecrest(settings_dict,filepath = nodefiles[x['name']],launch_viewer=False)\n",
    "    base_segments[cell.cell_data['metadata']['main_seg']['base']] = cell.cell_data['base_segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65202cf0-c24e-4769-9b9b-21ae104aee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 lf cells.\n",
      "18 lg cells.\n",
      "10 mg1 cells.\n",
      "12 mg2 cells.\n",
      "0 lx cells.\n",
      "1 mgx cells.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "for ctype in ['lf','lg','mg1','mg2','lx','mgx']:\n",
    "    these_cells = ell.vs.select(lambda v: ctype in v['cell_type'])\n",
    "    print(f'{len(these_cells)} {ctype} cells.')# {len(ell.vs.select(lambda v: 'lg' in v['cell_type']))} lg cells. {len(ell.vs.select(lambda v: 'mg1' in v['cell_type']))} mg1 cells. {len(ell.vs.select(lambda v: 'mg' in v['cell_type']))} mg cells.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "622663cb-0f17-427c-93f6-020f719f4676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range for cell 213605530 synapse at syn_ has no segment id\n"
     ]
    }
   ],
   "source": [
    "## find edges and set the cell-structure attribute of the edge based on which part of the cell the edge goes to\n",
    "edge_list = []\n",
    "cells_with_synapses = []\n",
    "cells_without_synapses = []\n",
    "# for each node,\n",
    "for x_pre in ell.vs:\n",
    "# x_pre = ell.vs.find('128473437')\n",
    "\n",
    "    # if the node has post-synaptic annotations (the current cell is assumed pre-synaptic)\n",
    "    pre = ecrest(settings_dict,filepath = nodefiles[x_pre['name']],launch_viewer=False)\n",
    "    if pre.cell_data['end_points']['post-synaptic'] != []:\n",
    "        \n",
    "        cells_with_synapses.append([x_pre['name'],x_pre['cell_type'],len(pre.cell_data['end_points']['post-synaptic'])])\n",
    "        \n",
    "        # for each synapse\n",
    "        for syn_ in pre.cell_data['end_points']['post-synaptic']:\n",
    "            try:\n",
    "                post_seg = syn_[3]\n",
    "\n",
    "                # go through each other nodes\n",
    "                for x_post in ell.vs:\n",
    "                # x_post = ell.vs.find('387368998')\n",
    "\n",
    "                    post = base_segments[x_post['name']] #ecrest(settings_dict,filepath = nodefiles[x_post['name']],launch_viewer=False)\n",
    "\n",
    "\n",
    "                    for k,v in post.items():\n",
    "\n",
    "                        for v_ in list(v): #find keys (can be multiple on the same cell) for matching segment ids\n",
    "\n",
    "                            if post_seg == v_: \n",
    "\n",
    "                            # add edge to the graph between current node and matching node\n",
    "                                edge_list.append([x_pre['name'],x_post['name'],k])\n",
    "\n",
    "                            # what happens if the edge already exists? can you \"add another\" or does the \"strength\" attribute increase?\n",
    "\n",
    "                            # set edge attribute for cell structure of edge\n",
    "\n",
    "                            # ****HOW MAKE THIS DIRECTED?\n",
    "            except IndexError as msg:\n",
    "                cellid = x_pre['name']\n",
    "                print(msg, f'for cell {cellid} synapse at syn_ has no segment id')\n",
    "\n",
    "    else:\n",
    "        cells_without_synapses.append([x_pre['name'],x_pre['cell_type'],len(pre.cell_data['end_points']['post-synaptic'])])\n",
    "        cellid = x_pre['name']\n",
    "        # print(f'no synapses for {cellid}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b2688ae-653b-41b0-bd4f-a86290a87eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['128473437', 'mgx', 5],\n",
       " ['213605530', 'mg2', 93],\n",
       " ['214412684', 'mg1', 56],\n",
       " ['214550811', 'mg1', 68],\n",
       " ['214581797', 'mg2', 46],\n",
       " ['215572949', 'mg2', 70],\n",
       " ['216129202', 'mg2', 88],\n",
       " ['220275752', 'gran', 54],\n",
       " ['297178666', 'mli', 84],\n",
       " ['299497999', 'mg1', 9],\n",
       " ['299589324', 'sg', 59],\n",
       " ['300210608', 'mg1', 42],\n",
       " ['300316308', 'mg2', 74],\n",
       " ['300380579', 'mg1', 46],\n",
       " ['302143252', 'mg1', 70],\n",
       " ['31102601', 'gran', 168],\n",
       " ['386117124', 'mg2', 74],\n",
       " ['387368998', 'mg1', 42],\n",
       " ['392213717', 'gran', 61],\n",
       " ['42802314', 'mg2', 36],\n",
       " ['471233236', 'mg2', 64],\n",
       " ['472175645', 'mg1', 70],\n",
       " ['472409584', 'mg1', 28],\n",
       " ['480066826', 'mg2', 56],\n",
       " ['49530373', 'uk', 44]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells_with_synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bde4262-d9ab-49ce-8364-07c49f24f802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['119793391', 'lg', 0],\n",
       " ['126649726', 'mg', 0],\n",
       " ['133378529', 'lg', 0],\n",
       " ['134492570', 'lf', 0],\n",
       " ['134616493', 'lf', 0],\n",
       " ['135514741', 'lf', 0],\n",
       " ['208812182', 'mli', 0],\n",
       " ['214503199', 'lg', 0],\n",
       " ['215403551', 'lg', 0],\n",
       " ['215526370', 'lg', 0],\n",
       " ['218515759', 'uk', 0],\n",
       " ['220213102', 'uk', 0],\n",
       " ['299404889', 'mg2', 0],\n",
       " ['300474334', 'lg', 0],\n",
       " ['300796727', 'lg', 0],\n",
       " ['30117125', 'lf', 0],\n",
       " ['301787806', 'lg', 0],\n",
       " ['305332461', 'lg', 0],\n",
       " ['307418797', 'lf', 0],\n",
       " ['386300356', 'mg2', 0],\n",
       " ['388406692', 'lg', 0],\n",
       " ['389085521', 'mg1', 0],\n",
       " ['390542812', 'lg', 0],\n",
       " ['391902729', 'gran', 0],\n",
       " ['392072123', 'lf', 0],\n",
       " ['392814322', 'lf', 0],\n",
       " ['393063300', 'lf', 0],\n",
       " ['393325331', 'lf', 0],\n",
       " ['394686712', 'lf', 0],\n",
       " ['43235451', 'lg', 0],\n",
       " ['45955972', 'lg', 0],\n",
       " ['472051969', 'mg2', 0],\n",
       " ['473274862', 'gran', 0],\n",
       " ['474898913', 'lg', 0],\n",
       " ['476971816', 'uk', 0],\n",
       " ['480081746', 'gran', 0],\n",
       " ['48573302', 'lf', 0],\n",
       " ['48929295', 'lf', 0],\n",
       " ['49453764', 'lf', 0],\n",
       " ['557818053', 'lg', 0],\n",
       " ['558020412', 'lg', 0],\n",
       " ['561826647', 'lg', 0],\n",
       " ['563840037', 'lf', 0],\n",
       " ['645162652', 'lg', 0],\n",
       " ['650610061', 'lf', 0],\n",
       " ['650953193', 'lf', 0],\n",
       " ['652266299', 'lf', 0],\n",
       " ['653504340', 'uk', 0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells_without_synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82896044-84a3-435b-b94a-eb2a4cc0ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edge_list,columns = ['pre','post','structure'])\n",
    "df_edges = deepcopy(df.value_counts().reset_index(name='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f8cb7ca-d7f3-4fb3-9179-6ccc5dd5f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 total synapses in current network\n",
      "24 unique pre synaptic cells - to - 58 unique post-synaptic cells (or structures once we have them)\n",
      "111 unique edges in the network\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(df)} total synapses in current network')\n",
    "print(f'{len(df[\"pre\"].unique())} unique pre synaptic cells - to - {len(df[\"post\"].unique())} unique post-synaptic cells (or structures once we have them)')\n",
    "\n",
    "print(f'{len(df_edges)} unique edges in the network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e184e839-bde3-4be2-92d2-f7f75bd2fa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mg1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell.vs.find('472175645')['cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdf19e71-9b34-409b-8b8b-244f39c8d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique edge, get the cell-type pair and structure\n",
    "\n",
    "for i,r in df_edges.iterrows():\n",
    "    df_edges.loc[i,'pre_type']=ell.vs.find(r['pre'])['cell_type']\n",
    "    df_edges.loc[i,'post_type']=ell.vs.find(r['post'])['cell_type']\n",
    "    # print(ell.vs.find(r['pre'])['cell_type'])\n",
    "    # print(ell.vs.find(r['post'])['cell_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af082ada-55cd-4e38-80ee-3134e18ffd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>post</th>\n",
       "      <th>structure</th>\n",
       "      <th>weight</th>\n",
       "      <th>pre_type</th>\n",
       "      <th>post_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>472175645</td>\n",
       "      <td>393063300</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20</td>\n",
       "      <td>mg1</td>\n",
       "      <td>lf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216129202</td>\n",
       "      <td>305332461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>mg2</td>\n",
       "      <td>lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42802314</td>\n",
       "      <td>214503199</td>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>mg2</td>\n",
       "      <td>lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215572949</td>\n",
       "      <td>214503199</td>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>mg2</td>\n",
       "      <td>lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213605530</td>\n",
       "      <td>305332461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>mg2</td>\n",
       "      <td>lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>300210608</td>\n",
       "      <td>49453764</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>mg1</td>\n",
       "      <td>lf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>300316308</td>\n",
       "      <td>214412684</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>mg2</td>\n",
       "      <td>mg1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>300380579</td>\n",
       "      <td>220275752</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>mg1</td>\n",
       "      <td>gran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>302143252</td>\n",
       "      <td>213605530</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>mg1</td>\n",
       "      <td>mg2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>128473437</td>\n",
       "      <td>387368998</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>mgx</td>\n",
       "      <td>mg1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pre       post structure  weight pre_type post_type\n",
       "0    472175645  393063300   unknown      20      mg1        lf\n",
       "1    216129202  305332461   unknown      18      mg2        lg\n",
       "2     42802314  214503199   unknown      12      mg2        lg\n",
       "3    215572949  214503199   unknown      12      mg2        lg\n",
       "4    213605530  305332461   unknown      12      mg2        lg\n",
       "..         ...        ...       ...     ...      ...       ...\n",
       "106  300210608   49453764   unknown       1      mg1        lf\n",
       "107  300316308  214412684   unknown       1      mg2       mg1\n",
       "108  300380579  220275752   unknown       1      mg1      gran\n",
       "109  302143252  213605530   unknown       1      mg1       mg2\n",
       "110  128473437  387368998   unknown       1      mgx       mg1\n",
       "\n",
       "[111 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe08b8fd-54a6-45f1-81fe-36e15eee924a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges['weight'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afd125cc-9a3a-4ea5-9a4a-38faad6ed2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_type</th>\n",
       "      <th>post_type</th>\n",
       "      <th>structure</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mg2</td>\n",
       "      <td>lg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mg1</td>\n",
       "      <td>lf</td>\n",
       "      <td>unknown</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mg1</td>\n",
       "      <td>mg2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mg2</td>\n",
       "      <td>mg1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gran</td>\n",
       "      <td>lg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gran</td>\n",
       "      <td>mg1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mg1</td>\n",
       "      <td>uk</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mg1</td>\n",
       "      <td>gran</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mg2</td>\n",
       "      <td>uk</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mg1</td>\n",
       "      <td>mgx</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mgx</td>\n",
       "      <td>mg1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mli</td>\n",
       "      <td>lg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mli</td>\n",
       "      <td>mg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mli</td>\n",
       "      <td>mg1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mli</td>\n",
       "      <td>mg2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sg</td>\n",
       "      <td>mg</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pre_type post_type structure  counts\n",
       "0       mg2        lg   unknown      35\n",
       "1       mg1        lf   unknown      30\n",
       "2       mg1       mg2   unknown      11\n",
       "3       mg2       mg1   unknown      10\n",
       "4      gran        lg   unknown       5\n",
       "5      gran       mg1   unknown       5\n",
       "6       mg1        uk   unknown       4\n",
       "7       mg1      gran   unknown       2\n",
       "8       mg2        uk   unknown       2\n",
       "9       mg1       mgx   unknown       1\n",
       "10      mgx       mg1   unknown       1\n",
       "11      mli        lg   unknown       1\n",
       "12      mli        mg   unknown       1\n",
       "13      mli       mg1   unknown       1\n",
       "14      mli       mg2   unknown       1\n",
       "15       sg        mg   unknown       1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges[['pre_type','post_type','structure']].value_counts().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6da3acb9-9de2-411f-9326-ab5443b5bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges[['pre_type','post_type','structure']].value_counts().reset_index(name='counts')['counts'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7414c7-1d86-46a7-be25-45a1ba8a5159",
   "metadata": {},
   "source": [
    "## GET most recent files (by filename date) in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92ae0f-6fb5-4440-ae11-8ada737d782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'C:/Users/mpetkova/Dropbox/U19_zebrafish/EMfullres/LateralLineCurlDetector/CREST/right_afferents/'\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/EngertLab/Dropbox/CREST/mariela_fish_credentials.json'\n",
    "\n",
    "names = os.listdir(dirname);\n",
    "cellid_filename=list();\n",
    "for ind in range(len(names)):\n",
    "    content = names[ind].split('_')\n",
    "    if ('cell' in content):\n",
    "        cellid_filename.append(names[ind])\n",
    "d={}\n",
    "for name in cellid_filename:\n",
    "    ID,content_type,date=name.split('_')[2], name.split('_')[0], name.split('_')[-1]\n",
    "    date=date[:-5]\n",
    "    #create entry in dict which holds ID, file type (ex: cell_graph) and file path\n",
    "    if ID not in d:\n",
    "        d[ID]=[date, name]\n",
    "        #if there are multiple files with the same ID, keep the info for the newest one\n",
    "    else:\n",
    "        if date>d[ID][0]:\n",
    "            d[ID][0]=date\n",
    "            d[ID][1]=name\n",
    "            \n",
    "############################################################################################################################ \n",
    "# Collect all the base segments for each ID\n",
    "import json\n",
    "\n",
    "base_segs = {}\n",
    "\n",
    "for key in d.keys():\n",
    "    f = open(dirname+d[key][1])\n",
    "    data = json.load(f)\n",
    "    base_segs[key]=sum(data['base_segments'].values(),[])\n",
    "    f.close()\n",
    "\n",
    "############################################################################################################################ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce129b0-73f7-4e94-8985-7f8b17d31adf",
   "metadata": {},
   "source": [
    "## Fix cell_data dictionary keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cb9c4d36-43c7-4715-a62c-ae9837921bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(\"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/\")\n",
    "filepath = filepath / \"cell_graph_305332461__2023-04-01 21.04.03.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6eec29e-2be3-441a-b196-316373c3d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = ecrest(settings_dict,filepath = filepath,launch_viewer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "101fbab4-c354-4de4-abd7-96adeb1e5c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exit volume': [],\n",
       " 'natural': [],\n",
       " 'bad alignment': [],\n",
       " 'uncorrected split': [],\n",
       " 'artefact': [],\n",
       " 'natural end': [],\n",
       " 'uncertain': [],\n",
       " 'pre-synaptic': [],\n",
       " 'post-synaptic': []}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_points = cell.cell_data['end_points']\n",
    "old_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14c9f900-a71f-402b-89f6-a0ec76625a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_points = {}\n",
    "for p in cell.point_types:\n",
    "    # if p not in cell.cell_data['end_points']:\n",
    "    end_points[p] = []\n",
    "        \n",
    "cell.cell_data['end_points'] = end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76c1f388-7f89-4c08-8769-97c0c5459d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.cell_data['end_points']['natural end'] = old_points['natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6bcd077e-bc64-400b-9f56-0bbb382498fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['exit volume', 'natural end', 'uncertain', 'pre-synaptic', 'post-synaptic'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell.cell_data['end_points'].pop('natural')\n",
    "cell.cell_data['end_points'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bbf6b9bc-1ed2-4e71-be0b-0c7651843936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 305332461 reconstruction locally at 2023-04-05 11.20.24\n"
     ]
    }
   ],
   "source": [
    "cell.save_cell_graph(directory_path = filepath.parent, file_name=filepath.name, save_to_cloud=False); #rewrites the original, not with a new time stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b276e-251e-4c16-a30f-bfaab72eebc5",
   "metadata": {},
   "source": [
    "## Figure out what is wrong with a crest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ef7ae9d8-9034-4c22-bff7-c8e39f8c0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(\"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/\")\n",
    "filepath = filepath / \"cell_graph_213605530__2023-03-29 22.49.21.json\"\n",
    "cell = ecrest(settings_dict,filepath = filepath,launch_viewer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d743ef3b-a049-44dc-8e32-893a87a5fec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.cell_data['end_points']['post-synaptic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f4b2b-e2d0-4998-8d32-caa3d08f5900",
   "metadata": {},
   "source": [
    "## Fix pre-synaptic to be post-synaptic annotation list in converted crest jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b6ba64bf-cbc9-4778-81ba-8cd635606f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fix = Path(\"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/Complete/synapses/to-crest/conversion_specs_synapse_fix.json\")\n",
    "\n",
    "with open(json_fix,'r') as f:\n",
    "    cells_to_fix = f.read()\n",
    "    cells_to_fix = json.loads(cells_to_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e78fd2e7-16f0-4b42-9e81-751b1b114c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_to_fix = cells_to_fix['cell_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e2176837-bbba-4557-a9a8-b9e760b06b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 214412684 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 214550811 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 215572949 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 216129202 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 220275752 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 297178666 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 299497999 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 299589324 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 300210608 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 300316308 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 300380579 reconstruction locally at 2023-04-05 12.11.10\n",
      "\"305035439'\"\n",
      "Saved cell 31102601 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 387368998 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 392213717 reconstruction locally at 2023-04-05 12.11.10\n",
      "Saved cell 42802314 reconstruction locally at 2023-04-05 12.11.11\n",
      "'472161980'\n",
      "Saved cell 472175645 reconstruction locally at 2023-04-05 12.11.11\n",
      "Saved cell 472409584 reconstruction locally at 2023-04-05 12.11.11\n",
      "Saved cell 480066826 reconstruction locally at 2023-04-05 12.11.11\n",
      "Saved cell 49530373 reconstruction locally at 2023-04-05 12.11.11\n"
     ]
    }
   ],
   "source": [
    "for k,v in cells_to_fix.items():\n",
    "    try:\n",
    "        filepath = nodefiles[k]\n",
    "        cell = ecrest(settings_dict,filepath = filepath,launch_viewer=False)\n",
    "        cell.cell_data['end_points']['post-synaptic'] = deepcopy(cell.cell_data['end_points']['pre-synaptic'])\n",
    "\n",
    "        cell.cell_data['end_points']['pre-synaptic'] = []\n",
    "        # cell.save_cell_graph(directory_path = filepath.parent / 'original', file_name=filepath.name, save_to_cloud=False); #rewrites the original, not with a new time stamp\n",
    "    except KeyError as msg:\n",
    "        print(msg)\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "af15d4a1-2c45-4dad-8dc5-ee8b1eb4317e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bac8b0a7-b6cd-4a56-a155-7cb8f90d2c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exit volume': [],\n",
       " 'natural end': [[142609.46875, 275542.6875, 45.0],\n",
       "  [142776.15625, 278173.6875, 2775.0],\n",
       "  [53208.87890625, 271123.09375, 13365.0],\n",
       "  [70813.0859375, 267435.34375, 10044.652404785156],\n",
       "  [51008.359375, 284277.96875, 56675.0830078125],\n",
       "  [68367.4921875, 273829.5625, 31418.91357421875],\n",
       "  [64639.48046875, 274508.65625, 35085.003662109375],\n",
       "  [62399.1796875, 303022.0625, 106049.47265625],\n",
       "  [54059.69921875, 292912.375, 77115.0],\n",
       "  [115337.7109375, 289251.84375, 74204.99267578125],\n",
       "  [140118.015625, 284278.375, 106005.0],\n",
       "  [142204.484375, 284977.09375, 106005.0],\n",
       "  [111865.0390625, 291143.6875, 67154.99267578125],\n",
       "  [110964.0390625, 289608.1875, 66825.0],\n",
       "  [109141.9609375, 289524.5625, 66975.0],\n",
       "  [106861.765625, 289384.875, 68985.0],\n",
       "  [222726.3125, 265308.8125, 60494.996337890625],\n",
       "  [185022.09375, 273914.90625, 45135.0],\n",
       "  [184830.203125, 272752.84375, 52605.0],\n",
       "  [169899.09375, 265474.03125, 13754.999084472656],\n",
       "  [135296.546875, 277537.78125, 40934.996337890625],\n",
       "  [122864.8046875, 270745.4375, 31184.996337890625],\n",
       "  [137723.015625, 312193.65625, 106035.0],\n",
       "  [137060.875, 313303.625, 102337.37548828125],\n",
       "  [140551.875, 311073.71875, 78974.99267578125],\n",
       "  [200516.203125, 311475.6875, 106035.0],\n",
       "  [192419.9375, 310598.125, 96764.99267578125],\n",
       "  [183279.203125, 310559.15625, 93345.0],\n",
       "  [130835.0390625, 192378.203125, 106035.0],\n",
       "  [81289.7109375, 179026.671875, 106035.0],\n",
       "  [90222.59375, 208912.078125, 106035.0],\n",
       "  [192105.296875, 49391.17578125, 9614.999084472656],\n",
       "  [212747.71875, 49180.796875, 61094.99267578125],\n",
       "  [124347.953125, 52019.859375, 106035.0],\n",
       "  [155152.578125, 76213.7265625, 45.0],\n",
       "  [133582.078125, 128614.546875, 106035.0],\n",
       "  [134242.03125, 98370.8203125, 106035.0],\n",
       "  [113433.1484375, 99209.953125, 106035.0],\n",
       "  [182430.203125, 49238.4609375, 34124.996337890625],\n",
       "  [93554.6640625, 73034.8515625, 104906.46240234375],\n",
       "  [88471.875, 119794.3125, 38834.996337890625],\n",
       "  [55033.328125, 84431.0703125, 40455.003662109375],\n",
       "  [67395.7734375, 70934.171875, 65925.00732421875],\n",
       "  [124569.890625, 55806.61328125, 69015.00732421875],\n",
       "  [74379.4140625, 84828.9765625, 45.0],\n",
       "  [83033.75, 86694.6015625, 25305.0],\n",
       "  [91617.828125, 104709.140625, 45.0],\n",
       "  [141076.125, 60318.34375, 106035.0],\n",
       "  [215211.328125, 308878.625, 53954.996337890625],\n",
       "  [214443.046875, 307279.96875, 54344.996337890625],\n",
       "  [215030.859375, 307986.46875, 52575.0],\n",
       "  [214712.859375, 302142.6875, 62385.00732421875],\n",
       "  [214104.203125, 304233.90625, 60854.996337890625],\n",
       "  [189899.59375, 311289.40625, 48975.0],\n",
       "  [183343.78125, 311370.34375, 44205.0],\n",
       "  [181160.03125, 310586.78125, 43245.0],\n",
       "  [170115.796875, 310241.25, 37575.0],\n",
       "  [168698.96875, 311308.71875, 37034.996337890625],\n",
       "  [154350.265625, 313316.1875, 37544.996337890625],\n",
       "  [152391.453125, 310610.8125, 45.0],\n",
       "  [153568.765625, 310708.3125, 2715.000228881836],\n",
       "  [137728.703125, 310831.78125, 33255.003662109375],\n",
       "  [141694.96875, 310141.375, 50775.00732421875],\n",
       "  [162656.5, 323412.5625, 5775.000457763672],\n",
       "  [161882.171875, 324019.03125, 6008.211822509766],\n",
       "  [174081.75, 311736.1875, 4869.499969482422],\n",
       "  [175620.734375, 311505.1875, 11204.999084472656],\n",
       "  [176342.515625, 310904.40625, 8715.0],\n",
       "  [173013.703125, 311588.125, 8327.289733886719],\n",
       "  [171701.1875, 311510.78125, 8654.999084472656],\n",
       "  [169689.0, 310699.90625, 6794.999084472656],\n",
       "  [169953.203125, 311584.03125, 7065.0],\n",
       "  [150787.890625, 329012.25, 32775.0],\n",
       "  [150811.59375, 328484.53125, 34214.996337890625],\n",
       "  [151155.734375, 326433.0, 37514.996337890625],\n",
       "  [144179.609375, 316226.78125, 41535.0],\n",
       "  [126132.1015625, 317534.4375, 27014.998168945312],\n",
       "  [125275.65625, 317271.84375, 26084.998168945312],\n",
       "  [124675.6796875, 318120.6875, 25844.998168945312],\n",
       "  [136838.90625, 311748.375, 4455.0],\n",
       "  [132672.9375, 310965.5, 3705.000228881836],\n",
       "  [134711.140625, 314111.90625, 42495.003662109375],\n",
       "  [137472.484375, 309393.09375, 46785.0],\n",
       "  [78388.6796875, 315089.40625, 106035.0],\n",
       "  [56271.62109375, 318292.40625, 36254.996337890625],\n",
       "  [36406.5625, 318730.25, 59355.003662109375],\n",
       "  [36906.96875, 318733.28125, 58664.996337890625],\n",
       "  [30937.228515625, 320357.75, 62595.0],\n",
       "  [34140.55859375, 321677.53125, 61725.0],\n",
       "  [38609.1953125, 317320.8125, 55395.003662109375],\n",
       "  [39111.91796875, 316482.65625, 51765.003662109375],\n",
       "  [43218.67578125, 316450.96875, 48795.0],\n",
       "  [62954.66796875, 314006.625, 53445.00732421875],\n",
       "  [47927.6875, 317762.5, 69915.0],\n",
       "  [32473.51953125, 324043.25, 84885.0],\n",
       "  [73807.90625, 312036.875, 17924.998168945312],\n",
       "  [64130.23828125, 311797.0625, 13305.0],\n",
       "  [34540.015625, 317452.46875, 6524.999542236328],\n",
       "  [98563.9453125, 310230.6875, 21315.0],\n",
       "  [98442.4296875, 308578.15625, 25005.0],\n",
       "  [101650.9140625, 310098.0, 26985.001831054688],\n",
       "  [106998.640625, 309657.78125, 33675.003662109375],\n",
       "  [106726.640625, 308553.78125, 34095.003662109375],\n",
       "  [104712.7265625, 310591.125, 32595.0],\n",
       "  [105705.3515625, 309894.53125, 32745.003662109375]],\n",
       " 'uncertain': [],\n",
       " 'pre-synaptic': [],\n",
       " 'post-synaptic': [[222438.765625,\n",
       "   266163.84375,\n",
       "   60164.99267578125,\n",
       "   '385188039'],\n",
       "  [222150.640625, 264922.28125, 60225.00732421875, '207761438'],\n",
       "  [222024.890625, 267046.09375, 57765.0, '387491152'],\n",
       "  [221821.09375, 266376.46875, 58124.996337890625, '386346210'],\n",
       "  [221122.375, 267628.375, 57824.996337890625, '299344334'],\n",
       "  [220142.234375, 269705.28125, 57824.996337890625, '385188039'],\n",
       "  [218304.78125, 272044.125, 56085.003662109375, '301603337'],\n",
       "  [219175.921875, 273562.75, 55695.003662109375, '301619421'],\n",
       "  [184640.65625, 274442.0625, 45675.003662109375, '215666697'],\n",
       "  [185299.90625, 274542.125, 45465.003662109375, '302684381'],\n",
       "  [185364.640625, 274118.34375, 46725.0, '301538610'],\n",
       "  [186329.46875, 274646.8125, 51855.0, '302667883'],\n",
       "  [170126.8125, 265266.3125, 13875.0, '41564382'],\n",
       "  [173270.828125, 266121.875, 17505.001831054688, '128612633'],\n",
       "  [174976.484375, 267636.78125, 20595.001831054688, '129758863'],\n",
       "  [176047.40625, 268245.4375, 21195.001831054688, '128612633'],\n",
       "  [174134.953125, 268264.1875, 20925.001831054688, '128612632'],\n",
       "  [175716.90625, 268953.3125, 26715.001831054688, '129744690'],\n",
       "  [175769.859375, 268088.0625, 27945.0, '215647260'],\n",
       "  [175030.609375, 268507.8125, 32265.003662109375, '215633294'],\n",
       "  [134582.828125, 277103.125, 40845.0, '130812329'],\n",
       "  [132883.890625, 276403.46875, 41715.0, '302559454'],\n",
       "  [129092.6171875, 275796.625, 42405.0, '302559664'],\n",
       "  [127891.5546875, 276132.71875, 41895.0, '302559111'],\n",
       "  [123086.421875, 269439.5625, 33945.003662109375, '115945511'],\n",
       "  [122927.5234375, 268533.125, 33945.003662109375, '215525266'],\n",
       "  [123698.5546875, 269569.0625, 34605.0, '130812329'],\n",
       "  [123180.609375, 268391.84375, 35025.0, '215525737'],\n",
       "  [120918.5625, 267548.90625, 37755.003662109375, '130812329'],\n",
       "  [119834.46875, 267233.09375, 40095.003662109375, '215511594'],\n",
       "  [118698.4375, 266762.125, 40035.003662109375, '214366905'],\n",
       "  [118990.890625, 268249.0625, 43065.0, '111345587'],\n",
       "  [118393.8359375, 269207.9375, 44091.01318359375, '301384141'],\n",
       "  [118357.6953125, 267847.09375, 44595.003662109375, '300238999'],\n",
       "  [117708.5625, 270587.0625, 45555.0, '300238999'],\n",
       "  [117996.9765625, 270769.53125, 45045.003662109375, '301384808'],\n",
       "  [70899.265625, 267728.40625, 10065.0, '40229907'],\n",
       "  [64805.5078125, 267682.625, 9255.000915527344, '43637142'],\n",
       "  [61313.9765625, 268318.71875, 9435.000915527344, '43637214'],\n",
       "  [60731.25, 268189.21875, 9225.0, '43620822'],\n",
       "  [56518.765625, 271486.5, 11625.0, '43622129'],\n",
       "  [54586.29296875, 271913.15625, 11655.0, '42476420'],\n",
       "  [54150.72265625, 271147.96875, 11355.000915527344, '41348014'],\n",
       "  [55226.171875, 270553.3125, 10605.000915527344, '41348014'],\n",
       "  [56132.625, 270871.15625, 10275.000915527344, '43621743'],\n",
       "  [54094.2578125, 270927.34375, 13095.001831054688, '43622281'],\n",
       "  [52987.67578125, 270791.96875, 13245.000915527344, '43621993'],\n",
       "  [76980.3359375, 281484.90625, 12794.999084472656, '45958431'],\n",
       "  [78685.75, 282098.96875, 14385.0, '131830315'],\n",
       "  [68648.90625, 274140.65625, 31994.996337890625, '119179690'],\n",
       "  [67494.0703125, 273422.53125, 32984.996337890625, '119179690'],\n",
       "  [64262.49609375, 274684.125, 34875.0, '123804398'],\n",
       "  [65362.77734375, 275698.90625, 36254.996337890625, '119179690'],\n",
       "  [64110.91015625, 276387.9375, 36494.996337890625, '216547178'],\n",
       "  [65411.3125, 277300.15625, 38204.996337890625, '119179690'],\n",
       "  [52007.59765625, 284414.5625, 56714.996337890625, '301247367'],\n",
       "  [51299.17578125, 283929.375, 56684.996337890625, '389393898'],\n",
       "  [51687.35546875, 285045.40625, 55935.0, '389409910'],\n",
       "  [56595.0703125, 279360.3125, 55364.996337890625, '388264713'],\n",
       "  [55925.4609375, 279535.0, 55184.99267578125, '211953945'],\n",
       "  [56195.5859375, 279067.125, 53445.00732421875, '388264300'],\n",
       "  [54498.90625, 293680.34375, 75884.99267578125, '476432190'],\n",
       "  [53945.75, 292399.34375, 76814.99267578125, '476432449'],\n",
       "  [61975.5078125, 291960.90625, 69494.99267578125, '476445559'],\n",
       "  [63790.24609375, 292504.375, 68384.99267578125, '390572721'],\n",
       "  [142478.109375, 284582.59375, 105615.0, '647238132'],\n",
       "  [142206.390625, 286096.46875, 105644.99267578125, '393031999'],\n",
       "  [114504.7734375, 289958.1875, 75224.99267578125, '388422459'],\n",
       "  [114068.0703125, 288978.03125, 74504.99267578125, '476570050'],\n",
       "  [112073.4609375, 291612.40625, 67515.0, '476553358'],\n",
       "  [111209.7734375, 289535.59375, 67454.99267578125, '305889380'],\n",
       "  [108346.90625, 288759.15625, 67454.99267578125, '305889380'],\n",
       "  [105891.6640625, 288574.75, 68625.0, '305889380'],\n",
       "  [103718.8125, 289757.8125, 69824.99267578125, '305889380']]}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.cell_data['end_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e827d5e-6818-4ac7-ad95-8c231650e7d6",
   "metadata": {},
   "source": [
    "## Anatomical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed8e96-377a-4a21-9eb3-b3a462d669e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
