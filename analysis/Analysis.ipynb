{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31a75a1-680b-42f7-a979-b3fc38bd326f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72bbd0-2eff-4e39-a363-90aca421ec6e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e65463-c950-47ce-a195-f61b5fc3faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a903e-0d78-4fb9-9b5d-9386721b584a",
   "metadata": {},
   "source": [
    "### 2. Define the 'ecrest' class using functions from CREST.py\n",
    "\n",
    "An instance of this object will be able to:\n",
    "- open an neuroglancer viewer for proofrieading (see \"Proofread using CREST\")\n",
    "    - add-remove segments (using graph feature for efficiency)\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "- convert from neuroglancer json (see \"Convert From Neuroglancer to eCREST\")\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "    \n",
    "Run the following code cell to define the crest_json class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19e9a0f6-7de4-458d-acf7-ce841ef7f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ecrest:\n",
    "    \n",
    "    def __init__(self,settings_dict, segment_id = None, segment_list = None, filepath = None, launch_viewer=False):\n",
    "        \n",
    "        '''\n",
    "        At some point, store these initialization values (ie addresses, keys lists) as a 'params' file that can be provided to the init function instead of hard-coding\n",
    "        \n",
    "        main_base_id : base segment ID from neuroglancer list\n",
    "        \n",
    "        db_path : filepath to agglomeration database sql file locally on computer\n",
    "        \n",
    "        '''\n",
    "        #####\n",
    "        \n",
    "        '''\n",
    "        set up local stuff\n",
    "        '''\n",
    "        \n",
    "        self.import_from_settings_dict(settings_dict)\n",
    "        self.launch_viewer = launch_viewer\n",
    "        \n",
    "        # Create the connection to the database (right now just for 'Cell Reconstruction')\n",
    "        self.connect_db(self.db_paths)\n",
    "        \n",
    "        # Set up addresses\n",
    "        # addresses are stored in the agglomo SQL file        \n",
    "        required_addresses = ['agglo_address', 'base_address', 'em_address', 'cloud_storage_address']\n",
    "        [self.agglo_seg, self.base_seg, self.em, self.cloud_storage_address]  = self.get_addresses(required_addresses)\n",
    "       \n",
    "        self.cell_pos = 0\n",
    "        self.start_time = time()\n",
    "        self.link_opened = False\n",
    "\n",
    "        self.get_vx_sizes()\n",
    "        self.added_keybindings = set()\n",
    "        \n",
    "        if segment_id!=None: \n",
    "            # initialize from segment ID\n",
    "            self.load_from_segment_id(segment_id,segment_list)\n",
    "            \n",
    "        if filepath!=None:\n",
    "            # initialize from file (crest .json state)\n",
    "            self.load_from_file(filepath)\n",
    "        #####\n",
    "        \n",
    "        '''\n",
    "        Set up neuroglancer viewer\n",
    "        '''\n",
    "        \n",
    "        if launch_viewer==True:\n",
    "            self.viewer = neuroglancer.Viewer()\n",
    "            self.viewer.set_state({})\n",
    "\n",
    "            # Add keybindings:\n",
    "            pr_keybindings = {\n",
    "                'change-structure': lambda s: self.change_cell_structure(),\n",
    "                'change-anchor-seg': self.change_anchor_seg,\n",
    "                'add-or-remove-seg': self.add_or_remove_seg,\n",
    "                'mark-branch-in-colour': self.mark_branch_in_colour,\n",
    "                'change-point' : lambda s: self.change_point()\n",
    "                # 'grow-graph': lambda s: self.grow_graph(), ### WHY IS GROW GRAPH DISABLED? SEEMS USEFUL FOR LABELING CELL STRUCTURES AFTER ADDING SEGMENTS?\n",
    "                # 'increase-threshold': lambda s: self.increase_threshold(),\n",
    "                # 'decrease-threshold': lambda s: self.decrease_threshold(),\n",
    "                # 'start-branch-focus': self.branch_focus,\n",
    "                # 'accept-new-segs': lambda s: self.accept_new_segs(),        \n",
    "            }\n",
    "\n",
    "            self.add_keybindings_no_duplicates(pr_keybindings)            \n",
    "\n",
    "            with self.viewer.config_state.txn() as s:\n",
    "                s.input_event_bindings.viewer['keyc'] = 'change-structure'\n",
    "                s.input_event_bindings.data_view['dblclick0'] = 'add-or-remove-seg'\n",
    "                s.input_event_bindings.data_view['alt+mousedown0'] = 'mark-branch-in-colour'\n",
    "                s.input_event_bindings.data_view['shift+mousedown2'] = 'change-anchor-seg'\n",
    "                s.input_event_bindings.data_view['keyp'] = 'change-point'\n",
    "                # s.input_event_bindings.viewer['keyg'] = 'grow-graph'\n",
    "                # s.input_event_bindings.viewer['keyk'] = 'increase-threshold'\n",
    "                # s.input_event_bindings.viewer['keyj'] = 'decrease-threshold'\n",
    "                # s.input_event_bindings.viewer['keya'] = 'accept-new-segs'\n",
    "                # s.input_event_bindings.data_view['shift+mousedown0'] = 'start-branch-focus'\n",
    "\n",
    "            with self.viewer.config_state.txn() as s:\n",
    "                s.show_layer_panel = True ###\n",
    "                \n",
    "            # setup point annoations\n",
    "            self.set_endpoint_annotation_layers()\n",
    "            self.set_base_seg_merger_layer()\n",
    "            self.point_pos = -1\n",
    "            self.change_point()\n",
    "\n",
    "            self.set_seg_colours()\n",
    "            self.cell_structure_pos = -1\n",
    "            self.change_cell_structure()\n",
    "\n",
    "            loc = self.get_locations_from_base_segs([self.cell_data['metadata']['main_seg']['base']])[self.cell_data['metadata']['main_seg']['base']]\n",
    "            self.change_view(loc, css=0.22398, ps=389.338)\n",
    "            self.reset_seg_pr_layers()\n",
    "\n",
    "            b = self.cell_data['base_segments']\n",
    "            second_part = ', '.join([f'{x}: {len(b[x])}' for x in b.keys()])\n",
    "            print(f'updating viewer status message: Current Base Segment Counts: {second_part}')\n",
    "            with self.viewer.config_state.txn() as s:\n",
    "                s.status_messages['current_seg_count'] = f'Current Base Segment Counts: {second_part}'\n",
    "\n",
    "            self.open_ng_link()\n",
    "            # self.assert_segs_in_sync()\n",
    "\n",
    "    def open_ng_link(self):\n",
    "\n",
    "        if not self.link_opened:\n",
    "            wb_open(str(self.viewer))\n",
    "            self.link_opened = True\n",
    "\n",
    "    def import_from_settings_dict(self,settings_dict):\n",
    "        # self.settings_dict = settings_dict\n",
    "        self.db_paths = Path(settings_dict['db_path'])\n",
    "        self.point_types = settings_dict['annotation_points']\n",
    "        self.cell_structures = settings_dict['cell_structures']\n",
    "        self.max_num_base_added = settings_dict['max_num_base_added']\n",
    "        self.save_dir = Path(settings_dict['save_dir'])\n",
    "\n",
    "    def add_keybindings_no_duplicates(self, dict):\n",
    "\n",
    "        for k in dict:\n",
    "\n",
    "            if k not in self.added_keybindings:\n",
    "\n",
    "                self.viewer.actions.add(k, dict[k])\n",
    "                self.added_keybindings.add(k)           \n",
    "                \n",
    "    def load_from_segment_id(self,main_base_id,segment_list = None):\n",
    "        '''\n",
    "        initializes the graph after loading all the base segments in the agglomeration segment with the main_base_id\n",
    "        '''\n",
    "        agglo_seg_id = self.get_agglo_seg_of_base_seg(str(main_base_id))\n",
    "        \n",
    "        self.cell_data = {\n",
    "            'graph_edges': [],\n",
    "            'graph_nodes': [],\n",
    "            'base_locations': {},\n",
    "            'added_graph_edges': [], \n",
    "            'added_graph_edges_pre_proofreading': [],\n",
    "            'end_points': {key: [] for key in self.point_types},\n",
    "            'base_seg_merge_points': [],\n",
    "            'removed_base_segs': set(),\n",
    "            'anchor_seg' : str(main_base_id),\n",
    "            'metadata': {   \n",
    "                'main_seg' : {'agglo' : {self.agglo_seg : agglo_seg_id}, 'base' : str(main_base_id)},\n",
    "                'data_sources': {\n",
    "                    'em' : self.em, \n",
    "                    'base': self.base_seg, \n",
    "                    'agglo': self.agglo_seg,\n",
    "                    },\n",
    "                'timing' : [],\n",
    "                'completion' : [],\n",
    "                'cell-type' : {'manual': [], 'auto': []}\n",
    "                },\n",
    "            'base_segments' : {dtype: set() for dtype in self.cell_structures}\n",
    "        }\n",
    "        \n",
    "        if segment_list!=None: # Then a list of base_segments has been provided and should override getting all base segments from agglomo\n",
    "                                # For example, this would be the case if converting from a neuroglancer-direct json state reconstruction\n",
    "            self.cell_data['base_segments']['unknown']=set(segment_list)\n",
    "\n",
    "            '''\n",
    "            TODO\n",
    "\n",
    "            CHANGE SEGMENT LIST TO BE A DICTIONARY OF {CELL STRUCTURE : LIST} \n",
    "            so can import segments for specific parts of cells\n",
    "\n",
    "            '''\n",
    "\n",
    "        if segment_list==None: # Then a list of base segments was not provided, and need to get all base segments associated with main_base_seg in its agglo segment\n",
    "            segment_list = self.get_base_segs_of_agglo_seg(agglo_seg_id)\n",
    "            self.cell_data['base_segments']['unknown']=set(segment_list)\n",
    "        \n",
    "        # Initialize graph of base_segments (can be across different cell structures)\n",
    "        self.create_pr_graph()\n",
    "        \n",
    "        # Initialize the CREST json file\n",
    "        # self.save_cell_graph()\n",
    "        \n",
    "        print(f'Created a CREST instance for NEW Reconstruction of {main_base_id}. No file saved yet -- save manually.')                                            \n",
    "        \n",
    "    def load_from_file(self,filepath):\n",
    "    \n",
    "        with open(filepath, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "            cell_data=myfile.read()\n",
    "            self.cell_data = json.loads(cell_data)\n",
    "        \n",
    "        for dtype in self.cell_data['base_segments']:\n",
    "            self.cell_data['base_segments'][dtype] = set(self.cell_data['base_segments'][dtype])\n",
    "    \n",
    "        self.cell_data['removed_base_segs'] = set(self.cell_data['removed_base_segs'])\n",
    "        \n",
    "        main_base_id = self.cell_data['metadata']['main_seg']['base']\n",
    "        # print(f'Loading a CREST instance for LOADED Reconstruction of {main_base_id}')\n",
    "        \n",
    "        self.load_graph_from_celldata()\n",
    "        self.resolving_seg_overlap()\n",
    "        # self.adjust_annotations_structures()\n",
    "        \n",
    "\n",
    "    def get_addresses(self, required_addresses):\n",
    "        \n",
    "        '''\n",
    "        req_addresses = ['agglo_address', 'base_address', 'em_address', 'cloud_storage_address']\n",
    "        '''\n",
    "        a = ', '.join(required_addresses)\n",
    "\n",
    "        self.db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')\n",
    "\n",
    "        results = self.db_cursors.fetchall()[0]\n",
    "\n",
    "        return results\n",
    "        \n",
    "    def connect_db(self, db_path):\n",
    "\n",
    "        self.db_cursors = sqlite3_connect(db_path, check_same_thread=False).cursor()\n",
    "        \n",
    "    def update_msg(self, msg, layer='status'):\n",
    "        \n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.status_messages[layer] = msg\n",
    "\n",
    "    def get_vx_sizes(self):\n",
    "               \n",
    "        self.db_cursors.execute('SELECT * FROM voxel_sizes_table')\n",
    "\n",
    "        self.vx_sizes = {}\n",
    "\n",
    "        for dtype, x, y, z, x_size, y_size, z_size in self.db_cursors.fetchall():\n",
    "\n",
    "            self.vx_sizes[dtype] = [x, y, z]\n",
    "\n",
    "            if dtype == 'em':\n",
    "                self.starting_location = [int(x_size/2), int(y_size/2), int(z_size/2),]\n",
    "\n",
    "    def set_base_seg_merger_layer(self):\n",
    "\n",
    "        self.point_types.append('Base Segment Merger')\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            s.layers['Base Segment Merger'] = neuroglancer.AnnotationLayer()\n",
    "            s.layers['Base Segment Merger'].filterBySegmentation = [\"segments\"]\n",
    "            s.layers['Base Segment Merger'].linkedSegmentationLayer = {\"segments\": 'base_segs'}\n",
    "            s.layers['Base Segment Merger'].annotationColor = '#ffa500'\n",
    "            s.layers['Base Segment Merger'].tool = \"annotatePoint\"\n",
    "\n",
    "            for pos, point in enumerate(self.cell_data['base_seg_merge_points']):\n",
    "\n",
    "                point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                pa = neuroglancer.PointAnnotation(id=f'bm_{pos}', point = point_array, segments=[[point[3]]])\n",
    "                s.layers['Base Segment Merger'].annotations.append(pa)                \n",
    "\n",
    "    def change_point(self):\n",
    "\n",
    "        if self.point_pos == len(self.point_types)-1:\n",
    "            self.point_pos = 0\n",
    "        else:\n",
    "            self.point_pos += 1\n",
    "\n",
    "        selected_layer = self.point_types[self.point_pos]\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            s.selectedLayer.layer = selected_layer\n",
    "            s.selected_layer.visible = True\n",
    "            s.layers[selected_layer].tab = 'Annotations'\n",
    "        \n",
    "        self.update_msg(f'Current Point Annotation Type (P): {selected_layer}', layer='current point type')\n",
    "\n",
    "    def change_cell_structure(self):\n",
    "     \n",
    "        if self.cell_structure_pos == len(self.cell_structures)-1:\n",
    "            self.cell_structure_pos = 0\n",
    "\n",
    "        else:\n",
    "            self.cell_structure_pos += 1\n",
    "            \n",
    "        self.update_msg(f'Current Cell Structure (C): {self.cell_structures[self.cell_structure_pos]}', layer='Current Cell Structure')\n",
    "            \n",
    "    def adjust_annotations_structures(self):\n",
    "        '''\n",
    "        when loading a cell from a file, add necessary annotations and structures if do not exist\n",
    "        '''     \n",
    "        \n",
    "        for p in self.point_types:\n",
    "            if p not in self.cell_data['end_points']:\n",
    "                self.cell_data['end_points'][p] = [] # create the entry for that annotation point\n",
    "        self.point_types = list(set(self.point_types + list(self.cell_data['end_points'].keys())))\n",
    "        self.point_types = [x for x in self.point_types if not ('base' in x.lower() and 'merge' in x.lower())]\n",
    "        \n",
    "        self.set_endpoint_annotation_layers() # reset annotations layers to include any adjustments\n",
    "\n",
    "        existing_struc = [x for x in self.cell_data['base_segments'].keys() if x!= 'unknown']\n",
    "        for dtype in self.cell_structures:\n",
    "            if dtype not in self.cell_data['base_segments'].keys():\n",
    "                self.cell_data['base_segments'][dtype] = set() # create the entry for that annotation point\n",
    "        self.cell_structures = list(set(self.cell_structures) | set(existing_struc))\n",
    "        \n",
    "        self.set_seg_colours() # reset colors for segments\n",
    "        \n",
    "    def set_endpoint_annotation_layers(self): \n",
    "\n",
    "        self.point_types = list(set(self.point_types + list(self.cell_data['end_points'].keys())))\n",
    "        self.point_types = [x for x in self.point_types if not ('base' in x.lower() and 'merge' in x.lower())]\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for point_type in self.point_types:\n",
    "\n",
    "                s.layers[point_type] = neuroglancer.AnnotationLayer()\n",
    "                \n",
    "                if point_type == 'post-synaptic':\n",
    "                    s.layers[point_type].annotationColor = '#ff00ff'\n",
    "                    s.layers[point_type].linkedSegmentationLayer = {\"segments\": 'base_segs'} # set it up linked to base_segs\n",
    "                elif point_type == 'pre-synaptic':\n",
    "                    s.layers[point_type].annotationColor = '#00EEEE'\n",
    "                    s.layers[point_type].linkedSegmentationLayer = {\"segments\": 'base_segs'} # set it up linked to base_segs\n",
    "                elif (point_type == 'natural end') | (point_type == 'exit volume'):\n",
    "                    s.layers[point_type].annotationColor = '#FFFF00'\n",
    "                elif point_type == 'uncertain':\n",
    "                    s.layers[point_type].annotationColor = '#EE0000'\n",
    "                else:\n",
    "                    s.layers[point_type].annotationColor = '#ffffff'\n",
    "\n",
    "                s.layers[point_type].tool = \"annotatePoint\"\n",
    "                s.layers[point_type].tab = 'Annotations'\n",
    "\n",
    "                # If data already exists for this point type:\n",
    "\n",
    "        self.load_annotation_layer_points()\n",
    "        \n",
    "    def load_annotation_layer_points(self):\n",
    "        \n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            for point_type in self.point_types:\n",
    "\n",
    "                # If data already exists for this point type:\n",
    "                if point_type in self.cell_data['end_points'].keys():\n",
    "\n",
    "                    for pos, point in enumerate(self.cell_data['end_points'][point_type]):\n",
    "\n",
    "                        if len(point)==3: # then there is no segment ID associated with the annotation point\n",
    "                        \n",
    "                            point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                            point_id = f'{point_type}_{pos}'\n",
    "                            pa = neuroglancer.PointAnnotation(id=point_id, point = point_array)\n",
    "                            s.layers[point_type].annotations.append(pa)\n",
    "\n",
    "                        if len(point)==4: # then include the segment ID with the annotation point\n",
    "                            point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                            point_id = f'{point_type}_{pos}'\n",
    "                            segment_id = point[3]\n",
    "                            pa = neuroglancer.PointAnnotation(id=point_id, point = point_array, segments = [[segment_id]])\n",
    "                            s.layers[point_type].annotations.append(pa)                     \n",
    "\n",
    "    def save_point_types_successfully(self):\n",
    "\n",
    "        for t in self.point_types:\n",
    "\n",
    "            this_type_points = []\n",
    "     \n",
    "            for x in self.viewer.state.layers[t].annotations:\n",
    "                if t == 'Base Segment Merger' and x.segments == None:\n",
    "                    c = [int(y) for y in x.point]\n",
    "                    self.update_mtab(f'Error, no segment for point {c}, for point layer {t}, correct and re-save', 'Cell Reconstruction')\n",
    "                    return False\n",
    "\n",
    "                else:\n",
    "                    co_ords = [float(x) for x in list(x.point)]\n",
    "                    co_ords_and_id = [co_ords[x]*self.vx_sizes['em'][x] for x in range(3)]\n",
    "\n",
    "                    if x.segments != None:\n",
    "                        if len(x.segments[0]) > 0:\n",
    "                            co_ords_and_id.append(str(x.segments[0][0]))\n",
    "\n",
    "                    this_type_points.append(co_ords_and_id)\n",
    "\n",
    "            if t == 'Base Segment Merger':\n",
    "                self.cell_data['base_seg_merge_points'] = this_type_points\n",
    "            else:\n",
    "                self.cell_data['end_points'][t] = this_type_points\n",
    "\n",
    "        return True                            \n",
    "\n",
    "    def set_seg_colours(self):\n",
    "        chosen_col = '#D2B48C'\n",
    "        self.chosen_seg_colours = {'unknown': '#D2B48C'} # tan\n",
    "\n",
    "        # acceptable_colours = set(['#FFFF00', '#800080', '#008000', '#FF00FF', '#00FF00', '#FF69B4', '#FF8C00'])\n",
    "        # used_colours = set()\n",
    "\n",
    "        for x in self.cell_structures:\n",
    "\n",
    "            # available_colours = acceptable_colours - used_colours\n",
    "\n",
    "            # if len(available_colours) == 0:\n",
    "            #     available_colours = acceptable_colours\n",
    "            \n",
    "            if x=='multiple':\n",
    "                chosen_col = '#9C661F' # white\n",
    "\n",
    "            if x=='axon':\n",
    "                chosen_col = '#008000' # green\n",
    "\n",
    "            if x=='dendrite':\n",
    "                chosen_col = '#FFFF00' # yellow\n",
    "\n",
    "            if x=='basal dendrite': # orange-red\n",
    "                chosen_col = '#CD4B00'\n",
    "\n",
    "            if x=='apical dendrite': # orange\n",
    "                chosen_col = '#FF8000'\n",
    "    \n",
    "            if x not in self.cell_data['base_segments'].keys():\n",
    "                chosen_col = '#708090' # if not one of the explicitly chosen structures, make it slate gray\n",
    "\n",
    "            # used_colours.add(chosen_col)\n",
    "            self.chosen_seg_colours[x] = chosen_col\n",
    "    \n",
    "    def import_base_segments(self,base_segments):\n",
    "        \n",
    "        '''\n",
    "        base_segments is the list of segments from neuroglancer json (which is why get put in \"unknown\")\n",
    "        '''\n",
    "        # Turn lists back to sets:\n",
    "        self.cell_data['base_segments']['unknown'] = set([str(x) for x in base_segments])\n",
    "                \n",
    "    \n",
    "    def create_pr_graph(self):\n",
    "\n",
    "        seg_id = self.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "        print(f'Creating base segment graph for cell {seg_id}', 'Cell Reconstruction')\n",
    "\n",
    "        all_base_segs = [str(a) for b in self.cell_data['base_segments'].values() for a in b]\n",
    "        \n",
    "        self.update_base_locations(all_base_segs)\n",
    "\n",
    "              \n",
    "        ####\n",
    "        # Correct base segment locations that got left out \n",
    "        '''td:\n",
    "        figure out why they are like this.\n",
    "        for example, for one the segment id returned '0' even though there was a location returned\n",
    "        '''\n",
    "        no_loc_base_segs = [str(x) for x in all_base_segs if x not in self.cell_data['base_locations']]\n",
    "        if no_loc_base_segs != []:\n",
    "            for s in no_loc_base_segs:\n",
    "                try:\n",
    "                    results_dict = self.get_locations_from_base_segs(s)\n",
    "                    k = list(results_dict.keys())[0] # get key for this segment ID in queried segment location\n",
    "                    self.cell_data['base_locations'][s] = self.get_corrected_xyz(results_dict[k], 'seg') # manually log its location with given segment ID\n",
    "                except: \n",
    "                    print(f'{s} actually no base segment location in SQL... will attach without location later')\n",
    "                    continue\n",
    "            self.cell_data['no_loc_base_segs'] = no_loc_base_segs # did not add this until after some conversions already done\n",
    "        ####\n",
    "        \n",
    "        \n",
    "        print(f'all base locations for {len(all_base_segs)} obtained from SQL database')\n",
    "        \n",
    "        possible_edges = []\n",
    "        agglo_segs_done = set()\n",
    "        base_segs_done = set()\n",
    "\n",
    "        for base_seg in all_base_segs:\n",
    "\n",
    "            if base_seg in base_segs_done: continue # if the base segment has been included, go to next\n",
    "            # if the base segment has not been included yet,\n",
    "\n",
    "            agglo_seg = self.get_agglo_seg_of_base_seg(base_seg) # get its agglomeration segment\n",
    "            children_base_segs = self.get_base_segs_of_agglo_seg(agglo_seg) # and all of the other base segments also in that agglo seg\n",
    "            base_segs_done.update(children_base_segs) # mark all of these base segments as included\n",
    "\n",
    "            if not agglo_seg in agglo_segs_done: # connect the agglomeration segment for those bases if it has not already been done\n",
    "\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg)\n",
    "\n",
    "                agglo_segs_done.add(agglo_seg)\n",
    "                possible_edges.extend(edges)\n",
    "\n",
    "        all_bs_set = set(all_base_segs)\n",
    "        possible_edges = [x for x in possible_edges if x[0] in all_bs_set] # only include edges between connect base segments in the reconstruction\n",
    "            # note that this is what probably creates so many disconnected clusters... if a base segment is missing from the agglo, \n",
    "            #then the edges from that segment will not be included and will need to be connected manually\n",
    "        chosen_edges = [x for x in possible_edges if x[1] in all_bs_set]\n",
    "\n",
    "        self.pr_graph = ig_Graph(directed=False)\n",
    "        self.pr_graph.add_vertices(all_base_segs)\n",
    "        self.pr_graph.add_edges(chosen_edges)\n",
    "\n",
    "        print('graph created among all_base_segs')\n",
    "        \n",
    "\n",
    "        self.add_cc_bridging_edges_pairwise()\n",
    "        print('weak clusters connected')\n",
    "        \n",
    "        self.attach_noloc_segs()\n",
    "        print('segments without a location connected')\n",
    "        \n",
    "        self.cell_data['graph_nodes'] = [x['name'] for x in self.pr_graph.vs]\n",
    "        self.cell_data['graph_edges'] = [(self.pr_graph.vs[x.source]['name'], self.pr_graph.vs[x.target]['name']) for x in self.pr_graph.es]\n",
    "\n",
    "\n",
    "        '''\n",
    "        # removed assertion of pr_graph.clusters==1 because importing from a neuroglancer json might \"break\" this and it is ok...\n",
    "        \n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1\n",
    "        '''\n",
    "        \n",
    "        n_clusters = len(self.pr_graph.clusters(mode='weak'))\n",
    "        \n",
    "        print(f'{n_clusters} clusters in graph (note should/would be only 1 if loaded base ID from agglomo fresh)')\n",
    "        \n",
    "        # self.assert_segs_in_sync()\n",
    "        \n",
    "        # print(f'successful assertion that graph segments and segments listed in base_segments match')\n",
    "        \n",
    "    def load_graph_from_celldata(self):\n",
    "\n",
    "        self.pr_graph = ig_Graph()\n",
    "        self.pr_graph.add_vertices(self.cell_data['graph_nodes'])\n",
    "        self.pr_graph.add_edges(self.cell_data['graph_edges'])\n",
    "        \n",
    "    def save_cell_graph(self, directory_path = None, file_name=None, save_to_cloud=False):\n",
    "        \n",
    "        timestamp = str(datetime.now())[:-7].replace(':','.')\n",
    "        main_base_id = self.cell_data['metadata']['main_seg']['base']\n",
    "                \n",
    "        cell_data = deepcopy(self.cell_data)\n",
    "\n",
    "        # Convert sets to lists for saving in json file:\n",
    "        for dtype in cell_data['base_segments'].keys():\n",
    "            cell_data['base_segments'][dtype] = list(cell_data['base_segments'][dtype])\n",
    "        \n",
    "        cell_data['removed_base_segs'] = list(cell_data['removed_base_segs'])\n",
    "        \n",
    "        cell_data['graph_nodes'] = [x['name'] for x in self.pr_graph.vs]\n",
    "        cell_data['graph_edges'] = [(self.pr_graph.vs[x.source]['name'], self.pr_graph.vs[x.target]['name']) for x in self.pr_graph.es]\n",
    "\n",
    "        completion_list = list(set(cell_data['metadata']['completion']))\n",
    "        completion_list.sort()\n",
    "        completion_string = ','.join(completion_list).replace('_', ' ')\n",
    "            \n",
    "        cell_data['metadata']['data_sources']['agglo'] = self.agglo_seg\n",
    "        \n",
    "        if directory_path==None:\n",
    "            directory_path = self.save_dir\n",
    "            \n",
    "        if file_name == None:\n",
    "            file_name = f'cell_graph_{main_base_id}_{completion_string}_{timestamp}.json'\n",
    "            \n",
    "#         with open(f'{self.save_dir}/{file_name}', 'w') as fp:\n",
    "#             json_dump(cell_data, fp)\n",
    "        with open(directory_path / file_name, 'w') as fp:\n",
    "            json.dump(cell_data, fp, indent=4)\n",
    "\n",
    "        print(f'Saved cell {main_base_id} reconstruction locally at {timestamp}')\n",
    "\n",
    "    def update_base_locations(self, seg_list):\n",
    "\n",
    "        seg_list = [x for x in seg_list if x not in self.cell_data['base_locations'].keys()]\n",
    "\n",
    "        result_dict = self.get_locations_from_base_segs(seg_list)\n",
    "\n",
    "        for r in result_dict:\n",
    "            self.cell_data['base_locations'][r] = self.get_corrected_xyz(result_dict[r], 'seg')\n",
    "\n",
    "    def get_locations_from_base_segs(self, base_segs, batch_size = 1000):\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        if len(base_segs) > 0:\n",
    "        \n",
    "            num_batches = int(len(base_segs)/batch_size)\n",
    "            \n",
    "            for batch in range(num_batches+1):\n",
    "\n",
    "                q = ','.join([str(x) for x in base_segs[batch*batch_size:(batch+1)*batch_size]])\n",
    "                \n",
    "                query = f\"\"\"SELECT seg_id, x, y, z FROM base_location WHERE seg_id IN ({q})\"\"\"\n",
    "\n",
    "                self.db_cursors.execute(query)\n",
    "\n",
    "                this_batch = {str(x[0]): (int(x[1]), int(x[2]), int(x[3])) for x in self.db_cursors.fetchall()}\n",
    "\n",
    "                results.update(this_batch)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_corrected_xyz(self, xyz, adj_key, rel_to_em=False):\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for pos, coord in enumerate(xyz):\n",
    "            result.append(coord*self.vx_sizes[adj_key][pos])\n",
    "            \n",
    "        if rel_to_em==True:\n",
    "            result = [int(result[x]/self.vx_sizes['em'][x]) for x in range(3)]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_agglo_seg_of_base_seg(self, base_seg):\n",
    "\n",
    "        base_seg = str(base_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT agglo_id FROM agglo_base_resolved WHERE base_id = {base_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        agglo_segs = [str(x[0]) for x in self.db_cursors.fetchall()]\n",
    "\n",
    "        assert len(agglo_segs) <= 1\n",
    "\n",
    "        if agglo_segs == []:\n",
    "            return base_seg\n",
    "        else:\n",
    "            return agglo_segs[0]\n",
    "\n",
    "    def get_base_segs_of_agglo_seg(self, agglo_seg):\n",
    "\n",
    "        agglo_seg = str(agglo_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT base_id FROM agglo_base_resolved WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        base_segs = [str(x[0]) for x in self.db_cursors.fetchall()]\n",
    "        base_segs.append(agglo_seg)\n",
    "\n",
    "        return base_segs\n",
    "\n",
    "    def get_edges_from_agglo_seg(self, agglo_seg):\n",
    "\n",
    "        agglo_seg = str(agglo_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT label_a, label_b FROM agglo_to_edges WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        edges = [(str(x[0]), str(x[1])) for x in self.db_cursors.fetchall()]\n",
    "\n",
    "        return edges\n",
    "    \n",
    "    def add_cc_bridging_edges_pairwise(self):\n",
    "        \n",
    "        '''\n",
    "        con_comms = \"connected components\" abbreviation\n",
    "        '''\n",
    "\n",
    "        con_comms = list(self.pr_graph.clusters(mode='weak'))\n",
    "        print(f'{len(con_comms)} clusters of connected components. Connecting these clusters with nearest base segments.')\n",
    "        while len(con_comms) > 1:\n",
    "\n",
    "            candidate_edges = []\n",
    "\n",
    "            for cc1, cc2 in combinations(con_comms, 2): # gets all possible pairwise combinations between segments\n",
    "                \n",
    "                # get the name of each base segment\n",
    "                cc1_base_segs = [self.pr_graph.vs[x]['name'] for x in cc1]\n",
    "                cc2_base_segs = [self.pr_graph.vs[x]['name'] for x in cc2]\n",
    "\n",
    "                cc1_list = [x for x in cc1_base_segs if x in self.cell_data['base_locations']]\n",
    "                cc2_list = [x for x in cc2_base_segs if x in self.cell_data['base_locations']]\n",
    "\n",
    "                if cc1_list == [] or cc2_list == []:\n",
    "                    continue\n",
    "\n",
    "                sel_cc1, sel_cc2, dist = self.get_closest_dist_between_ccs(cc1_list, cc2_list)\n",
    "                candidate_edges.append([sel_cc1, sel_cc2, dist])\n",
    "\n",
    "            if candidate_edges == []: \n",
    "                return\n",
    "\n",
    "            origin, target, dist = min(candidate_edges, key = lambda x: x[2])\n",
    "\n",
    "            self.pr_graph.add_edges([(origin, target)])\n",
    "            self.cell_data['added_graph_edges_pre_proofreading'].append([origin, target, dist])\n",
    "#             self.update_mtab(f'Added an edge between segments {origin} and {target}, {dist} nm apart', 'Cell Reconstruction')\n",
    "\n",
    "            con_comms = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "    def get_closest_dist_between_ccs(self, cc1_node_list, cc2_node_list):\n",
    "\n",
    "        cc1_node_locs = [self.cell_data['base_locations'][x] for x in cc1_node_list]\n",
    "        cc2_node_locs = [self.cell_data['base_locations'][x] for x in cc2_node_list]\n",
    "\n",
    "        f = cdist(cc1_node_locs, cc2_node_locs, 'euclidean')\n",
    "\n",
    "        min_indices = unravel_index(argmin(f, axis=None), f.shape)\n",
    "\n",
    "        sel_cc1 = cc1_node_list[min_indices[0]]\n",
    "        sel_cc2 = cc2_node_list[min_indices[1]]\n",
    "        dist = int(f[min_indices])  \n",
    "\n",
    "        return sel_cc1, sel_cc2, dist\n",
    "            \n",
    "    def attach_noloc_segs(self):\n",
    "        ''' NOTE that this does not run (it returns) if self.pr_graph.clusters(mode='weak') == 1\n",
    "        This is a case that is asserted in oringinal CREST.py in '''\n",
    "        \n",
    "        # For isolated segments without locations, attach to largest connected component:\n",
    "        remaining_cc = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "        if len(remaining_cc) == 1: return\n",
    "\n",
    "        if len(remaining_cc) > 1:\n",
    "            no_loc_base_segs = set([x['name'] for x in self.pr_graph.vs if x['name'] not in self.cell_data['base_locations']])\n",
    "            largest_cc = max(remaining_cc, key = lambda x: len(x))\n",
    "\n",
    "            '''\n",
    "            #### Raises TypeError: unsupported operand type(s) for &: 'list' and 'set'\n",
    "            for cc in remaining_cc:\n",
    "                no_loc_this_cc = cc & no_loc_base_segs\n",
    "                if cc != largest_cc and no_loc_this_cc != set():\n",
    "                    rand_seg1 = random_choice(list(no_loc_this_cc))\n",
    "                    rand_seg2 = random_choice(list(largest_cc))\n",
    "                    self.pr_graph.add_edges([(rand_seg1, rand_seg2)])\n",
    "                    self.cell_data['added_graph_edges_pre_proofreading'].append([rand_seg1, rand_seg2, 'unknown'])\n",
    "#                     print(f'Added an edge between segments {rand_seg1} and {rand_seg2}', 'Cell Reconstruction')\n",
    "            '''\n",
    "            # I think the following block replaces the commented out above with the correct intension?\n",
    "            nodes_names = [x['name'] for x in self.pr_graph.vs]\n",
    "            for cc in remaining_cc:\n",
    "                # no_loc_this_cc = cc & no_loc_base_segs # raises TypeError: unsupported operand type(s) for &: 'list' and 'set'\n",
    "                no_loc_this_cc = set([nodes_names[i] for i in remaining_cc[1]])& set(no_loc_base_segs) # I think this is what Alex was going for?\n",
    "                if cc != largest_cc and no_loc_this_cc != set():\n",
    "                    rand_seg1 = random_choice(list(no_loc_this_cc))\n",
    "                    rand_seg2 = random_choice(list(largest_cc))\n",
    "                    self.pr_graph.add_edges([(rand_seg1, rand_seg2)])\n",
    "                    self.cell_data['added_graph_edges_pre_proofreading'].append([rand_seg1, rand_seg2, 'unknown'])\n",
    "            #                     print(f'Added an edge between segments {rand_seg1} and {rand_seg2}', 'Cell Reconstruction')\n",
    "\n",
    "\n",
    "    def assert_segs_in_sync(self, return_segs=False):\n",
    "        \n",
    "        displayed_segs = set([str(x) for x in self.viewer.state.layers['base_segs'].segments])\n",
    "        graph_segs = set([x['name'] for x in self.pr_graph.vs])\n",
    "        listed_segs = set([a for b in [self.cell_data['base_segments'][cs] for cs in self.cell_data['base_segments'].keys()] for a in b])\n",
    "\n",
    "        assert listed_segs == graph_segs\n",
    "\n",
    "        if not displayed_segs == graph_segs:\n",
    "            self.update_displayed_segs()\n",
    "        \n",
    "\n",
    "        if return_segs:\n",
    "            return displayed_segs\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        \n",
    "    def get_ds_segs_of_certain_col(self, base_seg, colour):\n",
    "\n",
    "        ds = self.get_downstream_base_segs(base_seg)[0]\n",
    "\n",
    "        # If any of the downstream segments doesn't have a colour, set it to tan:\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in ds:\n",
    "                if int(bs) not in s.layers['base_segs'].segment_colors.keys():\n",
    "                    s.layers['base_segs'].segment_colors[int(bs)] = '#D2B48C'\n",
    "\n",
    "            ds = set([x for x in ds if s.layers['base_segs'].segment_colors[int(x)] == colour])\n",
    "        \n",
    "        return ds\n",
    "\n",
    "    def update_displayed_segs(self):\n",
    "\n",
    "        displayed_segs = set([str(x) for x in self.viewer.state.layers['base_segs'].segments])\n",
    "        listed_segs = set([x for y in self.cell_data['base_segments'].values() for x in y])\n",
    "        graph_segs = set([x['name'] for x in self.pr_graph.vs])\n",
    "\n",
    "        assert listed_segs == graph_segs\n",
    "\n",
    "        # Identify segments that failed to be removed from the viewer:\n",
    "        segs_to_remove = displayed_segs - listed_segs\n",
    "\n",
    "        # Identify segments that failed to be added to the viewer:\n",
    "        missing_segs = listed_segs - displayed_segs\n",
    "        # missing_focus_segs = self.focus_seg_set - set([str(x) for x in self.viewer.state.layers['focus_segs'].segments])\n",
    "\n",
    "        if not missing_segs == set():\n",
    "            # Correct the viewer:\n",
    "            with self.viewer.txn(overwrite=True) as s:\n",
    "                \n",
    "                layer = 'base_segs'\n",
    "            \n",
    "                for bs in missing_segs:\n",
    "                    s.layers[layer].segment_colors[int(bs)] = '#D2B48C'\n",
    "                    s.layers[layer].segments.add(int(bs)) \n",
    "\n",
    "                for bs in segs_to_remove:\n",
    "                    if int(bs) in s.layers[layer].segments:\n",
    "                        s.layers[layer].segments.remove(int(bs))\n",
    "                            \n",
    "    def add_or_remove_seg(self, action_state):  \n",
    "\n",
    "        rel_layer = 'base_segs'\n",
    "        \n",
    "        base_seg = self.check_selected_segment(rel_layer, action_state, banned_segs = [self.cell_data['anchor_seg']])\n",
    "\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        # Otherwise, add or remove to main layer:\n",
    "        \n",
    "        displayed_segs = self.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        if base_seg in displayed_segs:\n",
    "\n",
    "            self.remove_downstream_base_segs(base_seg)\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "            # Adding a segment:\n",
    "\n",
    "            agglo_seg = self.check_selected_segment('agglo', action_state)\n",
    "  \n",
    "            if agglo_seg == 'None': return\n",
    "\n",
    "            constituent_base_ids = self.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {self.max_num_base_added}')\n",
    "\n",
    "            if len(constituent_base_ids) > self.max_num_base_added:\n",
    "                base_ids = [base_seg]\n",
    "                #self.large_agglo_segs.add(agglo_seg)\n",
    "            else:\n",
    "                base_ids = constituent_base_ids\n",
    "\n",
    "            current_segs = self.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "            num_base_segs_this_agglo_seg = len(base_ids)\n",
    "            base_ids = [x for x in base_ids if x not in current_segs]\n",
    "            num_base_segs_not_already_included = len(base_ids)\n",
    "\n",
    "            if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "                base_ids = [x for x in base_ids if x not in self.cell_data['removed_base_segs']]\n",
    "\n",
    "                if not base_seg in base_ids:\n",
    "                    base_ids.append(base_seg)\n",
    "    \n",
    "            self.update_base_locations(base_ids)\n",
    "            self.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "            if len(base_ids) > 1:\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg)\n",
    "                edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "                self.pr_graph.add_edges(edges)\n",
    "\n",
    "            join_msg = self.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "\n",
    "            # Update lists of base segments and displayed segs:\n",
    "            self.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "\n",
    "            with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "                for bs in base_ids:\n",
    "                    s.layers['base_segs'].segment_colors[int(bs)] = '#D2B48C'\n",
    "                    s.layers['base_segs'].segments.add(int(bs))\n",
    "\n",
    "\n",
    "            self.update_displayed_segs() \n",
    "            self.assert_segs_in_sync()\n",
    "\n",
    "            print(f'Added {len(base_ids)} base segments from agglomerated segment {agglo_seg}{join_msg}')\n",
    "\n",
    "    def remove_downstream_base_segs(self, base_seg):\n",
    "\n",
    "        segs_to_remove, n_con_com = self.get_downstream_base_segs(base_seg)\n",
    "\n",
    "        self.assert_segs_in_sync()\n",
    "\n",
    "        # Remove from lists and segmentation layer:\n",
    "        for cs in self.cell_data['base_segments'].keys():\n",
    "            self.cell_data['base_segments'][cs] -= set(segs_to_remove)\n",
    "\n",
    "        self.pr_graph.delete_vertices(segs_to_remove)\n",
    "        # self.focus_seg_set -= set(segs_to_remove)\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in segs_to_remove:\n",
    "\n",
    "                if int(bs) in s.layers['base_segs'].segments:\n",
    "                    s.layers['base_segs'].segments.remove(int(bs))\n",
    "\n",
    "        self.assert_segs_in_sync()\n",
    "            \n",
    "        self.cell_data['removed_base_segs'].update(set(segs_to_remove))\n",
    "        print(f'{len(segs_to_remove)} base segments removed from {n_con_com} connected components')\n",
    "        self.cell_data['added_graph_edges'] = [x for x in self.cell_data['added_graph_edges'] if (x[0] not in segs_to_remove) and (x[1] not in segs_to_remove)]\n",
    "\n",
    "    def get_downstream_base_segs(self, base_seg):\n",
    "\n",
    "        edge_backup = [(self.pr_graph.vs[p_ix]['name'], base_seg) for p_ix in self.pr_graph.neighbors(base_seg)]\n",
    "\n",
    "        self.pr_graph.delete_vertices([base_seg])\n",
    "\n",
    "        current_cc = list(self.pr_graph.clusters(mode='weak'))\n",
    "        current_cc_seg_ids = [[self.pr_graph.vs[i]['name'] for i in c] for c in current_cc]\n",
    "        ccs_to_remove = [cc for cc in current_cc_seg_ids if self.cell_data['anchor_seg'] not in cc]\n",
    "        segs_to_remove = [str(x) for y in ccs_to_remove for x in y if str(x) != '0']\n",
    "        segs_to_remove.append(base_seg)\n",
    "\n",
    "        self.pr_graph.add_vertices([base_seg])\n",
    "        self.pr_graph.add_edges(edge_backup)\n",
    "\n",
    "        return segs_to_remove, len(current_cc)\n",
    "    \n",
    "    def add_closest_edge_to_graph(self, new_segs, seg_to_link):\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 2\n",
    "\n",
    "        # Some segments do not have locations recorded:\n",
    "        current_cell_node_list = [x['name'] for x in self.pr_graph.vs if x['name'] not in new_segs]\n",
    "        current_cell_node_list = [x for x in current_cell_node_list if x in self.cell_data['base_locations']]\n",
    "        \n",
    "        # Then determine new segments that are acceptable as partners\n",
    "        if seg_to_link in self.cell_data['base_locations'].keys():\n",
    "            new_segs = [seg_to_link]\n",
    "        else:\n",
    "            new_segs = [x for x in new_segs if x in self.cell_data['base_locations']]\n",
    "\n",
    "        sel_curr, sel_new, dist = self.get_closest_dist_between_ccs(current_cell_node_list, new_segs)\n",
    "        \n",
    "        self.pr_graph.add_edges([(sel_curr, sel_new)])\n",
    "        self.cell_data['added_graph_edges'].append([sel_curr, sel_new, dist])\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1     \n",
    "\n",
    "        return f', linked base segments {sel_curr} and {sel_new}, {round(dist)}nm apart, '\n",
    "\n",
    "    def resolving_seg_overlap(self):\n",
    "\n",
    "        for p1, p2 in combinations(self.cell_data['base_segments'].keys(), 2):\n",
    "\n",
    "            common_segments = set(self.cell_data['base_segments'][p1]) & set(self.cell_data['base_segments'][p2])\n",
    "\n",
    "            if common_segments != set():\n",
    "\n",
    "                self.update_mtab(f\"Base segments {common_segments} are present in both {p1} and {p2} layers, moving to 'unknown'\", 'Cell Reconstruction')\n",
    "\n",
    "                for dtype in p1, p2:\n",
    "                    if dtype != 'unknown':\n",
    "                        self.cell_data['base_segments'][dtype] -= common_segments\n",
    "\n",
    "                self.cell_data['base_segments']['unknown'].update(common_segments)\n",
    "\n",
    "    def mark_branch_in_colour(self, action_state):\n",
    "\n",
    "        base_seg = self.check_selected_segment('base_segs', action_state, banned_segs = [self.cell_data['anchor_seg']])\n",
    "\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        if base_seg not in [x['name'] for x in self.pr_graph.vs]:\n",
    "            print(f'Base segment {base_seg} was not in the base segment graph, updating displayed segments ...')\n",
    "            self.update_displayed_segs()\n",
    "            return\n",
    "\n",
    "        col = self.viewer.state.layers['base_segs'].segment_colors\n",
    "\n",
    "        if int(base_seg) not in col.keys(): return\n",
    "\n",
    "        current_colour = col[int(base_seg)]\n",
    "        downstream_segs = self.get_ds_segs_of_certain_col(base_seg, current_colour)\n",
    "\n",
    "        if current_colour != '#D2B48C':\n",
    "            cell_part = 'unknown'\n",
    "        else:\n",
    "            cell_part = self.cell_structures[self.cell_structure_pos]\n",
    "        \n",
    "        new_colour = self.chosen_seg_colours[cell_part]\n",
    "\n",
    "        for cs in self.cell_data['base_segments'].keys():\n",
    "\n",
    "            if cs == cell_part:\n",
    "                self.cell_data['base_segments'][cs].update(downstream_segs)\n",
    "            else:\n",
    "                self.cell_data['base_segments'][cs] -= downstream_segs\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            for bs in downstream_segs:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = new_colour\n",
    "\n",
    "    def check_selected_segment(self, layer, action, banned_segs = [], acceptable_segs='all'):\n",
    "\n",
    "        if layer not in action.selectedValues: \n",
    "            return 'None'\n",
    "\n",
    "        selected_segment = str(action.selected_values.get(layer).value)\n",
    "        banned_segs.extend(['None', '0'])\n",
    "\n",
    "        if selected_segment in banned_segs:\n",
    "            return 'None'\n",
    "        else:\n",
    "            if acceptable_segs != 'all':\n",
    "                if selected_segment not in acceptable_segs:\n",
    "                    print(f'Segment {selected_segment} not in current graph')\n",
    "                    return 'None'\n",
    "\n",
    "            return selected_segment\n",
    "        \n",
    "    def change_anchor_seg(self, action_state):  \n",
    "\n",
    "        base_seg = self.check_selected_segment('base_segs', action_state, banned_segs=[self.cell_data['anchor_seg']])\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            s.layers['base_segs'].segment_colors[int(self.cell_data['anchor_seg'])] = '#D2B48C'\n",
    "            s.layers['base_segs'].segment_colors[int(base_seg)] = '#1e90ff'\n",
    "            \n",
    "        self.cell_data['anchor_seg'] = deepcopy(base_seg)\n",
    "        \n",
    "    def change_view(self, location, css=None, ps=None):\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            dimensions = neuroglancer.CoordinateSpace(\n",
    "                scales=self.vx_sizes['em'],\n",
    "                units='nm',\n",
    "                names=['x', 'y', 'z']   )\n",
    "\n",
    "            s.showSlices = False\n",
    "            s.dimensions = dimensions\n",
    "            s.position = array(location)\n",
    "            s.layout = \"xy-3d\"\n",
    "\n",
    "            if css != None:\n",
    "                s.crossSectionScale = css\n",
    "            \n",
    "            if ps != None:\n",
    "                s.projectionScale = ps\n",
    "                \n",
    "    def reset_seg_pr_layers(self, two_d_intensity = 0.5):\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            s.layers['em'] = neuroglancer.ImageLayer(source = self.em)\n",
    "\n",
    "            s.layers['agglo'] = neuroglancer.SegmentationLayer(source = self.agglo_seg, segment_colors={})\n",
    "            s.layers['agglo'].pick = False\n",
    "            s.layers['agglo'].visible = True\n",
    "            s.layers['agglo'].ignoreNullVisibleSet = False\n",
    "            s.layers['agglo'].selectedAlpha = two_d_intensity\n",
    "            s.layers['agglo'].objectAlpha = 1.00\n",
    "            \n",
    "            all_segs = [a for b in self.cell_data['base_segments'].values() for a in b]\n",
    "\n",
    "            s.layers['base_segs'] = neuroglancer.SegmentationLayer(source = self.base_seg, segments=all_segs, segment_colors={})\n",
    "            s.layers['base_segs'].ignoreNullVisibleSet = False\n",
    "            s.layers['base_segs'].pick = False\n",
    "            s.layers['base_segs'].selectedAlpha = two_d_intensity #For 2D\n",
    "\n",
    "            for dtype in self.cell_data['base_segments'].keys():\n",
    "\n",
    "                for seg in self.cell_data['base_segments'][dtype]:\n",
    "                    s.layers['base_segs'].segment_colors[int(seg)] = self.chosen_seg_colours[dtype]\n",
    "\n",
    "            s.layers['base_segs'].segment_colors[int(self.cell_data['anchor_seg'])] = '#1e90ff'\n",
    "\n",
    "    def import_annotations(self,neuroglancer_data, neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "        for n, c in zip(neuroglancer_layer_name,crest_layer_name):\n",
    "            \n",
    "            # get the 'layers' dictionary that has that name\n",
    "\n",
    "            neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == n), None)\n",
    "\n",
    "            # create the annotation list for CREST and put it into cell_data\n",
    "\n",
    "            annotation_list = []\n",
    "\n",
    "            for v in neuroglancer_layer['annotations']:\n",
    "                # print(v)\n",
    "                corrected_location = self.get_corrected_xyz(v['point'], 'seg')\n",
    "\n",
    "                if 'segments' not in v.keys():\n",
    "                    annotation_list.extend([corrected_location])\n",
    "                if 'segments' in v.keys():\n",
    "                    annotation_list.extend([corrected_location + v['segments'][0]])\n",
    "\n",
    "            self.cell_data['end_points'][c].extend(annotation_list)\n",
    "\n",
    "    def define_ctype(self,ctype, method):\n",
    "        '''\n",
    "        method = \"manual\" or \"auto\" \n",
    "        ctype = \"lg/lf/mg1/mg2/mgx/gc/mli/uk...\"\n",
    "        '''\n",
    "        try:\n",
    "            self.cell_data['metadata']['cell-type'][method] = ctype\n",
    "        except KeyError:\n",
    "            self.cell_data['metadata']['cell-type']={'auto':'','manual':''}\n",
    "            self.cell_data['metadata']['cell-type'][method] = ctype\n",
    "\n",
    "    def get_ctype(self,method):\n",
    "        '''\n",
    "        method = \"manual\" or \"auto\" \n",
    "        '''\n",
    "        ctype = ''\n",
    "        \n",
    "        try:\n",
    "            ctype = self.cell_data['metadata']['cell-type'][method]\n",
    "        except KeyError:\n",
    "            self.cell_data['metadata']['cell-type']={'auto':'','manual':''}\n",
    "\n",
    "        try:\n",
    "            ctype = self.cell_data['metadata']['cell-type'][method]\n",
    "        except Exception:\n",
    "            print('cell type not defined for this cell yet -- use cell_type.define(ctype,method)')\n",
    "\n",
    "        return ctype\n",
    "    \n",
    "def import_settings(dict_json):\n",
    "    with open(dict_json, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "        settings_dict=myfile.read()\n",
    "        settings_dict = json.loads(settings_dict)\n",
    "    return settings_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c2185-2363-4dd2-a4ec-ed4c691e794b",
   "metadata": {},
   "source": [
    "### Import settings\n",
    "\n",
    "If you save a copy of settings_dict.json (found in the \"under construction\" directory of eCREST repo) locally somewhere outside the repo (like in your save_dir), then you can use the following code cell to import. This avoids needing to re-type the save_dir and db_path each time you \"git pull\" updates from the repo to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e594867-f9ad-4514-aae8-78127c6afb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee76f1-7249-4add-9d08-ebba36c4d6c9",
   "metadata": {},
   "source": [
    "## Build connectivity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66307f56-b982-42bf-acf6-2f878db555d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"/Volumes/GoogleDrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2aad7187-2ce8-4145-9a73-8920508de0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [child.name.split('_')[2] for child in sorted(Path(dirpath).iterdir()) \n",
    "         if (child.name[0]!='.') & (child.is_file())] # ignore hidden files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0067d9f0-3b06-4352-ba0b-9c7ad87e9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefiles = dict()\n",
    "for child in sorted(Path(dirpath).iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3ca4fa4-40af-4f4d-8e5a-2e0b811bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ell = ig_Graph() \n",
    "ell.add_vertices(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab17c50-b195-4950-99ae-6d2c25d2a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cell types to each node\n",
    "for x in ell.vs:\n",
    "    cell = ecrest(settings_dict,filepath = nodefiles[x['name']],launch_viewer=False)\n",
    "    x['cell-type'] = cell.get_ctype('manual') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15fc2a93-da06-47c1-befe-833fc81beb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = ecrest(settings_dict,filepath = nodefiles['653504340'],launch_viewer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "193df9da-5b95-4e86-a48c-e3219a2e2334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown\n",
      "654649292\n",
      "cell body\n",
      "axon\n",
      "basal dendrite\n",
      "apical dendrite\n"
     ]
    }
   ],
   "source": [
    "for k,v in cell.cell_data['base_segments'].items():\n",
    "    print(k)\n",
    "    try: print(list(v)[0])\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9bb3def5-7344-49d0-9136-c45abf4ee241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622663cb-0f17-427c-93f6-020f719f4676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305332461 'post-synaptic'\n"
     ]
    }
   ],
   "source": [
    "## find edges and set the cell-structure attribute of the edge based on which part of the cell the edge goes to\n",
    "edge_list = []\n",
    "# for each node,\n",
    "for x_pre in ell.vs:\n",
    "# x_pre = ell.vs.find('128473437')\n",
    "\n",
    "    # if the node has post-synaptic annotations (the current cell is assumed pre-synaptic)\n",
    "    pre = ecrest(settings_dict,filepath = nodefiles[x_pre['name']],launch_viewer=False)\n",
    "    try:\n",
    "        pre.cell_data['end_points']['post-synaptic'] != []\n",
    "        \n",
    "        # for each synapse\n",
    "        for syn_ in pre.cell_data['end_points']['post-synaptic']:\n",
    "            post_seg = syn_[3]\n",
    "\n",
    "            # go through each other nodes\n",
    "            for x_post in ell.vs:\n",
    "            # x_post = ell.vs.find('387368998')\n",
    "\n",
    "                post = ecrest(settings_dict,filepath = nodefiles[x_post['name']],launch_viewer=False)\n",
    "\n",
    "\n",
    "                for k,v in post.cell_data['base_segments'].items():\n",
    "\n",
    "                    for v_ in list(v): #find keys (can be multiple on the same cell) for matching segment ids\n",
    "                        \n",
    "                        if post_seg == v_: \n",
    "\n",
    "                        # add edge to the graph between current node and matching node\n",
    "                            edge_list.append([x_pre['name'],x_post['name'],k])\n",
    "\n",
    "                        # what happens if the edge already exists? can you \"add another\" or does the \"strength\" attribute increase?\n",
    "\n",
    "                        # set edge attribute for cell structure of edge\n",
    "\n",
    "                        # ****HOW MAKE THIS DIRECTED?\n",
    "\n",
    "    except Exception as msg:\n",
    "        print(x_pre['name'],msg)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e09af-0d16-4613-bc84-129a97ed1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7414c7-1d86-46a7-be25-45a1ba8a5159",
   "metadata": {},
   "source": [
    "## GET most recent files (by filename date) in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92ae0f-6fb5-4440-ae11-8ada737d782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'C:/Users/mpetkova/Dropbox/U19_zebrafish/EMfullres/LateralLineCurlDetector/CREST/right_afferents/'\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/EngertLab/Dropbox/CREST/mariela_fish_credentials.json'\n",
    "\n",
    "names = os.listdir(dirname);\n",
    "cellid_filename=list();\n",
    "for ind in range(len(names)):\n",
    "    content = names[ind].split('_')\n",
    "    if ('cell' in content):\n",
    "        cellid_filename.append(names[ind])\n",
    "d={}\n",
    "for name in cellid_filename:\n",
    "    ID,content_type,date=name.split('_')[2], name.split('_')[0], name.split('_')[-1]\n",
    "    date=date[:-5]\n",
    "    #create entry in dict which holds ID, file type (ex: cell_graph) and file path\n",
    "    if ID not in d:\n",
    "        d[ID]=[date, name]\n",
    "        #if there are multiple files with the same ID, keep the info for the newest one\n",
    "    else:\n",
    "        if date>d[ID][0]:\n",
    "            d[ID][0]=date\n",
    "            d[ID][1]=name\n",
    "            \n",
    "############################################################################################################################ \n",
    "# Collect all the base segments for each ID\n",
    "import json\n",
    "\n",
    "base_segs = {}\n",
    "\n",
    "for key in d.keys():\n",
    "    f = open(dirname+d[key][1])\n",
    "    data = json.load(f)\n",
    "    base_segs[key]=sum(data['base_segments'].values(),[])\n",
    "    f.close()\n",
    "\n",
    "############################################################################################################################ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e827d5e-6818-4ac7-ad95-8c231650e7d6",
   "metadata": {},
   "source": [
    "## Anatomical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed8e96-377a-4a21-9eb3-b3a462d669e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
