{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad326bee-88d1-4c8a-b521-c31f2244dbfb",
   "metadata": {},
   "source": [
    "# Proofread in eCREST\n",
    "\n",
    "The files generated by this script will also be able to be opened in CREST original (though some information may be lost if using original CREST.py or .exe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b4d1a-b07e-40b3-a362-e3a7dcc1d64c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Do the following two setup steps regardless of how you will be using this script. \n",
    "\n",
    "### 1. Imports\n",
    "\n",
    "Run the following code cell to import the necessary packages and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73173909-7e4c-4e66-9216-ec31ae11d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean,unique,nan\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new\n",
    "import neuroglancer\n",
    "\n",
    "# from eCREST_cli_beta import ecrest, import_settings\n",
    "from eCREST_cli import ecrest, import_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c555f-bd8a-4922-85e1-50aaf8ec727a",
   "metadata": {},
   "source": [
    "The 'ecrest' class has been imported from eCREST_cli.py\n",
    "\n",
    "An instance of this object will be able to:\n",
    "- open an neuroglancer viewer for proofrieading (see \"Proofread using CREST\")\n",
    "    - add-remove segments (using graph feature for efficiency)\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "- convert from neuroglancer json (see \"Convert From Neuroglancer to eCREST\")\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc18eab-9366-478a-bfbc-0e3bb4eef890",
   "metadata": {},
   "source": [
    "# USING THE CREST_JSON class\n",
    "\n",
    "## Settings definitions\n",
    "\n",
    "Whether you are converting from neuroglancer or creating a new reconstruction, the settings_dict parameters is needed to create CREST json files with correct formatting. \n",
    "- 'save_dir' : the directory where JSON files are saved \n",
    "- 'cred' and 'db_path' : specify the path to the agglomeration database file on your local computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac738a5-547a-40b9-aa5c-a606b15f690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {\n",
    "    'save_dir' : '/Users/kperks/Documents/eCREST-local-files/in-progress',\n",
    "    'db_path' : '/Users/kperks/Documents/eCREST-local-files/Mariela_bigquery_exports_agglo_v230111c_16_crest_proofreading_database.db',\n",
    "    'max_num_base_added' : 1000,\n",
    "    'cell_structures' : ['unknown','axon', 'basal dendrite', 'apical dendrite', 'dendrite', 'multiple'],\n",
    "    'annotation_points' : ['exit volume', 'natural end', 'uncertain', 'pre-synaptic', 'post-synaptic']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322d51a-097d-4f63-9ade-5dc59cb06a85",
   "metadata": {},
   "source": [
    "### Import settings\n",
    "\n",
    "If you save a copy of settings_dict.json (found in the \"under construction\" directory of eCREST repo) locally somewhere outside the repo (like in your save_dir), then you can use the following code cell to import. This avoids needing to re-type the save_dir and db_path each time you \"git pull\" updates from the repo to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d6360-08db-4cc2-addf-07b7b17e057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27a53c-cb5c-41e1-a4e1-afed0def0c65",
   "metadata": {},
   "source": [
    "## Proofread using eCREST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8a391-2d53-4f44-be0b-a85e483820a2",
   "metadata": {},
   "source": [
    "### 1. Create a crest_json object that launches a proofreading instance of neuroglancer\n",
    "\n",
    "\n",
    "Initialize with either:\n",
    "- (segment_id, segment_list): the main_base_id from the neuroglancer file you are converting and a list of base_segments.\n",
    "- (segment_id): a \"main_base_id\"\n",
    "- (filepath): an existing CREST json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7213e13-c449-4dc8-aa01-866afa9f41f1",
   "metadata": {},
   "source": [
    "#### NEW reconstruction from segment ID\n",
    "\n",
    "If you wanted to start reconstructing a new cell from a main base segment, \n",
    "you would use the following code block to launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642dbb6c-5350-4ff2-915b-7e0c7fac799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 41501459#  # a manageable afferent\n",
    "crest = ecrest(settings_dict,segment_id = segment_id, launch_viewer=True)\n",
    "# viewer_object = crest.neuroglancer_viewer()\n",
    "# crest.load_to_viewer()\n",
    "\n",
    "'''\n",
    "If you want to change keybindings for functions:\n",
    "'''\n",
    "with crest.viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "    print(s.input_event_bindings.data_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a8d58-0251-453c-8fe4-4733b6e84a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crest.max_num_base_added=2000\n",
    "crest.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36395436-5951-4246-8dee-a5ba9e100643",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### EDIT reconstruction from file\n",
    "\n",
    "If you wanted to edit a reconstruction from an existing file, \n",
    "you would use the following code block to launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3051f-8143-4a48-af15-f42fde741fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir'])\n",
    "\n",
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8db1b7-8f3c-4256-9e9d-3de4a2695dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "['', '', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6cdb2-a72f-4522-b3d5-9514ea0980e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest = ecrest(settings_dict,filepath= nodefiles['214613070'], launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f5268-5b69-4dbc-8df5-666c1e91334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = Path(settings_dict['save_dir']) /'todo_presynaptic/mg2_214581797'\n",
    "len([child for child in todo.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7201ab5b-2b74-4379-9e7a-d07562f99970",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) /'todo_presynaptic/mg2_214581797' #/ 'kp/482680782_grc'##/ 'todo_postsynaptic_sg' #\n",
    "filename = 'cell_graph_210034272__2023-07-15 09.50.19.json'#'cell_graph_306242528__2023-06-26 09.26.24.json'\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)\n",
    "\n",
    "\n",
    "'''\n",
    "If you want to change keybindings for functions:\n",
    "'''\n",
    "with crest.viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "    print(s.input_event_bindings.data_view)\n",
    "\n",
    "# # crest.cell_data['removed_base_segs']=set()\n",
    "crest.max_num_base_added=1500\n",
    "\n",
    "# crest.cell_data['removed_base_segs']=set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3a02a-9689-4430-a46c-4bd626ef1b55",
   "metadata": {},
   "source": [
    "## check for duplicates (single cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfa41ab-c574-44ad-b30b-f777aa4eeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segments_net = crest.get_base_segments_dict(Path(settings_dict['save_dir']))\n",
    "# base_segments_kp = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'kp/482680782_grc')\n",
    "base_segments_mg1 = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_postsynaptic_sg')\n",
    "base_segments_aff = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_afferent')\n",
    "base_segments_mg2_p = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_presynaptic/mg2_214581797')\n",
    "base_segments_mg1_p = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_presynaptic/mg1_299496636')\n",
    "base_segments_p = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_presynaptic')\n",
    "base_segments_postmg = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_postsynaptic_mg')\n",
    "base_segments_postmg_check = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_postsynaptic_mg/check-duplicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef430e-8c2d-4935-aa44-0e4fda4e1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('from the main folder:')\n",
    "df = crest.check_duplicates(base_segments_net)\n",
    "display(df)\n",
    "# print('from the kp folder:')\n",
    "# df = crest.check_duplicates(base_segments_kp)\n",
    "# display(df)\n",
    "print('from the sg post folder:')\n",
    "df = crest.check_duplicates(base_segments_mg1)\n",
    "display(df)\n",
    "print('from the aff folder:')\n",
    "df = crest.check_duplicates(base_segments_aff)\n",
    "display(df)\n",
    "print('from the mg2 ex folder:')\n",
    "df = crest.check_duplicates(base_segments_mg2_p)\n",
    "display(df)\n",
    "print('from the mg1 ex folder:')\n",
    "df = crest.check_duplicates(base_segments_mg1_p)\n",
    "display(df)\n",
    "print('from the presyn folder:')\n",
    "df = crest.check_duplicates(base_segments_p)\n",
    "display(df)\n",
    "\n",
    "# print('from the mg post folder:')\n",
    "# df = crest.check_duplicates(base_segments_postmg)\n",
    "# display(df)\n",
    "# print('from the mg post check duplicates folder:')\n",
    "# df = crest.check_duplicates(base_segments_postmg_check)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46a5ad-a7c0-42d4-94bc-e7de55174f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cell type then run the code cell\n",
    "cell_type = 'vmi'\n",
    "\n",
    "## Do not edit\n",
    "method = 'manual' # define which method you are using (manual or auto)\n",
    "crest.define_ctype(cell_type,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cf970-8572-46f8-aa3e-b216394161e5",
   "metadata": {},
   "source": [
    "### 2. SAVE YOUR WORK BEFORE CLOSING NEUROGLANCER! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea50386-cc2f-428d-84bc-50495132bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.save_cell_graph(directory_path = Path(settings_dict['save_dir']))# / 'todo_postsynaptic_sg/check-duplicates')#/'volume-subsample-all/in-progress')# / 'todo_presynaptic/sg1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a059d6-8f62-4fff-a695-9078af0098f3",
   "metadata": {},
   "source": [
    "If you want to re-write the file you opened instead of saving with a new timestamp in the filename, run the following code cell instead of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b8429-ccf4-4961-861a-69b238710930",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = json_path / filename\n",
    "crest.save_cell_graph(directory_path = filepath.parent)#, file_name=filepath.name); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c23b45-e993-42ff-9718-4f1a9ab8ade3",
   "metadata": {},
   "source": [
    "#### Use the following to open a new cell in the same neuroglancer tab as is already opened\n",
    "\n",
    "**DOES NOT WORK YET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c8fd5-8ce2-4048-bbb7-9e367806d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = Path(settings_dict['save_dir']) / 'todo_post-synaptic'\n",
    "# filename = 'cell_graph_302637877__2023-04-09 19.21.28.json'\n",
    "\n",
    "# crest = ecrest(settings_dict,filepath= json_path / filename)\n",
    "# crest.neuroglancer_viewer(viewer_object)\n",
    "# crest.load_to_viewer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c90f9-ff7e-46cd-965f-c3735d12fc3a",
   "metadata": {},
   "source": [
    "### 3. CELL TYPING\n",
    "\n",
    "If part of your job as a reconstructor is to identify cell types, then you can use the following blocks of code.  \n",
    "First, check if it is already defined (and what the cell type was defined as).  \n",
    "\n",
    "\n",
    "After you are finished defining the cell type:  \n",
    "**DONT FORGET TO SAVE YOUR WORK!**. \n",
    "(step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9e3c8-a310-4331-bfa7-e24a1acd93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign which method you are using (manual or auto)\n",
    "method = 'manual'\n",
    "\n",
    "## Do not edit\n",
    "crest.get_ctype(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48efbe57-08ed-4547-8037-a960d72c15f8",
   "metadata": {},
   "source": [
    "If not defined (or defined incorrectly), then define it.\n",
    "> OPTIONS: mg1, mg2, mgx, lg, lf, lx, mli, gc, gran, sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8ee8e-c2f0-4468-8741-cd7bf84b539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cell type and which method you are using (manual or auto)\n",
    "cell_type = 'lf'\n",
    "method = 'manual'\n",
    "\n",
    "## Do not edit\n",
    "crest.define_ctype(cell_type,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db229173-332f-45c2-ba32-d907a2c7b9e7",
   "metadata": {},
   "source": [
    "## Check for DUPLICATES - single cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e1955-f159-41b5-b007-168c8225f469",
   "metadata": {},
   "source": [
    "Specify a folder of cells that you want to check for duplicates with the cell you are reconstructing.\n",
    "\n",
    "The following code cell uses the function ```get_base_segments_dict``` in the crest instance to create a dictionary of all base segments for each cell within a specified directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd642d2-171d-494e-98f6-027708ba51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir']) #/ 'todo_post-synaptic'\n",
    "\n",
    "base_segments = crest.get_base_segments_dict(dirpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5258d-1eb8-45e5-9c2b-f5fa4ac95ece",
   "metadata": {},
   "source": [
    "Load a cell that needs checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11e64a-e89b-4542-a796-7afcc991396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) / 'todo_post-synaptic' / 'check-duplicates'\n",
    "filename = 'cell_graph_50844566__2023-04-21 14.47.44.json'\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307560e-4722-4ec4-a7c2-21c681a66ac3",
   "metadata": {},
   "source": [
    "And then uses the function ```get_duplicates``` in the crest instance to check if it overlaps with any of the cells in that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a24e7-160e-45ca-a334-14be192adf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = crest.check_duplicates(base_segments)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a874946-0275-46e0-aec7-be6ba4271ec5",
   "metadata": {},
   "source": [
    "## Convert From Neuroglancer to eCREST\n",
    "\n",
    "Run the following code cell to convert neuroglancer json files to eCREST json files. \n",
    "\n",
    "Uses \"conversion_specs.json\" to batch process conversion.\n",
    "\n",
    "Conversion using \"conversion_specs.json\" expects:\n",
    "- a folder of neuroglancer json files (with filenames standardized like in Google Drive)\n",
    "- \"dirname\" is the folder containing neuroglancer json files to be converted\n",
    "- that the \"conversion_specs.json\" is in the ```settings_dict['save_dir']``` key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c0940-9886-4c81-b9f9-d75e97b8d2f0",
   "metadata": {},
   "source": [
    "### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848ec1f-7cdd-4f7c-93a2-2025c79806ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_specs_filename = \"conversion_specs.json\"\n",
    "\n",
    "with open(Path(settings_dict['save_dir']) / conversion_specs_filename) as f:\n",
    "    conversion_specs = json.load(f)\n",
    "\n",
    "p = Path(conversion_specs['dirname'])\n",
    "\n",
    "for cell_id, info in conversion_specs['cell_info'].items():\n",
    "   \n",
    "    f = info['filename']\n",
    "    neuroglancer_layer_name = info['neuroglancer_layer_name']\n",
    "    crest_layer_name = info['crest_layer_name']\n",
    "  \n",
    "    ## Get main_base_seg_ID from filename or from list of segment IDs\n",
    "    main_base_id = f.split('_')[1] # gets the base segment ID from the name\n",
    "    \n",
    "    try:\n",
    "        assert cell_id == main_base_id, f'cell id and filename do not match in conversion json; moving on to next cell without completing this one'\n",
    "    except AssertionError as msg:\n",
    "        print(msg)\n",
    "        #add error message to json\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "        loaded['cell_info'][cell_id]['errors'].append(str(msg))\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"w\") as f:\n",
    "            json.dump(loaded, f, indent=4)\n",
    "        continue\n",
    "    \n",
    "    ## Load the neuroglancer json\n",
    "    print(f'you have selected cell {cell_id} to convert')\n",
    "    \n",
    "    with open(p / f, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "        neuroglancer_data = json.load(myfile)\n",
    "\n",
    "    print(f'Obtaining base_seg IDs from segmentation layer of neuroglancer json.')\n",
    "\n",
    "    ## Obtain the list of base_segments from the neuroglancer json\n",
    "    segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "    try:\n",
    "        # add annotation layer\n",
    "        \n",
    "        base_segment_list_ng = segmentation_layer['segments']\n",
    "    except TypeError as msg:\n",
    "        print(msg, f': segmentation layer source is different; moving on to next cell without completing this one')\n",
    "        #add error message to json\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "        loaded['cell_info'][cell_id]['errors'].append(str(msg) + f': segmentation layer source is different; moving on to next cell without completing this one')\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"w\") as f:\n",
    "            json.dump(loaded, f, indent=4)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    print(f'creating a crest_json object with no viewer for this cell')\n",
    "    ## Create CREST instance with no viewer, segment_list, and segment_id\n",
    "    crest = ecrest(settings_dict, segment_id = main_base_id, segment_list = base_segment_list_ng, launch_viewer=False)\n",
    "\n",
    "    print(f'importing annotation layers from neuroglancer')\n",
    "    ## Get annotations from neuroglancer -- iterate through one layer at a time to check for errors in layer names\n",
    "    for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "        # get the 'layers' dictionary that has that name\n",
    "        neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "\n",
    "        if neuroglancer_layer != None:\n",
    "            if cl_ in crest.point_types:\n",
    "                # add annotation layer\n",
    "                crest.import_annotations(neuroglancer_data, [nl_], [cl_])\n",
    "                print(f\"Imported - {nl_} - layer from neuroglancer annotations tabs for cell {crest.cell_data['metadata']['main_seg']['base']} as - {cl_} -.\")\n",
    "            else: \n",
    "                msg = f\"CREST layer name - {cl_} - incorrect for cell {crest.cell_data['metadata']['main_seg']['base']} in conversion_json\"\n",
    "                print(msg)\n",
    "                #add error message to json\n",
    "                with open(crest.save_dir / conversion_specs_filename, \"r\") as f:\n",
    "                    loaded = json.load(f)\n",
    "                loaded['cell_info'][cell_id]['errors'].append(str(msg))\n",
    "                with open(crest.save_dir / conversion_specs_filename, \"w\") as f:\n",
    "                    json.dump(loaded, f, indent=4)\n",
    "        else:\n",
    "            msg = f\"no layer by the name - {nl_} - in neuroglancer json for cell {crest.cell_data['metadata']['main_seg']['base']}\"\n",
    "            print(msg)\n",
    "            #add error message to json\n",
    "            with open(crest.save_dir / conversion_specs_filename, \"r\") as f:\n",
    "                loaded = json.load(f)\n",
    "            loaded['cell_info'][cell_id]['errors'].append(str(msg))\n",
    "            with open(crest.save_dir / conversion_specs_filename, \"w\") as f:\n",
    "                json.dump(loaded, f, indent=4)\n",
    "\n",
    "\n",
    "    ## Save the cell_data as json\n",
    "    print(f'saving cell {cell_id} with completed graph and annotations layers imported')\n",
    "    crest.save_cell_graph() # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471abac-fd9d-4bba-8b86-777a7549c4e0",
   "metadata": {},
   "source": [
    "### Single file\n",
    "\n",
    "Just make the \"conversion_specs\" file have one cell in it. The \"batch\" loop will still run on one cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803f3fd-ce8a-4a2d-9ab4-e7f865cd2ff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Just annotations layer\n",
    "\n",
    "If starting from scratch on a reconstruction is faster than converting the base_segs into a graph... but you want the annotations preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10506a09-0cad-409a-978a-a549f762191f",
   "metadata": {},
   "source": [
    "#### From another crest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0d186-da46-4a9c-a3b1-19b4d9e725cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'todo_post-synaptic'\n",
    "filename = 'cell_graph_299497999__2023-06-29 11.15.50.json'\n",
    "\n",
    "crest_ = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b04f6-63ce-44c4-b13d-eec201f4609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in crest.cell_data['end_points'].keys():\n",
    "    crest.cell_data['end_points'][layer_name] = crest_.cell_data['end_points'][layer_name]\n",
    "\n",
    "    crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693dd2c-2554-41be-b2b5-93724e30f53c",
   "metadata": {},
   "source": [
    "#### from neuroglancer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b377f82-9628-480c-a70e-c545e779d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'todo_post-synaptic'\n",
    "filename = 'cell_graph_482680782__2023-07-20 17.46.00.json'\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22bf1fc-3b85-44fb-989d-ff792cdea197",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer_layer_name = ['post-synaptic']#'pre-synaptic']#,\n",
    "crest_layer_name = ['pre-synaptic']#,'post-synaptic']\n",
    "neuroglancer_path = '/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer_synapses/finished'\n",
    "neuroglancer_path = Path(neuroglancer_path) / '482680782_grc_nbs.json'\n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)\n",
    "# for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "    # get the 'layers' dictionary that has that name\n",
    "    neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "\n",
    "    if neuroglancer_layer != None:\n",
    "        if cl_ in crest.point_types:\n",
    "            # add annotation layer\n",
    "            crest.import_annotations(neuroglancer_data, [nl_], [cl_])\n",
    "            print(f\"Imported - {nl_} - layer from neuroglancer annotations tabs for cell {crest.cell_data['metadata']['main_seg']['base']} as - {cl_} -.\")\n",
    "        else: \n",
    "            msg = f\"CREST layer name - {cl_} - incorrect for cell {crest.cell_data['metadata']['main_seg']['base']} in conversion_json\"\n",
    "            print(msg)\n",
    "\n",
    "    else:\n",
    "        msg = f\"no layer by the name - {nl_} - in neuroglancer json for cell {crest.cell_data['metadata']['main_seg']['base']}\"\n",
    "        print(msg)\n",
    "\n",
    "crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3653ad1-9cf9-456a-b295-1e82f47484bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "base_segment_list_ng = segmentation_layer['segments']\n",
    "\n",
    "base_ids_added = set()\n",
    "\n",
    "anchor_seg = crest.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "segs_to_add = set(base_segment_list_ng).difference(set([a for b in crest.cell_data['base_segments'].values() for a in b]))\n",
    "\n",
    "\n",
    "segs_to_add = [s for s in segs_to_add if '!' not in s]\n",
    "\n",
    "print(len(segs_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03136077-5e9d-4810-b951-85f59b51c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crest.cell_data['end_points']['post-synaptic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcd50d-00eb-4b3a-a383-1260de498480",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the cell_data as json\n",
    "print(f'saving cell {neuroglancer_path} with annotations layers imported')\n",
    "crest.save_cell_graph() # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328ab76-abee-4c55-8604-72b40e04db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ids_added = set()\n",
    "\n",
    "for base_seg in segs_to_add: #overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): # dup diff main adds segments in dup that were not in main\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != crest.cell_data['metadata']['main_seg']['base']): \n",
    "        \n",
    "        displayed_segs = crest.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = crest.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = crest.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = crest.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in crest.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > crest.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # crest.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {crest.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        print(base_ids)\n",
    "        crest.update_base_locations(base_ids)\n",
    "        crest.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = crest.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            crest.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = crest.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        crest.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with crest.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        crest.update_displayed_segs() \n",
    "        crest.assert_segs_in_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1910ccc-c196-4053-a537-36bbf9c92a9d",
   "metadata": {},
   "source": [
    "#### dictionary of just one annotation layer \n",
    "\n",
    "(the json file would be a list of dicts.... each dict is an annotation point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f7201-5b0f-4370-a95f-73af8bd5a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = json_path / 'tmp' /'annotations.json'\n",
    "\n",
    "with open(annotations_path, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    annotate_data = json.load(myfile)\n",
    "# for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "# annotate_data\n",
    "annotation_list = []\n",
    "for v in annotate_data:\n",
    "\n",
    "\n",
    "    # for v in neuroglancer_layer['annotations']:\n",
    "    corrected_location = crest.get_corrected_xyz(v['point'], 'seg')\n",
    "\n",
    "    if 'segments' not in v.keys():\n",
    "        annotation_list.extend([corrected_location])\n",
    "    if 'segments' in v.keys():\n",
    "        annotation_list.extend([corrected_location + v['segments'][0]])\n",
    "\n",
    "# self.cell_data['end_points'][c].extend(annotation_list)\n",
    "\n",
    "crest.cell_data['end_points']['post-synaptic'] = annotation_list\n",
    "\n",
    "crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcf80d-58a6-4c55-8141-39429f268315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the cell_data as json\n",
    "print(f'saving cell {neuroglancer_path} with annotations layers imported')\n",
    "crest.save_cell_graph() # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501822aa-784f-4db5-9952-30c13eae85c8",
   "metadata": {},
   "source": [
    "### segments from an NG json into an existing CREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639eaef-165b-4feb-a1c4-aac1d028cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'todo_post-synaptic'\n",
    "filename = 'cell_graph_476801247__2023-06-04 20.32.28.json'\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cfa38-5007-42c8-8ab2-355347a6dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer_path = '/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer_synapses/finished'\n",
    "neuroglancer_path = Path(neuroglancer_path) / '304356725_nbs.json'\n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbfdd0-5f07-45ad-bfdb-96a382c33791",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "base_segment_list_ng = segmentation_layer['segments']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd251f07-07bf-4f99-adf7-7fb84e9fbc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ids_added = set()\n",
    "anchor_cell = crest\n",
    "anchor_seg = anchor_cell.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "segs_to_add = set(base_segment_list_ng).difference(set([a for b in anchor_cell.cell_data['base_segments'].values() for a in b]))\n",
    "print(len(segs_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075aed08-f4f2-450c-92a5-0214313f05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_to_add = set([x for x in list(segs_to_add) if \"!\" not in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6790ac-097b-4b9b-a443-36078a55c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this might be a version that does not work so well, see visualize overlapping segments section for one that does?'''\n",
    "# for base_seg in segs_to_add:\n",
    "#     # if this segment has not already been added and it is not the anchor seg_ (should not be if not already part of cell)\n",
    "#     if (base_ids_added&set(base_seg)==set()) & (base_seg != anchor_seg): \n",
    "        \n",
    "#         displayed_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "#         if base_seg in displayed_segs:\n",
    "#             # print(f'{base_seg} already in cell, continueing')\n",
    "#             continue\n",
    "\n",
    "#         # print(i,base_seg)\n",
    "#         agglo_seg = anchor_cell.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "#         constituent_base_ids = anchor_cell.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "#         print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {crest.max_num_base_added}')\n",
    "\n",
    "\n",
    "#         if len(constituent_base_ids) > anchor_cell.max_num_base_added:\n",
    "#             base_ids = [base_seg]\n",
    "#             # anchor_cell.large_agglo_segs.add(agglo_seg)\n",
    "#             # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "#         else:\n",
    "#             base_ids = constituent_base_ids\n",
    "        \n",
    "#         current_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "#         num_base_segs_this_agglo_seg = len(base_ids)\n",
    "#         base_ids = [x for x in base_ids if x not in current_segs]\n",
    "#         num_base_segs_not_already_included = len(base_ids)\n",
    "        \n",
    "#         # if there were segments from this agglo seg that were not in current graph, make sure you don't actually want them excluded\n",
    "#         if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "#             base_ids = [x for x in base_ids if x not in anchor_cell.cell_data['removed_base_segs']]\n",
    "\n",
    "#             if not base_seg in base_ids:\n",
    "#                 base_ids.append(base_seg)\n",
    "        \n",
    "#         anchor_cell.update_base_locations(base_ids)\n",
    "#         anchor_cell.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "#         if len(base_ids) > 1:\n",
    "#             edges = anchor_cell.get_edges_from_agglo_seg(agglo_seg)\n",
    "#             edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "#             anchor_cell.pr_graph.add_edges(edges)\n",
    "\n",
    "#         join_msg = anchor_cell.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "#         # Update lists of base segments and displayed segs:\n",
    "#         anchor_cell.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "#         with anchor_cell.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "#             for bs in base_ids:\n",
    "#                 s.layers['base_segs'].segment_colors[int(bs)] = '#ff0000' #'#d2b48c'\n",
    "#                 s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "#         base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "#         anchor_cell.update_displayed_segs() \n",
    "#         anchor_cell.assert_segs_in_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb36244-d283-40ad-ae7a-edc59eab4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc91a44-d0de-46b3-bddd-ede5fa141617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anchor_cell.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8c690-c776-4620-a210-4065261ae42a",
   "metadata": {},
   "source": [
    "## Check for duplicates in mg_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7747c62-07c7-4727-ad09-e8574409f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)\n",
    "\n",
    "dirpath = Path(settings_dict['save_dir']) #/ 'todo_postsynaptic_mg/check-duplicates' #'todo_presynaptic'#\n",
    "# dirpath = \"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\"\n",
    "\n",
    "nodes = [child.name.split('_')[2] for child in sorted(dirpath.iterdir()) \n",
    "         if (child.name[0]!='.') & (child.is_file())] # ignore hidden files]\n",
    "\n",
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67dd95-77ee-4df9-af8b-6ba81842e3cb",
   "metadata": {},
   "source": [
    "For each of the previous files,\n",
    "Check against the following directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4486f7-0574-4699-8032-21b4970826c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_list = [\n",
    "    Path(settings_dict['save_dir']),\n",
    "    # Path(settings_dict['save_dir'])/'volume-subsample-all/in-progress',\n",
    "    # Path(settings_dict['save_dir'])/'todo_postsynaptic_grc',\n",
    "    # Path(settings_dict['save_dir'])/'todo_postsynaptic_sg',\n",
    "    # Path(settings_dict['save_dir'])/'todo_postsynaptic_mg',\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic',\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic/mg2_214581797',\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic/mg1_299496636',\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic/Krista/grc_386392158',\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic/unsure',\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic/needs-cell-type'\n",
    "]\n",
    "\n",
    "for d_ in directory_list:\n",
    "    df_all = pd.DataFrame()\n",
    "    crest = ecrest(settings_dict,launch_viewer=False)\n",
    "    base_segments = crest.get_base_segments_dict(d_)# / 'todo_postsynaptic_sg/check-duplicates')\n",
    "\n",
    "\n",
    "    for k,f in nodefiles.items():\n",
    "        cell = ecrest(settings_dict,filepath = f,launch_viewer=False)\n",
    "        df = cell.check_duplicates(base_segments)\n",
    "        if not df.empty:\n",
    "            df_all = pd.concat([df_all,df]) \n",
    "    \n",
    "    print(f'for directory {d_} the following are duplicates with cells in main folder')\n",
    "    display(df_all)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d70d2-2efa-4f06-a618-d76a5288e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellf = 'cell_graph_310752287__2023-07-26 19.49.58.json'\n",
    "cell = ecrest(settings_dict,filepath = dirpath/cellf, launch_viewer=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a2d32-5202-49c1-85da-a57daccf1352",
   "metadata": {},
   "source": [
    "## visualize overlapping segments for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b2440-8128-456e-bdb7-4a2ebe31a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)\n",
    "dirpath = Path(settings_dict['save_dir'])\n",
    "                  \n",
    "# First, where is the \"main\" cell?\n",
    "    # This will create a base_segments dictionary of all cells in this main directory\n",
    "cell = ecrest(settings_dict,launch_viewer=False)\n",
    "base_segments =  cell.get_base_segments_dict(dirpath)\n",
    "\n",
    "base_segments_dup = base_segments# cell.get_base_segments_dict(dirpath / 'todo_postsynaptic_sg/check-duplicates')#'todo_postsynaptic_mg/check-duplicates') #base_segments #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ec755-1496-4873-8f08-080cee0912cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a6e58-c7d7-4c80-afdb-b7966823fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = '44025489'\t\t\t\n",
    "dup = '44025132' \t\t\n",
    "\n",
    "overlap_segs={}\n",
    "overlap_segs['main']=base_segments[main].difference(base_segments_dup[dup])\n",
    "overlap_segs['dup']=base_segments_dup[dup].difference(base_segments[main])\n",
    "\n",
    "print(f'{len(overlap_segs[\"main\"])} segments in main on {nodefiles[main].name.split(\"_\")[-1][:-5]} that are not in dup')\n",
    "print(f'{len(overlap_segs[\"dup\"])} segments in dup on {nodefiles[dup].name.split(\"_\")[-1][:-5]} that are not in main')\n",
    "\n",
    "overlap_seg_list = base_segments[main] & base_segments_dup[dup]#base_segments_dup[dup]\n",
    "print(f'{len(overlap_seg_list)} segments in both')\n",
    "\n",
    "# overlap_segs[\"dup\"]\n",
    "# overlap_segs[\"dup\"] = overlap_segs[\"dup\"].difference(set(['642149703']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31a84a-accc-4463-9065-3e657a89b4ef",
   "metadata": {},
   "source": [
    "### Create viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcac4e-c5f7-4e41-8e0f-44b6d6a4c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = neuroglancer.Viewer()\n",
    "viewer.set_state({})\n",
    "\n",
    "location=[17000,17000,1500]\n",
    "\n",
    "with viewer.config_state.txn() as s:\n",
    "    s.show_layer_panel = True ###\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    dimensions = neuroglancer.CoordinateSpace(\n",
    "        scales=[16, 16, 30],# self.vx_sizes['em'],\n",
    "        units='nm',\n",
    "        names=['x', 'y', 'z']   )\n",
    "    s.showSlices = False\n",
    "    s.dimensions = dimensions\n",
    "    s.position = array(location)\n",
    "    s.layout = \"3d\"\n",
    "    s.projectionScale = 30000\n",
    "    s.projection_background_color= \"#000000\"\n",
    "\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    wb_open(str(viewer))\n",
    "\n",
    "db_cursors = sqlite3_connect(settings_dict['db_path'], check_same_thread=False).cursor()\n",
    "a = ', '.join(['base_address'])\n",
    "db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')\n",
    "[base_seg] = db_cursors.fetchall()[0]\n",
    "two_d_intensity = 0.5\n",
    "\n",
    "for layer_name in ['main','dup','overlap']:\n",
    "    with viewer.txn(overwrite=True) as s:\n",
    "        s.layers[layer_name] = neuroglancer.SegmentationLayer(source = base_seg, segments=[], segment_colors={})\n",
    "        s.layers[layer_name].ignoreNullVisibleSet = False\n",
    "        s.layers[layer_name].pick = False\n",
    "        s.layers[layer_name].selectedAlpha = two_d_intensity #For 2D\n",
    "\n",
    "### load cells and color overlap\n",
    "cell_color={'main':'#33cc33','dup':'#cc33ff'}\n",
    "\n",
    "for k in ['main','dup']:\n",
    "    with viewer.txn(overwrite=True) as s:\n",
    "        color_structure = cell_color[k] # blue\n",
    "        for bs in overlap_segs[k]:\n",
    "            s.layers[k].segments.add(int(bs))\n",
    "            s.layers[k].segment_colors[int(bs)] = color_structure # blue\n",
    "\n",
    "color_structure='#ff0000'\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    for bs in list(overlap_seg_list):\n",
    "        s.layers['overlap'].segments.add(int(bs))\n",
    "        s.layers['overlap'].segment_colors[int(bs)] = color_structure # blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea34dc-4d17-494e-81ba-260f92504110",
   "metadata": {},
   "source": [
    "### Load main cell so can add segments from duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad9af8-3f2f-4c41-8cd1-979dd5124cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir']) #/ 'todo_postsynaptic_sg/check-duplicates'\n",
    "f_list = [f.name for f in dirpath.glob('*' + dup + '*')]\n",
    "try: \n",
    "    len(f_list)==1\n",
    "    main_cell = ecrest(settings_dict,filepath= dirpath / f_list[-1], launch_viewer=True)\n",
    "except:\n",
    "    print(f'more than one file for {main}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127cad2-fffa-47cd-acf0-e5f2633eb02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cell.save_cell_graph()\n",
    "main_cell.get_ctype(\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d4464-d371-4a6f-a004-79bb8543b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cell.cell_data['removed_base_segs']=set()\n",
    "main_cell.max_num_base_added=1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf011c-8ff7-4392-81cf-73dc8379dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS VERSION OF HOW TO DO THIS IS CURRENTLY WORKING BEST\n",
    "'''\n",
    "anchor_cell = main_cell\n",
    "base_ids_added = set()\n",
    "\n",
    "for base_seg in overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): #overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): # dup diff main adds segments in dup that were not in main\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != anchor_cell.cell_data['metadata']['main_seg']['base']): \n",
    "        \n",
    "        displayed_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = anchor_cell.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = anchor_cell.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in anchor_cell.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > anchor_cell.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # anchor_cell.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {anchor_cell.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        print(base_ids)\n",
    "        anchor_cell.update_base_locations(base_ids)\n",
    "        anchor_cell.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = anchor_cell.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            anchor_cell.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = anchor_cell.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        anchor_cell.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with anchor_cell.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        anchor_cell.update_displayed_segs() \n",
    "        anchor_cell.assert_segs_in_sync()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006dce8-79f6-434e-b84b-d7e7750a6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.define_ctype(\"sg2\",\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5997c-edaa-4563-adf2-7fa5c4c4f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386d051-1ee4-4900-bfb9-25d4e339bad2",
   "metadata": {},
   "source": [
    "### get annotations from duplicate cell into main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c1921-3243-4ac5-a070-afa0cfacf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'kp'#/'todo_presynaptic/mg1_299496636' #/ 'todo_postsynaptic_sg/47366615' #\n",
    "filename = 'cell_graph_129851820__2023-08-09 13.43.19.json'#'cell_graph_306242528__2023-06-26 09.26.24.json'\n",
    "\n",
    "crest_ann = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e148fd6-04b3-4e41-9701-d647295eb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer_name in anchor_cell.cell_data['end_points'].keys():\n",
    "layer_names = ['natural end','exit volume','pre-synaptic','post-synaptic']\n",
    "for l_ in layer_names:\n",
    "    anchor_cell.cell_data['end_points'][l_] = crest_ann.cell_data['end_points'][l_]\n",
    "\n",
    "    anchor_cell.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e2b9b-462c-4a71-b802-52fa7cbe2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.save_cell_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da77b1d-bdd4-46c6-a87e-00ce33dd9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.get_ctype(\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72059f3-b6c2-447c-a016-ae144f39bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.define_ctype(\"sg1\",\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864771f-2897-4c0e-a0af-a82713adc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_base_segs = [str(a) for b in main_cell.cell_data['base_segments'].values() for a in b]\n",
    "\n",
    "# self.update_base_locations(all_base_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc79032-23cb-4771-8223-48abc4ff897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_base_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d4fb1-ab91-4e01-94fc-aa04d52751a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "batch_size=1000\n",
    "base_segs = all_base_segs[0:10]\n",
    "\n",
    "if len(base_segs) > 0:\n",
    "\n",
    "    num_batches = int(len(base_segs)/batch_size)\n",
    "\n",
    "    for batch in range(num_batches+1):\n",
    "\n",
    "        q = ','.join([str(x) for x in base_segs[batch*batch_size:(batch+1)*batch_size]])\n",
    "\n",
    "        # query = f\"\"\"SELECT seg_id, x, y, z FROM base_location WHERE seg_id IN ({q})\"\"\"\n",
    "        QUERY = f\"\"\"\n",
    "        SELECT\n",
    "            cast(objects.id as INT64) as seg_id,\n",
    "            sample_voxel.x as x,\n",
    "            sample_voxel.y as y,\n",
    "            sample_voxel.z as z,\n",
    "        FROM\n",
    "            `lcht-goog-connectomics.ell_roi450um_seg32fb16fb_220930.objinfo` as objects\n",
    "        WHERE objects.id IN ({q})\n",
    "        \"\"\"\n",
    "        main_cell.db_cursors.execute(query)\n",
    "\n",
    "        this_batch = {str(x[0]): (int(x[1]), int(x[2]), int(x[3])) for x in main_cell.db_cursors.fetchall()}\n",
    "\n",
    "        results.update(this_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ec179-196f-46e6-938b-fb5c47ed3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93e0cc-d1f2-4188-8616-d039f48ffbfa",
   "metadata": {},
   "source": [
    "## Combine annotations and/or base segments across different CREST files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd23bd-3376-4e69-a241-a6885285c06c",
   "metadata": {},
   "source": [
    "Duplicate cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5eac7a-3e80-45d8-ae64-5756e14e092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'todo_pre-synaptic/sg2'\n",
    "filename = 'cell_graph_305965235__2023-06-26 13.33.46.json'\n",
    "\n",
    "crest_1 = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659e93a-4a48-4c30-93f5-07db084a22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest_1.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d300545-84c3-4637-8e67-4fb0dd522dc3",
   "metadata": {},
   "source": [
    "Main cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254675f-baeb-4a56-802f-7791146be57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir'])\n",
    "filename = 'cell_graph_386117124__2023-04-09 14.32.27.json'\n",
    "\n",
    "crest_2 = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0056349-7474-427b-a6d5-873173020b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest_2.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a701ee-bb15-4fa7-bdaf-ee5b34bc4eda",
   "metadata": {},
   "source": [
    "### Get missing segments from one into the other...\n",
    "and adjust graph too (find missing edges and vertices... instead of making new graph, use old?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332015b-072f-4046-8ad5-9babeb94c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_1 = set([a for b in crest_1.cell_data['base_segments'].values() for a in b])\n",
    "segs_2 = set([a for b in crest_2.cell_data['base_segments'].values() for a in b])\n",
    "\n",
    "print(f'{len(segs_1.difference(segs_2))} segments in cell 1 that are not in cell 2')\n",
    "print(f'{len(segs_2.difference(segs_1))} segments in cell 2 that are not in cell 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f76caf-ec59-4e37-b9bb-d8592028bf4d",
   "metadata": {},
   "source": [
    "### add segments missing from one reconstruction to another\n",
    "\n",
    "as loop... keeps track of all added (and exclude them from next iterations) because some can be in same agglo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bbca4-09a5-4ae0-9c40-29345ac2145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign which cell you want to add to (and then keep)\n",
    "anchor_cell = crest_2\n",
    "\n",
    "# assign which segments need to be added\n",
    "base_ids_all = sorted(list(segs_1.difference(segs_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d3c8a-4802-4b12-adde-e2d8b5f180be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS VERSION OF HOW TO DO THIS IS CURRENTLY WORKING BEST\n",
    "'''\n",
    "\n",
    "base_ids_added = set()\n",
    "\n",
    "for base_seg in base_ids_all:\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != anchor_seg): \n",
    "        \n",
    "        displayed_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = anchor_cell.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = anchor_cell.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in anchor_cell.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > anchor_cell.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # anchor_cell.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {anchor_cell.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        \n",
    "        anchor_cell.update_base_locations(base_ids)\n",
    "        anchor_cell.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = anchor_cell.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            anchor_cell.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = anchor_cell.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        anchor_cell.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with anchor_cell.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        anchor_cell.update_displayed_segs() \n",
    "        anchor_cell.assert_segs_in_sync()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497d505-0a05-467f-990a-4285bf2d5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest_2.cell_data['end_points']['pre-synaptic'] = crest_1.cell_data['end_points']['pre-synaptic']\n",
    "crest_2.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd894d8c-9b42-4687-b1d4-715e3c1b1a2f",
   "metadata": {},
   "source": [
    "### Create new crest file from the union segment list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefe865-4961-490c-9b6d-6e3a449ad730",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_list = segs_1.union(segs_2)\n",
    "segment_id = crest_1.cell_data['metadata']['main_seg']['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b32bd-891e-4521-8e67-13f6c2c645f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest = ecrest(settings_dict, segment_id = segment_id, segment_list = new_seg_list, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9119a5-b7f9-4635-980b-4a6f6b60ef56",
   "metadata": {},
   "source": [
    "Add annotations from one of the cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5323527-07af-4829-8dd9-daaf7c1af105",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest.cell_data['end_points'] = crest_1.cell_data['end_points']\n",
    "\n",
    "combo_crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78281383-0cd2-479e-93d2-451728671c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest.define_ctype('uk','manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621e038-c237-40b9-ad4e-044628557f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ed1ea-c0da-412e-bd44-c52c7fbf0b4d",
   "metadata": {},
   "source": [
    "#### DONT FORGET TO SAVE YOUR WORK! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21516cc1-aa10-4222-b4a1-c96b30ad4777",
   "metadata": {},
   "source": [
    "## Other..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d1353-a6a3-41d5-87e3-5b0ca0f46bdf",
   "metadata": {},
   "source": [
    "### Add vertex if missing (if can't remove a segment, sometimes this is the reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d6494-401d-4923-b3c8-a3e400a2b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('479295220')\n",
    "crest.cell_data['base_segments']['unknown'].add('565168297')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c334e-4d74-4824-abf9-ff15a438aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.pr_graph.vs.find(\"459940426\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe282d93-d754-4cdf-b3ea-1ba87b4928ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.pr_graph.add_vertex(name='459940426')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7fdb0-af9a-4aa9-815e-0956813b5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.pr_graph.add_edges([(4966,323)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014faae-0438-4798-a635-b57e4af868c6",
   "metadata": {},
   "source": [
    "### define cell type for a crest file\n",
    "\n",
    "resaves as original file name (not with an updated timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efce2e-9ac4-4be6-a5cc-e236727cc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path('/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network')\n",
    "filepath = dirpath / 'cell_graph_307591597__2023-04-07 12.54.44.json'\n",
    "cell_type = 'lf'\n",
    "\n",
    "### \n",
    "crest = ecrest(settings_dict, filepath = filepath, launch_viewer=False);\n",
    "crest.define_ctype(cell_type,'manual')\n",
    "crest.get_ctype('manual') == cell_type\n",
    "crest.save_cell_graph(directory_path = filepath.parent, file_name=filepath.name, save_to_cloud=False); #rewrites the original, not with a new time stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993d5ed-8e30-4589-8a67-aa987d92c5c0",
   "metadata": {},
   "source": [
    "check cell type in neuroglancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60046ea-955a-4427-9f5d-de42cb2cf047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path('/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network')\n",
    "filepath = dirpath / 'cell_graph_213605530__2023-03-29 22.49.21.json'\n",
    "\n",
    "crest = ecrest(settings_dict, filepath = filepath, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98120e79-5427-4297-b25a-2574caa1ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.save_cell_graph(directory_path = filepath.parent, file_name=filepath.name, save_to_cloud=False); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b412c94-b9e0-44bd-8997-f389f5493ce1",
   "metadata": {},
   "source": [
    "### get cell types of neuroglancer reconstructions into crest json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcf6bc-1654-4043-abfe-8bd81985bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb2a8f-c3f6-4234-aa15-2698e9b12ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crestpath = \"/Volumes/GoogleDrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\"\n",
    "ngpath = \"/Volumes/GoogleDrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/files_for_names\"\n",
    "ngfiles = [x.name for x in Path(ngpath).iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac558f6-df50-48c2-8e4d-d800b9488cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype_list = []\n",
    "has_ctype = set()\n",
    "all_cells = set()\n",
    "\n",
    "for fname in sorted(list(Path(crestpath).iterdir())):\n",
    "    if (fname.name[0]!='.') & (fname.is_file()):\n",
    "        # display(fname.name)\n",
    "        crest = ecrest(settings_dict, filepath = fname, launch_viewer=False);\n",
    "        ngfile = list(filter(lambda x: cell.cell_data['metadata']['main_seg']['base'] in x, ngfiles))\n",
    "        \n",
    "        all_cells = all_cells | set({cell.cell_data['metadata']['main_seg']['base']})\n",
    "        \n",
    "        if len(ngfile)==1:\n",
    "            ctype = ngfile[0].split('_')[3].lower()\n",
    "            has_ctype = has_ctype | set({cell.cell_data['metadata']['main_seg']['base']})\n",
    "        ctype_list.append(ctype)\n",
    "        crest.define_ctype(ctype,'manual');\n",
    "        crest.save_cell_graph(directory_path = fname.parent, file_name=fname.name, save_to_cloud=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc61be-b897-4d59-9115-b6fa609694d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all crest cells have cell type definition from neuroglancer file name\n",
    "all_cells-has_ctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946bdd21-d4e1-4ae2-b80e-fc98faa378cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cell type labels\n",
    "list(unique(ctype_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c60dec-c910-4c18-99f4-a75d908f5dd6",
   "metadata": {},
   "source": [
    "### resave a json file with formatting for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189f733-6892-4e71-875b-bddfcbaa4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(\"D:\\electric-fish\\eCREST\\CREST_settings.json\")\n",
    "with open(filepath, \"r\") as f:\n",
    "    loaded = json.load(f)\n",
    "\n",
    "with open(filepath, \"w\") as f:\n",
    "    json.dump(loaded, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4183fe-b1da-45e3-991c-ae7b901967bc",
   "metadata": {},
   "source": [
    "### Add found missing segments to reconstructions\n",
    "\n",
    "manually go through each cell with missing segments, search and add them...\n",
    "\n",
    "keep a running \"todo\" list of any segments that should be a new reconstruction rather than missing from current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ff0b0-2921-4f17-ad51-06ea8a120c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_path = Path('/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/todo_post-synaptic/reconstructed_missing_segs-20230501.json')\n",
    "with open(missing_path,'r') as fp:\n",
    "    reconstructed_segs=fp.read()\n",
    "    reconstructed_segs = json.loads(reconstructed_segs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992a30f-f4de-4c1d-98c9-c676786ce643",
   "metadata": {},
   "source": [
    "for each key in the dict, open the crest file for that cell (from nodefiles) and visualize the missing segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0376024-5f75-4690-b813-b5d72a59a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)\n",
    "\n",
    "dirpath = Path(settings_dict['save_dir'])\n",
    "# dirpath = \"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\"\n",
    "\n",
    "nodes = [child.name.split('_')[2] for child in sorted(dirpath.iterdir()) \n",
    "         if (child.name[0]!='.') & (child.is_file())] # ignore hidden files]\n",
    "\n",
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706e094-5bd0-4bad-b1ac-ca39409c4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba457b7-e9c8-414e-8195-be6a1ffc3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 36\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= nodefiles[keys[k]], launch_viewer=True)\n",
    "\n",
    "print(keys[k], reconstructed_segs[keys[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f898a-32d8-40c0-a9c3-f43e1f148a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with crest.viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "    print(s.input_event_bindings.data_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a2fab-8875-49a2-b050-2a00ac971a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.save_cell_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d557a40-72a3-498d-99c4-0fdd2acd850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.get_ctype('manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3854fc-3ccd-450a-adb9-a64cf5ef5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = [564038367,116931244,128551991,129636736,558157595,130764619,474759791,49654133,390060758,49873267,563840123,130656616,135592261]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
