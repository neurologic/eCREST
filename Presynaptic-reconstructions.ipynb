{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2be670f-c4a6-40d5-83a1-6498d55a2205",
   "metadata": {},
   "source": [
    "# Presynaptic reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1b16f-76db-4df0-8fe2-55b2c1ee3cac",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the following code cell to import the necessary packages and modules. \n",
    "\n",
    "The 'ecrest' class will be imported from eCREST_cli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd03028-d3d1-46c9-b640-03c0e23d88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean,unique,nan\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new\n",
    "import neuroglancer\n",
    "from eCREST_cli import ecrest, import_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa063060-89c7-413e-81f4-86dc0e47cf08",
   "metadata": {},
   "source": [
    "## Import settings\n",
    "\n",
    "Save a copy of settings_dict.json (found in the \"under construction\" directory of eCREST repo) locally somewhere outside the repo (like in your save_dir) and change the directory paths to match your setup. Then use the following code cell to import those specs. This avoids needing to re-type the save_dir and db_path each time you \"git pull\" updates from the repo to this notebook (because everyone has different directory paths).\n",
    "\n",
    "You will, however, need to change the \"path_to_settings_json\" before running the code cell if you git pull. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297836d0-b0e8-4d3a-b310-0f1b54660753",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaaf77f-ac2e-494b-bcb5-acc751d37844",
   "metadata": {},
   "source": [
    "## EDIT reconstruction from file\n",
    "\n",
    "Use the following code cell to launch an editable reconstruction from an existing eCREST json file.\n",
    "\n",
    "Note that you can also initialize an editable reconstruction using any of the following:\n",
    "- (segment_id, segment_list): the main_base_id from the neuroglancer file you are converting and a list of base_segments.\n",
    "- (segment_id): a \"main_base_id\"\n",
    "- (filepath): an existing CREST json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0226f67-47fe-47b6-a163-efe3c022350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) / 'todo_presynaptic'\n",
    "filename = 'cell_graph_387509776__2023-06-09 12.04.01.json'\n",
    "\n",
    "# This next line launches the reconstruction in neuroglancer\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)\n",
    "\n",
    "'''\n",
    "Uncomment the following code block to change the key/function pairings so that you do not have to double click to add new segments\n",
    "'''\n",
    "# with crest.viewer.config_state.txn() as s:\n",
    "#     s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "#     s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "#     print(s.input_event_bindings.data_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5dc3a-ccd4-4cc6-a366-84741ac23ec1",
   "metadata": {},
   "source": [
    "## check for duplicates\n",
    "\n",
    "Check if the open reconstruction in progress overlaps with any existing cells in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10541458-132e-4968-a7f0-402276831813",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_to_check = Path(settings_dict['save_dir']) / 'todo_presynaptic'\n",
    "\n",
    "base_segments = crest.get_base_segments_dict(directory_to_check)\n",
    "df = crest.check_duplicates(base_segments)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f40d90-3bc9-41eb-88ab-39c335cf6ec8",
   "metadata": {},
   "source": [
    "## SAVE YOUR WORK BEFORE CLOSING NEUROGLANCER! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546322db-1e68-4bd2-b8f5-cf49c5fdac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = Path(settings_dict['save_dir'])\n",
    "\n",
    "crest.save_cell_graph(directory_path = savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe2745-6b30-484f-a68a-7e13a770950b",
   "metadata": {},
   "source": [
    "If you want to re-write the file you opened instead of saving with a new timestamp in the filename, you can specify the following function input variables:\n",
    "- directory_path (= savedir)\n",
    "- file_name (= current filename for that cell)\n",
    "\n",
    "Otherwise, the save_cell_graph function automatically creates a new file name with a different timestamp in the name (and you need to manually delete the old one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea2c60-e184-4e7f-8b11-0192d04c1cbe",
   "metadata": {},
   "source": [
    "# Cell typing\n",
    "\n",
    "You can check if the reconstruction already has a cell type defined (and what the cell type was defined as).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a9aad-d4a4-49c6-939f-962ede2e3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign which method you are using (manual or auto)\n",
    "method = 'manual'\n",
    "\n",
    "## Do not edit\n",
    "crest.get_ctype(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4bbcd-5a9c-4b7d-ab38-b98a5ff50fa9",
   "metadata": {},
   "source": [
    "If not defined (or defined incorrectly), then define it using the code cell below.\n",
    "> OPTIONS: mg1, mg2, mgx, lg, lf, lx, mli, gc, gran, sg1, sg2, sgx\n",
    "\n",
    "After you are finished defining the cell type:  \n",
    "**DONT FORGET TO SAVE YOUR WORK!**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1469f38-76da-4369-a110-6647372a8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cell type and which method you are using (manual or auto)\n",
    "cell_type = ''\n",
    "\n",
    "## Do not edit\n",
    "method = 'manual'\n",
    "crest.define_ctype(cell_type,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e792574-f386-4924-8c81-10d7d967ac50",
   "metadata": {},
   "source": [
    "# Dealing with duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e048ce6-fca8-4aae-b883-e51b3edccbe9",
   "metadata": {},
   "source": [
    "## Get segments for main cell and duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385df4f-3aa1-4790-9195-43791a6626e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)\n",
    "dirpath = Path(settings_dict['save_dir'])\n",
    "                  \n",
    "# First, where is the \"main\" cell?\n",
    "main_cell_path = dirpath\n",
    "    # This will create a base_segments dictionary of all cells in this main directory\n",
    "cell = ecrest(settings_dict,launch_viewer=False)\n",
    "base_segments_main =  cell.get_base_segments_dict(main_cell_path)\n",
    "\n",
    "# Then, where is the \"duplicate\" cell?\n",
    "duplicate_cell_path = dirpath / 'todo_presynaptic/'\n",
    "base_segments_dup = cell.get_base_segments_dict(duplicate_cell_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6748531-3749-428a-adfe-85e418bcef5f",
   "metadata": {},
   "source": [
    "The following code cell will tell you how many segments are overlapping between the two and how many of each cell is missing from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87930d29-37eb-4313-83b8-a6d135958749",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = '44098728' \n",
    "dup = '42968640'\n",
    "\n",
    "overlap_segs={}\n",
    "overlap_segs['main']=base_segments_main[main].difference(base_segments_dup[dup])\n",
    "overlap_segs['dup']=base_segments_dup[dup].difference(base_segments_main[main])\n",
    "\n",
    "print(f'{len(overlap_segs[\"main\"])} segments in \"main\" that are not in dup')\n",
    "print(f'{len(overlap_segs[\"dup\"])} segments in \"dup\" that are not in main')\n",
    "\n",
    "overlap_seg_list = base_segments_main[main] & base_segments_dup[dup]#base_segments_dup[dup]\n",
    "print(f'{len(overlap_seg_list)} segments in both')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351f54d-0e94-4f53-84f2-5bc25fdd0de9",
   "metadata": {},
   "source": [
    "## Create viewer to visualize segments from each cell and their overlap\n",
    "\n",
    "Red = overlapping segments  \n",
    "Green = segments only in main cell (not in duplicate)  \n",
    "Purple = segments only in duplicate cell (not in main)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed98672-fe85-4764-8e04-a7186e93bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = neuroglancer.Viewer()\n",
    "viewer.set_state({})\n",
    "\n",
    "location=[17000,17000,1500]\n",
    "\n",
    "with viewer.config_state.txn() as s:\n",
    "    s.show_layer_panel = True ###\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    dimensions = neuroglancer.CoordinateSpace(\n",
    "        scales=[16, 16, 30],# self.vx_sizes['em'],\n",
    "        units='nm',\n",
    "        names=['x', 'y', 'z']   )\n",
    "    s.showSlices = False\n",
    "    s.dimensions = dimensions\n",
    "    s.position = array(location)\n",
    "    s.layout = \"3d\"\n",
    "    s.projectionScale = 30000\n",
    "    s.projection_background_color= \"#000000\"\n",
    "\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    wb_open(str(viewer))\n",
    "\n",
    "db_cursors = sqlite3_connect(settings_dict['db_path'], check_same_thread=False).cursor()\n",
    "a = ', '.join(['base_address'])\n",
    "db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')\n",
    "[base_seg] = db_cursors.fetchall()[0]\n",
    "two_d_intensity = 0.5\n",
    "\n",
    "for layer_name in ['main','dup','overlap']:\n",
    "    with viewer.txn(overwrite=True) as s:\n",
    "        s.layers[layer_name] = neuroglancer.SegmentationLayer(source = base_seg, segments=[], segment_colors={})\n",
    "        s.layers[layer_name].ignoreNullVisibleSet = False\n",
    "        s.layers[layer_name].pick = False\n",
    "        s.layers[layer_name].selectedAlpha = two_d_intensity #For 2D\n",
    "\n",
    "### load cells and color overlap\n",
    "cell_color={'main':'#33cc33','dup':'#cc33ff'}\n",
    "\n",
    "for k in ['main','dup']:\n",
    "    with viewer.txn(overwrite=True) as s:\n",
    "        color_structure = cell_color[k] # blue\n",
    "        for bs in overlap_segs[k]:\n",
    "            s.layers[k].segments.add(int(bs))\n",
    "            s.layers[k].segment_colors[int(bs)] = color_structure # blue\n",
    "\n",
    "color_structure='#ff0000'\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    for bs in list(overlap_seg_list):\n",
    "        s.layers['overlap'].segments.add(int(bs))\n",
    "        s.layers['overlap'].segment_colors[int(bs)] = color_structure # blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de27267-7397-4593-8953-4e505fcb0f3d",
   "metadata": {},
   "source": [
    "## Load main cell so can add segments from duplicate into main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0eae3b-6ed7-4ada-bd5c-a469b4b6bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir']) #/ 'todo_postsynaptic_sg/check-duplicates'\n",
    "f_list = [f.name for f in dirpath.glob('*' + main + '*')]\n",
    "try: \n",
    "    len(f_list)==1\n",
    "    main_cell = ecrest(settings_dict,filepath= dirpath / f_list[-1], launch_viewer=True)\n",
    "except:\n",
    "    print(f'more than one file for {main}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88255126-dd98-4d8c-a732-1f730ba508f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "THIS VERSION OF HOW TO DO THIS IS CURRENTLY WORKING BEST\n",
    "'''\n",
    "anchor_cell = main_cell\n",
    "base_ids_added = set()\n",
    "\n",
    "for base_seg in overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): #overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): # dup diff main adds segments in dup that were not in main\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != anchor_cell.cell_data['metadata']['main_seg']['base']): \n",
    "        \n",
    "        displayed_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = anchor_cell.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = anchor_cell.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in anchor_cell.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > anchor_cell.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # anchor_cell.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {anchor_cell.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        print(base_ids)\n",
    "        anchor_cell.update_base_locations(base_ids)\n",
    "        anchor_cell.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = anchor_cell.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            anchor_cell.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = anchor_cell.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        anchor_cell.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with anchor_cell.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        anchor_cell.update_displayed_segs() \n",
    "        anchor_cell.assert_segs_in_sync()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4a1da-887a-4ab4-951c-b35ab4f8dc69",
   "metadata": {},
   "source": [
    "## SAVE THE MAIN CELL (with duplicate segments now added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f8fcd-b5b3-4d9f-8ad1-f5b08e940f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.save_cell_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
