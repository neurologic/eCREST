{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad326bee-88d1-4c8a-b521-c31f2244dbfb",
   "metadata": {},
   "source": [
    "# Convert json from neuroglancer to CREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45b074-5340-41f6-86c2-53f579932600",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73173909-7e4c-4e66-9216-ec31ae11d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c555f-bd8a-4922-85e1-50aaf8ec727a",
   "metadata": {},
   "source": [
    "### Define a 'crest_json' class using functions from CREST.py\n",
    "\n",
    "An instance of this object will be able to:\n",
    "- open an nbviewer\n",
    "- add-remove segments (using graph feature for efficiency)\n",
    "- format itself and save itself as a CREST-style .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da582ce-3ad0-4039-81c3-25e8b7180b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_whole_state = self.viewer.state.to_json()\n",
    "\n",
    "#         ftypes = ((\"json files\",\"*.json\"), (\"all files\",\"*.*\"))\n",
    "\n",
    "#         selected_file = filedialog.asksaveasfilename(initialdir = \"/\", title = \"Select file\", filetypes = ftypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c77ccc8-da3d-4f40-bee1-8c5d1dcfbd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class crest_json:\n",
    "    \n",
    "    def __init__(self,settings_dict, segment_id = None, segment_list = None, filepath = None):\n",
    "        \n",
    "        '''\n",
    "        At some point, store these initialization values (ie addresses, keys lists) as a 'params' file that can be provided to the init function instead of hard-coding\n",
    "        \n",
    "        main_base_id : base segment ID from neuroglancer list\n",
    "        \n",
    "        db_path : filepath to agglomeration database sql file locally on computer\n",
    "        \n",
    "        '''\n",
    "        #####\n",
    "        \n",
    "        '''\n",
    "        set up local stuff\n",
    "        '''\n",
    "        \n",
    "        self.import_from_settings_dict(settings_dict)\n",
    "        \n",
    "        # Create the connection to the database (right now just for 'Cell Reconstruction')\n",
    "        self.connect_db(self.db_paths)\n",
    "        \n",
    "        # Set up addresses\n",
    "        # addresses are stored in the agglomo SQL file        \n",
    "        required_addresses = ['agglo_address', 'base_address', 'em_address', 'cloud_storage_address']\n",
    "        [self.agglo_seg, self.base_seg, self.em, self.cloud_storage_address]  = self.get_addresses(required_addresses)\n",
    "       \n",
    "        self.cell_pos = 0\n",
    "        self.start_time = time()\n",
    "        self.link_opened = False\n",
    "        \n",
    "        self.get_vx_sizes()\n",
    "        self.added_keybindings = set()\n",
    "        \n",
    "        if segment_id!=None: \n",
    "            # initialize from segment ID\n",
    "            self.load_from_segment_id(segment_id,segment_list)\n",
    "            \n",
    "        if filepath!=None:\n",
    "            # initialize from file (crest .json state)\n",
    "            self.load_from_file(filepath)\n",
    "        #####\n",
    "        \n",
    "        '''\n",
    "        Set up neuroglancer viewer\n",
    "        '''\n",
    "        self.viewer = neuroglancer.Viewer()\n",
    "        self.viewer.set_state({})\n",
    "        \n",
    "        # Add keybindings:\n",
    "        pr_keybindings = {\n",
    "            'change-structure': lambda s: self.change_cell_structure(),\n",
    "            'change-anchor-seg': self.change_anchor_seg,\n",
    "            'add-or-remove-seg': self.add_or_remove_seg,\n",
    "            'mark-branch-in-colour': self.mark_branch_in_colour,\n",
    "            'change-point' : lambda s: self.change_point()\n",
    "            # 'grow-graph': lambda s: self.grow_graph(), ### WHY IS GROW GRAPH DISABLED? SEEMS USEFUL FOR LABELING CELL STRUCTURES AFTER ADDING SEGMENTS?\n",
    "            # 'increase-threshold': lambda s: self.increase_threshold(),\n",
    "            # 'decrease-threshold': lambda s: self.decrease_threshold(),\n",
    "            # 'start-branch-focus': self.branch_focus,\n",
    "            # 'accept-new-segs': lambda s: self.accept_new_segs(),        \n",
    "        }\n",
    "        \n",
    "        self.add_keybindings_no_duplicates(pr_keybindings)            \n",
    "\n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.input_event_bindings.viewer['keyc'] = 'change-structure'\n",
    "            s.input_event_bindings.data_view['dblclick0'] = 'add-or-remove-seg'\n",
    "            s.input_event_bindings.data_view['alt+mousedown0'] = 'mark-branch-in-colour'\n",
    "            s.input_event_bindings.data_view['shift+mousedown2'] = 'change-anchor-seg'\n",
    "            s.input_event_bindings.data_view['keyp'] = 'change-point'\n",
    "            # s.input_event_bindings.viewer['keyg'] = 'grow-graph'\n",
    "            # s.input_event_bindings.viewer['keyk'] = 'increase-threshold'\n",
    "            # s.input_event_bindings.viewer['keyj'] = 'decrease-threshold'\n",
    "            # s.input_event_bindings.viewer['keya'] = 'accept-new-segs'\n",
    "            # s.input_event_bindings.data_view['shift+mousedown0'] = 'start-branch-focus'\n",
    "            \n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.show_layer_panel = True ###\n",
    "\n",
    "        # setup point annoations\n",
    "        self.set_endpoint_annotation_layers()\n",
    "        self.set_base_seg_merger_layer()\n",
    "        self.point_pos = -1\n",
    "        self.change_point()\n",
    "\n",
    "        self.set_seg_colours()\n",
    "        self.cell_structure_pos = -1\n",
    "        self.change_cell_structure()\n",
    "\n",
    "        loc = self.get_locations_from_base_segs([self.cell_data['metadata']['main_seg']['base']])[self.cell_data['metadata']['main_seg']['base']]\n",
    "        self.change_view(loc, css=0.22398, ps=389.338)\n",
    "        self.reset_seg_pr_layers()\n",
    "\n",
    "        b = self.cell_data['base_segments']\n",
    "        second_part = ', '.join([f'{x}: {len(b[x])}' for x in b.keys()])\n",
    "        print(f'updating viewer status message: Current Base Segment Counts: {second_part}')\n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.status_messages['current_seg_count'] = f'Current Base Segment Counts: {second_part}'\n",
    "        \n",
    "        self.open_ng_link()\n",
    "\n",
    "    def open_ng_link(self):\n",
    "\n",
    "        if not self.link_opened:\n",
    "            wb_open(str(self.viewer))\n",
    "            self.link_opened = True\n",
    "\n",
    "    def import_from_settings_dict(self,settings_dict):\n",
    "        # self.settings_dict = settings_dict\n",
    "        self.db_paths = Path(settings_dict['db_path'])\n",
    "        self.point_types = settings_dict['annotation_points']\n",
    "        self.cell_structures = settings_dict['cell_structures']\n",
    "        self.max_num_base_added = settings_dict['max_num_base_added']\n",
    "        self.save_dir = Path(settings_dict['save_dir'])\n",
    "\n",
    "    def add_keybindings_no_duplicates(self, dict):\n",
    "\n",
    "        for k in dict:\n",
    "\n",
    "            if k not in self.added_keybindings:\n",
    "\n",
    "                self.viewer.actions.add(k, dict[k])\n",
    "                self.added_keybindings.add(k)           \n",
    "                \n",
    "    def load_from_segment_id(self,main_base_id,segment_list = None):\n",
    "        '''\n",
    "        initializes the graph after loading all the base segments in the agglomeration segment with the main_base_id\n",
    "        '''\n",
    "                                                \n",
    "        agglo_seg_id = self.get_agglo_seg_of_base_seg(self.cell_data['metadata']['main_seg']['base'])\n",
    "                                                \n",
    "        self.cell_data = {\n",
    "            'graph_edges': [],\n",
    "            'graph_nodes': [],\n",
    "            'base_locations': {},\n",
    "            'added_graph_edges': [], \n",
    "            'added_graph_edges_pre_proofreading': [],\n",
    "            'end_points': {key: [] for key in self.point_types},\n",
    "            'base_seg_merge_points': [],\n",
    "            'removed_base_segs': set(),\n",
    "            'anchor_seg' : str(main_base_id),\n",
    "            'metadata': {   \n",
    "                'main_seg' : {'agglo' : {self.agglo_seg : agglo_seg_id}, 'base' : str(main_base_id)},\n",
    "                'data_sources': {\n",
    "                    'em' : self.em, \n",
    "                    'base': self.base_seg, \n",
    "                    'agglo': self.agglo_seg,\n",
    "                    },\n",
    "                'timing' : [],\n",
    "                'completion' : []\n",
    "                },\n",
    "            'base_segments' : {dtype: set() for dtype in self.cell_structures}\n",
    "        }\n",
    "        \n",
    "        if segment_list!=None: # Then a list of base_segments has been provided and should override getting all base segments from agglomo\n",
    "                                # For example, this would be the case if converting from a neuroglancer-direct json state reconstruction\n",
    "            self.cell_data['base_segments']['unknown']=set(segment_list)\n",
    "            \n",
    "        if segment_list==None: # Then a list of base segments was not provided, and need to get all base segments associated with main_base_seg in its agglo segment\n",
    "            segment_list = self.get_base_segs_of_agglo_seg(agglo_seg_id)\n",
    "            self.cell_data['base_segments']['unknown']=set(segment_list)\n",
    "        \n",
    "        # Initialize graph of base_segments (should all be in 'unknown')\n",
    "        self.create_pr_graph()\n",
    "        \n",
    "        # Initialize the CREST json file\n",
    "        self.save_cell_graph()\n",
    "        \n",
    "        print(f'Created a CREST instance for NEW Reconstruction of {main_base_id}')                                            \n",
    "        \n",
    "    def load_from_file(self,filepath):\n",
    "    \n",
    "        with open(filepath, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "            cell_data=myfile.read()\n",
    "            self.cell_data = json.loads(cell_data)\n",
    "        \n",
    "        for dtype in self.cell_data['base_segments']:\n",
    "            self.cell_data['base_segments'][dtype] = set(self.cell_data['base_segments'][dtype])\n",
    "    \n",
    "        self.cell_data['removed_base_segs'] = set(self.cell_data['removed_base_segs'])\n",
    "        \n",
    "        main_base_id = self.cell_data['metadata']['main_seg']['base']\n",
    "        print(f'Loading a CREST instance for LOADED Reconstruction of {main_base_id}')\n",
    "        \n",
    "        self.load_graph_from_celldata()\n",
    "        self.resolving_seg_overlap()\n",
    "        # self.adjust_annotations_structures()\n",
    "        \n",
    "\n",
    "    def get_addresses(self, required_addresses):\n",
    "        \n",
    "        '''\n",
    "        req_addresses = ['agglo_address', 'base_address', 'em_address', 'cloud_storage_address']\n",
    "        '''\n",
    "        a = ', '.join(required_addresses)\n",
    "\n",
    "        self.db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')\n",
    "\n",
    "        results = self.db_cursors.fetchall()[0]\n",
    "\n",
    "        return results\n",
    "        \n",
    "    def connect_db(self, db_path):\n",
    "\n",
    "        self.db_cursors = sqlite3_connect(db_path, check_same_thread=False).cursor()\n",
    "        \n",
    "    def update_msg(self, msg, layer='status'):\n",
    "\n",
    "        with self.viewer.config_state.txn() as s:\n",
    "            s.status_messages[layer] = msg\n",
    "\n",
    "    def get_vx_sizes(self):\n",
    "               \n",
    "        self.db_cursors.execute('SELECT * FROM voxel_sizes_table')\n",
    "\n",
    "        self.vx_sizes = {}\n",
    "\n",
    "        for dtype, x, y, z, x_size, y_size, z_size in self.db_cursors.fetchall():\n",
    "\n",
    "            self.vx_sizes[dtype] = [x, y, z]\n",
    "\n",
    "            if dtype == 'em':\n",
    "                self.starting_location = [int(x_size/2), int(y_size/2), int(z_size/2),]\n",
    "\n",
    "    def set_base_seg_merger_layer(self):\n",
    "\n",
    "        self.point_types.append('Base Segment Merger')\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            s.layers['Base Segment Merger'] = neuroglancer.AnnotationLayer()\n",
    "            s.layers['Base Segment Merger'].filterBySegmentation = [\"segments\"]\n",
    "            s.layers['Base Segment Merger'].linkedSegmentationLayer = {\"segments\": 'base_segs'}\n",
    "            s.layers['Base Segment Merger'].annotationColor = '#ffa500'\n",
    "            s.layers['Base Segment Merger'].tool = \"annotatePoint\"\n",
    "\n",
    "            for pos, point in enumerate(self.cell_data['base_seg_merge_points']):\n",
    "\n",
    "                point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                pa = neuroglancer.PointAnnotation(id=f'bm_{pos}', point = point_array, segments=[[point[3]]])\n",
    "                s.layers['Base Segment Merger'].annotations.append(pa)                \n",
    "\n",
    "    def change_point(self):\n",
    "\n",
    "        if self.point_pos == len(self.point_types)-1:\n",
    "            self.point_pos = 0\n",
    "        else:\n",
    "            self.point_pos += 1\n",
    "\n",
    "        selected_layer = self.point_types[self.point_pos]\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            s.selectedLayer.layer = selected_layer\n",
    "            s.selected_layer.visible = True\n",
    "            s.layers[selected_layer].tab = 'Annotations'\n",
    "        \n",
    "        self.update_msg(f'Current Point Annotation Type (P): {selected_layer}', layer='current point type')\n",
    "\n",
    "    def change_cell_structure(self):\n",
    "     \n",
    "        if self.cell_structure_pos == len(self.cell_structures)-1:\n",
    "            self.cell_structure_pos = 0\n",
    "\n",
    "        else:\n",
    "            self.cell_structure_pos += 1\n",
    "            \n",
    "        self.update_msg(f'Current Cell Structure (C): {self.cell_structures[self.cell_structure_pos]}', layer='Current Cell Structure')\n",
    "            \n",
    "    def adjust_annotations_structures(self):\n",
    "        '''\n",
    "        when loading a cell from a file, add necessary annotations and structures if do not exist\n",
    "        '''     \n",
    "        \n",
    "        for p in self.point_types:\n",
    "            if p not in self.cell_data['end_points']:\n",
    "                self.cell_data['end_points'][p] = [] # create the entry for that annotation point\n",
    "        self.point_types = list(set(self.point_types + list(self.cell_data['end_points'].keys())))\n",
    "        self.point_types = [x for x in self.point_types if not ('base' in x.lower() and 'merge' in x.lower())]\n",
    "        \n",
    "        self.set_endpoint_annotation_layers() # reset annotations layers to include any adjustments\n",
    "\n",
    "        existing_struc = [x for x in self.cell_data['base_segments'].keys() if x!= 'unknown']\n",
    "        for dtype in self.cell_structures:\n",
    "            if dtype not in self.cell_data['base_segments'].keys():\n",
    "                self.cell_data['base_segments'][dtype] = set() # create the entry for that annotation point\n",
    "        self.cell_structures = list(set(self.cell_structures) | set(existing_struc))\n",
    "        \n",
    "        self.set_seg_colours() # reset colors for segments\n",
    "        \n",
    "    def set_endpoint_annotation_layers(self): \n",
    "\n",
    "        self.point_types = list(set(self.point_types + list(self.cell_data['end_points'].keys())))\n",
    "        self.point_types = [x for x in self.point_types if not ('base' in x.lower() and 'merge' in x.lower())]\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for point_type in self.point_types:\n",
    "\n",
    "                s.layers[point_type] = neuroglancer.AnnotationLayer()\n",
    "                \n",
    "                if point_type == 'post-synaptic':\n",
    "                    s.layers[point_type].annotationColor = '#ff00ff'\n",
    "                    s.layers[point_type].linkedSegmentationLayer = {\"segments\": 'base_segs'} # set it up linked to base_segs\n",
    "                elif point_type == 'pre-synaptic':\n",
    "                    s.layers[point_type].annotationColor = '#00EEEE'\n",
    "                    s.layers[point_type].linkedSegmentationLayer = {\"segments\": 'base_segs'} # set it up linked to base_segs\n",
    "                elif (point_type == 'natural end') | (point_type == 'exit volume'):\n",
    "                    s.layers[point_type].annotationColor = '#FFFF00'\n",
    "                elif point_type == 'uncertain':\n",
    "                    s.layers[point_type].annotationColor = '#EE0000'\n",
    "                else:\n",
    "                    s.layers[point_type].annotationColor = '#ffffff'\n",
    "\n",
    "                s.layers[point_type].tool = \"annotatePoint\"\n",
    "                s.layers[point_type].tab = 'Annotations'\n",
    "\n",
    "                # If data already exists for this point type:\n",
    "\n",
    "        self.load_annotation_layer_points()\n",
    "        \n",
    "    def load_annotation_layer_points(self):\n",
    "        \n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            for point_type in self.point_types:\n",
    "\n",
    "                # If data already exists for this point type:\n",
    "                if point_type in self.cell_data['end_points'].keys():\n",
    "\n",
    "                    for pos, point in enumerate(self.cell_data['end_points'][point_type]):\n",
    "\n",
    "                        if len(point)==3: # then there is no segment ID associated with the annotation point\n",
    "                        \n",
    "                            point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                            point_id = f'{point_type}_{pos}'\n",
    "                            pa = neuroglancer.PointAnnotation(id=point_id, point = point_array)\n",
    "                            s.layers[point_type].annotations.append(pa)\n",
    "\n",
    "                        if len(point)==4: # then include the segment ID with the annotation point\n",
    "                            point_array = array([int(point[x]/self.vx_sizes['em'][x]) for x in range(3)])\n",
    "                            point_id = f'{point_type}_{pos}'\n",
    "                            segment_id = point[3]\n",
    "                            pa = neuroglancer.PointAnnotation(id=point_id, point = point_array, segments = [[segment_id]])\n",
    "                            s.layers[point_type].annotations.append(pa)                     \n",
    "\n",
    "    def save_point_types_successfully(self):\n",
    "\n",
    "        for t in self.point_types:\n",
    "\n",
    "            this_type_points = []\n",
    "     \n",
    "            for x in self.viewer.state.layers[t].annotations:\n",
    "                if t == 'Base Segment Merger' and x.segments == None:\n",
    "                    c = [int(y) for y in x.point]\n",
    "                    self.update_mtab(f'Error, no segment for point {c}, for point layer {t}, correct and re-save', 'Cell Reconstruction')\n",
    "                    return False\n",
    "\n",
    "                else:\n",
    "                    co_ords = [float(x) for x in list(x.point)]\n",
    "                    co_ords_and_id = [co_ords[x]*self.vx_sizes['em'][x] for x in range(3)]\n",
    "\n",
    "                    if x.segments != None:\n",
    "                        if len(x.segments[0]) > 0:\n",
    "                            co_ords_and_id.append(str(x.segments[0][0]))\n",
    "\n",
    "                    this_type_points.append(co_ords_and_id)\n",
    "\n",
    "            if t == 'Base Segment Merger':\n",
    "                self.cell_data['base_seg_merge_points'] = this_type_points\n",
    "            else:\n",
    "                self.cell_data['end_points'][t] = this_type_points\n",
    "\n",
    "        return True                            \n",
    "\n",
    "    def set_seg_colours(self):\n",
    "        chosen_col = '#D2B48C'\n",
    "        self.chosen_seg_colours = {'unknown': '#D2B48C'} # tan\n",
    "\n",
    "        # acceptable_colours = set(['#FFFF00', '#800080', '#008000', '#FF00FF', '#00FF00', '#FF69B4', '#FF8C00'])\n",
    "        # used_colours = set()\n",
    "\n",
    "        for x in self.cell_structures:\n",
    "\n",
    "            # available_colours = acceptable_colours - used_colours\n",
    "\n",
    "            # if len(available_colours) == 0:\n",
    "            #     available_colours = acceptable_colours\n",
    "            \n",
    "            if x=='multiple':\n",
    "                chosen_col = '#9C661F' # white\n",
    "\n",
    "            if x=='axon':\n",
    "                chosen_col = '#008000' # green\n",
    "\n",
    "            if x=='dendrite':\n",
    "                chosen_col = '#FFFF00' # yellow\n",
    "\n",
    "            if x=='basal dendrite': # orange-red\n",
    "                chosen_col = '#CD4B00'\n",
    "\n",
    "            if x=='apical dendrite': # orange\n",
    "                chosen_col = '#FF8000'\n",
    "    \n",
    "            if x not in self.cell_data['base_segments'].keys():\n",
    "                chosen_col = '#708090' # if not one of the explicitly chosen structures, make it slate gray\n",
    "\n",
    "            # used_colours.add(chosen_col)\n",
    "            self.chosen_seg_colours[x] = chosen_col\n",
    "    \n",
    "    def import_base_segments(self,base_segments):\n",
    "        \n",
    "        '''\n",
    "        base_segments is the list of segments from neuroglancer json (which is why get put in \"unknown\")\n",
    "        '''\n",
    "        # Turn lists back to sets:\n",
    "        self.cell_data['base_segments']['unknown'] = set([str(x) for x in base_segments])\n",
    "                \n",
    "    \n",
    "    def create_pr_graph(self):\n",
    "\n",
    "        seg_id = self.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "        print(f'Creating base segment graph for cell {seg_id}', 'Cell Reconstruction')\n",
    "\n",
    "        all_base_segs = [str(a) for b in self.cell_data['base_segments'].values() for a in b]\n",
    "        \n",
    "        self.update_base_locations(all_base_segs)\n",
    "\n",
    "              \n",
    "        ####\n",
    "        # Correct base segment locations that got left out \n",
    "        '''td:\n",
    "        figure out why they are left out.\n",
    "        for example, for one the segment id returned '0' even though there was a location returned\n",
    "        '''\n",
    "        no_loc_base_segs = [str(x) for x in all_base_segs if x not in self.cell_data['base_locations']]\n",
    "        for s in no_loc_base_segs:\n",
    "            results_dict = self.get_locations_from_base_segs(s)\n",
    "            k = list(results_dict.keys())[0] # get key for this segment ID in queried segment location\n",
    "            self.cell_data['base_locations'][s] = self.get_corrected_xyz(results_dict[k], 'seg') # manually log its location with given segment ID\n",
    "        ####\n",
    "        \n",
    "        \n",
    "        possible_edges = []\n",
    "        agglo_segs_done = set()\n",
    "        base_segs_done = set()\n",
    "\n",
    "        for base_seg in all_base_segs:\n",
    "\n",
    "            if base_seg in base_segs_done: continue\n",
    "\n",
    "            agglo_seg = self.get_agglo_seg_of_base_seg(base_seg)\n",
    "            children_base_segs = self.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "            base_segs_done.update(children_base_segs)\n",
    "\n",
    "            if not agglo_seg in agglo_segs_done:\n",
    "\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg)\n",
    "\n",
    "                agglo_segs_done.add(agglo_seg)\n",
    "                possible_edges.extend(edges)\n",
    "\n",
    "        all_bs_set = set(all_base_segs)\n",
    "        possible_edges = [x for x in possible_edges if x[0] in all_bs_set]\n",
    "        chosen_edges = [x for x in possible_edges if x[1] in all_bs_set]\n",
    "\n",
    "        self.pr_graph = ig_Graph(directed=False)\n",
    "        self.pr_graph.add_vertices(all_base_segs)\n",
    "        self.pr_graph.add_edges(chosen_edges)\n",
    "        \n",
    "        self.cell_data['graph_nodes'] = [x['name'] for x in self.pr_graph.vs]\n",
    "        self.cell_data['graph_edges'] = [(self.pr_graph.vs[x.source]['name'], self.pr_graph.vs[x.target]['name']) for x in self.pr_graph.es]\n",
    "\n",
    "        self.add_cc_bridging_edges_pairwise()\n",
    "        self.attach_noloc_segs()\n",
    "\n",
    "        '''\n",
    "        # removed assertion of pr_graph.clusters==1 because importing from a neuroglancer json might \"break\" this and it is ok...\n",
    "        \n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1\n",
    "        '''\n",
    "        \n",
    "        n_clusters = len(self.pr_graph.clusters(mode='weak'))\n",
    "        \n",
    "        print(f'{n_clusters} clusters in graph (note should/would be only 1 if loaded base ID from agglomo fresh)')\n",
    "        \n",
    "        self.assert_segs_in_sync()\n",
    "        \n",
    "        print(f'successful assertion that graph segments and segments listed in base_segments match')\n",
    "        \n",
    "    def load_graph_from_celldata(self):\n",
    "\n",
    "        self.pr_graph = ig_Graph()\n",
    "        self.pr_graph.add_vertices(self.cell_data['graph_nodes'])\n",
    "        self.pr_graph.add_edges(self.cell_data['graph_edges'])\n",
    "\n",
    "        \n",
    "    def save_cell_graph(self, directory_path = None, file_name=None, save_to_cloud=False):\n",
    "        \n",
    "        timestamp = str(datetime.now())[:-7].replace(':','.')\n",
    "        main_base_id = self.cell_data['metadata']['main_seg']['base']\n",
    "                \n",
    "        cell_data = deepcopy(self.cell_data)\n",
    "\n",
    "        # Convert sets to lists for saving in json file:\n",
    "        for dtype in cell_data['base_segments'].keys():\n",
    "            cell_data['base_segments'][dtype] = list(cell_data['base_segments'][dtype])\n",
    "        \n",
    "        cell_data['removed_base_segs'] = list(cell_data['removed_base_segs'])\n",
    "\n",
    "        completion_list = list(set(cell_data['metadata']['completion']))\n",
    "        completion_list.sort()\n",
    "        completion_string = ','.join(completion_list).replace('_', ' ')\n",
    "            \n",
    "        cell_data['metadata']['data_sources']['agglo'] = self.agglo_seg\n",
    "        \n",
    "        if directory_path==None:\n",
    "            directory_path = self.save_dir\n",
    "            \n",
    "        if file_name == None:\n",
    "            file_name = f'cell_graph_{main_base_id}_{completion_string}_{timestamp}.json'\n",
    "            \n",
    "#         with open(f'{self.save_dir}/{file_name}', 'w') as fp:\n",
    "#             json_dump(cell_data, fp)\n",
    "        with open(directory_path / file_name, 'w') as fp:\n",
    "            json.dump(cell_data, fp)\n",
    "\n",
    "        print(f'Saved cell {main_base_id} locally', 'Cell Reconstruction')\n",
    "\n",
    "    def update_base_locations(self, seg_list):\n",
    "\n",
    "        seg_list = [x for x in seg_list if x not in self.cell_data['base_locations'].keys()]\n",
    "\n",
    "        result_dict = self.get_locations_from_base_segs(seg_list)\n",
    "\n",
    "        for r in result_dict:\n",
    "            self.cell_data['base_locations'][r] = self.get_corrected_xyz(result_dict[r], 'seg')\n",
    "\n",
    "    def get_locations_from_base_segs(self, base_segs, batch_size = 1000):\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        if len(base_segs) > 0:\n",
    "        \n",
    "            num_batches = int(len(base_segs)/batch_size)\n",
    "            \n",
    "            for batch in range(num_batches+1):\n",
    "\n",
    "                q = ','.join([str(x) for x in base_segs[batch*batch_size:(batch+1)*batch_size]])\n",
    "                \n",
    "                query = f\"\"\"SELECT seg_id, x, y, z FROM base_location WHERE seg_id IN ({q})\"\"\"\n",
    "\n",
    "                self.db_cursors.execute(query)\n",
    "\n",
    "                this_batch = {str(x[0]): (int(x[1]), int(x[2]), int(x[3])) for x in self.db_cursors.fetchall()}\n",
    "\n",
    "                results.update(this_batch)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_corrected_xyz(self, xyz, adj_key, rel_to_em=False):\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for pos, coord in enumerate(xyz):\n",
    "            result.append(coord*self.vx_sizes[adj_key][pos])\n",
    "            \n",
    "        if rel_to_em==True:\n",
    "            result = [int(result[x]/self.vx_sizes['em'][x]) for x in range(3)]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_agglo_seg_of_base_seg(self, base_seg):\n",
    "\n",
    "        base_seg = str(base_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT agglo_id FROM agglo_base_resolved WHERE base_id = {base_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        agglo_segs = [str(x[0]) for x in self.db_cursors.fetchall()]\n",
    "\n",
    "        assert len(agglo_segs) <= 1\n",
    "\n",
    "        if agglo_segs == []:\n",
    "            return base_seg\n",
    "        else:\n",
    "            return agglo_segs[0]\n",
    "\n",
    "    def get_base_segs_of_agglo_seg(self, agglo_seg):\n",
    "\n",
    "        agglo_seg = str(agglo_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT base_id FROM agglo_base_resolved WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        base_segs = [str(x[0]) for x in self.db_cursors.fetchall()]\n",
    "        base_segs.append(agglo_seg)\n",
    "\n",
    "        return base_segs\n",
    "\n",
    "    def get_edges_from_agglo_seg(self, agglo_seg):\n",
    "\n",
    "        agglo_seg = str(agglo_seg)\n",
    "\n",
    "        query = f\"\"\"SELECT label_a, label_b FROM agglo_to_edges WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "\n",
    "        self.db_cursors.execute(query)\n",
    "        edges = [(str(x[0]), str(x[1])) for x in self.db_cursors.fetchall()]\n",
    "\n",
    "        return edges\n",
    "    \n",
    "    def add_cc_bridging_edges_pairwise(self):\n",
    "        \n",
    "        '''\n",
    "        con_comms = \"connected components\" abbreviation\n",
    "        '''\n",
    "\n",
    "        con_comms = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "        while len(con_comms) > 1:\n",
    "\n",
    "            candidate_edges = []\n",
    "\n",
    "            for cc1, cc2 in combinations(con_comms, 2): # gets all possible pairwise combinations between segments\n",
    "                \n",
    "                # get the name of each base segment\n",
    "                cc1_base_segs = [self.pr_graph.vs[x]['name'] for x in cc1]\n",
    "                cc2_base_segs = [self.pr_graph.vs[x]['name'] for x in cc2]\n",
    "\n",
    "                cc1_list = [x for x in cc1_base_segs if x in self.cell_data['base_locations']]\n",
    "                cc2_list = [x for x in cc2_base_segs if x in self.cell_data['base_locations']]\n",
    "\n",
    "                if cc1_list == [] or cc2_list == []:\n",
    "                    continue\n",
    "\n",
    "                sel_cc1, sel_cc2, dist = self.get_closest_dist_between_ccs(cc1_list, cc2_list)\n",
    "                candidate_edges.append([sel_cc1, sel_cc2, dist])\n",
    "\n",
    "            if candidate_edges == []: \n",
    "                return\n",
    "\n",
    "            origin, target, dist = min(candidate_edges, key = lambda x: x[2])\n",
    "\n",
    "            self.pr_graph.add_edges([(origin, target)])\n",
    "            self.cell_data['added_graph_edges_pre_proofreading'].append([origin, target, dist])\n",
    "#             self.update_mtab(f'Added an edge between segments {origin} and {target}, {dist} nm apart', 'Cell Reconstruction')\n",
    "\n",
    "            con_comms = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "    def get_closest_dist_between_ccs(self, cc1_node_list, cc2_node_list):\n",
    "\n",
    "        cc1_node_locs = [self.cell_data['base_locations'][x] for x in cc1_node_list]\n",
    "        cc2_node_locs = [self.cell_data['base_locations'][x] for x in cc2_node_list]\n",
    "\n",
    "        f = cdist(cc1_node_locs, cc2_node_locs, 'euclidean')\n",
    "\n",
    "        min_indices = unravel_index(argmin(f, axis=None), f.shape)\n",
    "\n",
    "        sel_cc1 = cc1_node_list[min_indices[0]]\n",
    "        sel_cc2 = cc2_node_list[min_indices[1]]\n",
    "        dist = int(f[min_indices])  \n",
    "\n",
    "        return sel_cc1, sel_cc2, dist\n",
    "            \n",
    "    def attach_noloc_segs(self):\n",
    "        ''' NOTE that this does not run (it returns) if self.pr_graph.clusters(mode='weak') == 1\n",
    "        This is a case that is asserted in oringinal CREST.py in '''\n",
    "        \n",
    "        # For isolated segments without locations, attach to largest connected component:\n",
    "        remaining_cc = list(self.pr_graph.clusters(mode='weak'))\n",
    "\n",
    "        if len(remaining_cc) == 1: return\n",
    "\n",
    "        if len(remaining_cc) > 1:\n",
    "            no_loc_base_segs = set([x['name'] for x in self.pr_graph.vs if x['name'] not in self.cell_data['base_locations']])\n",
    "            largest_cc = max(remaining_cc, key = lambda x: len(x))\n",
    "            for cc in remaining_cc:\n",
    "                no_loc_this_cc = cc & no_loc_base_segs\n",
    "                if cc != largest_cc and no_loc_this_cc != set():\n",
    "                    rand_seg1 = random_choice(list(no_loc_this_cc))\n",
    "                    rand_seg2 = random_choice(list(largest_cc))\n",
    "                    self.pr_graph.add_edges([(rand_seg1, rand_seg2)])\n",
    "                    self.cell_data['added_graph_edges_pre_proofreading'].append([rand_seg1, rand_seg2, 'unknown'])\n",
    "#                     print(f'Added an edge between segments {rand_seg1} and {rand_seg2}', 'Cell Reconstruction')\n",
    "\n",
    "    def load_graph_from_celldata(self):\n",
    "\n",
    "        self.pr_graph = ig_Graph()\n",
    "        self.pr_graph.add_vertices(self.cell_data['graph_nodes'])\n",
    "        self.pr_graph.add_edges(self.cell_data['graph_edges'])\n",
    "\n",
    "    def assert_segs_in_sync(self, return_segs=False):\n",
    "\n",
    "        displayed_segs = set([str(x) for x in self.viewer.state.layers['base_segs'].segments]) # not connected to neuroglancer, so not relevant\n",
    "        graph_segs = set([x['name'] for x in self.pr_graph.vs])\n",
    "        listed_segs = set([a for b in [self.cell_data['base_segments'][cs] for cs in self.cell_data['base_segments'].keys()] for a in b])\n",
    "\n",
    "        assert listed_segs == graph_segs\n",
    "\n",
    "        if not displayed_segs == graph_segs:\n",
    "            self.update_displayed_segs()\n",
    "        \n",
    "        if return_segs:\n",
    "#             return displayed_segs\n",
    "            return graph_segs\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def get_ds_segs_of_certain_col(self, base_seg, colour):\n",
    "\n",
    "        ds = self.get_downstream_base_segs(base_seg)[0]\n",
    "\n",
    "        # If any of the downstream segments doesn't have a colour, set it to tan:\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in ds:\n",
    "                if int(bs) not in s.layers['base_segs'].segment_colors.keys():\n",
    "                    s.layers['base_segs'].segment_colors[int(bs)] = '#D2B48C'\n",
    "\n",
    "            ds = set([x for x in ds if s.layers['base_segs'].segment_colors[int(x)] == colour])\n",
    "        \n",
    "        return ds\n",
    "\n",
    "    def update_displayed_segs(self):\n",
    "\n",
    "        displayed_segs = set([str(x) for x in self.viewer.state.layers['base_segs'].segments])\n",
    "        listed_segs = set([x for y in self.cell_data['base_segments'].values() for x in y])\n",
    "        graph_segs = set([x['name'] for x in self.pr_graph.vs])\n",
    "\n",
    "        assert listed_segs == graph_segs\n",
    "\n",
    "        # Identify segments that failed to be removed from the viewer:\n",
    "        segs_to_remove = displayed_segs - listed_segs\n",
    "\n",
    "        # Identify segments that failed to be added to the viewer:\n",
    "        missing_segs = listed_segs - displayed_segs\n",
    "        # missing_focus_segs = self.focus_seg_set - set([str(x) for x in self.viewer.state.layers['focus_segs'].segments])\n",
    "\n",
    "        if not missing_segs == set():\n",
    "            # Correct the viewer:\n",
    "            with self.viewer.txn(overwrite=True) as s:\n",
    "                \n",
    "                layer = 'base_segs'\n",
    "            \n",
    "                for bs in missing_segs:\n",
    "                    s.layers[layer].segment_colors[int(bs)] = '#D2B48C'\n",
    "                    s.layers[layer].segments.add(int(bs)) \n",
    "\n",
    "                for bs in segs_to_remove:\n",
    "                    if int(bs) in s.layers[layer].segments:\n",
    "                        s.layers[layer].segments.remove(int(bs))\n",
    "                            \n",
    "    def add_or_remove_seg(self, action_state):  \n",
    "\n",
    "        rel_layer = 'base_segs'\n",
    "        \n",
    "        base_seg = self.check_selected_segment(rel_layer, action_state, banned_segs = [self.cell_data['anchor_seg']])\n",
    "\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        # Otherwise, add or remove to main layer:\n",
    "        \n",
    "        displayed_segs = self.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        if base_seg in displayed_segs:\n",
    "\n",
    "            self.remove_downstream_base_segs(base_seg)\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "            # Adding a segment:\n",
    "\n",
    "            agglo_seg = self.check_selected_segment('agglo', action_state)\n",
    "  \n",
    "            if agglo_seg == 'None': return\n",
    "\n",
    "            constituent_base_ids = self.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {self.max_num_base_added}')\n",
    "\n",
    "            if len(constituent_base_ids) > self.max_num_base_added:\n",
    "                base_ids = [base_seg]\n",
    "                #self.large_agglo_segs.add(agglo_seg)\n",
    "            else:\n",
    "                base_ids = constituent_base_ids\n",
    "\n",
    "            current_segs = self.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "            num_base_segs_this_agglo_seg = len(base_ids)\n",
    "            base_ids = [x for x in base_ids if x not in current_segs]\n",
    "            num_base_segs_not_already_included = len(base_ids)\n",
    "\n",
    "            if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "                base_ids = [x for x in base_ids if x not in self.cell_data['removed_base_segs']]\n",
    "\n",
    "                if not base_seg in base_ids:\n",
    "                    base_ids.append(base_seg)\n",
    "    \n",
    "            self.update_base_locations(base_ids)\n",
    "            self.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "            if len(base_ids) > 1:\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg)\n",
    "                edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "                self.pr_graph.add_edges(edges)\n",
    "\n",
    "            join_msg = self.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "\n",
    "            # Update lists of base segments and displayed segs:\n",
    "            self.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "\n",
    "            with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "                for bs in base_ids:\n",
    "                    s.layers['base_segs'].segment_colors[int(bs)] = '#D2B48C'\n",
    "                    s.layers['base_segs'].segments.add(int(bs))\n",
    "\n",
    "\n",
    "            self.update_displayed_segs() \n",
    "            self.assert_segs_in_sync()\n",
    "\n",
    "            print(f'Added {len(base_ids)} base segments from agglomerated segment {agglo_seg}{join_msg}')\n",
    "\n",
    "    def remove_downstream_base_segs(self, base_seg):\n",
    "\n",
    "        segs_to_remove, n_con_com = self.get_downstream_base_segs(base_seg)\n",
    "\n",
    "        self.assert_segs_in_sync()\n",
    "\n",
    "        # Remove from lists and segmentation layer:\n",
    "        for cs in self.cell_data['base_segments'].keys():\n",
    "            self.cell_data['base_segments'][cs] -= set(segs_to_remove)\n",
    "\n",
    "        self.pr_graph.delete_vertices(segs_to_remove)\n",
    "        # self.focus_seg_set -= set(segs_to_remove)\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in segs_to_remove:\n",
    "\n",
    "                if int(bs) in s.layers['base_segs'].segments:\n",
    "                    s.layers['base_segs'].segments.remove(int(bs))\n",
    "\n",
    "        self.assert_segs_in_sync()\n",
    "            \n",
    "        self.cell_data['removed_base_segs'].update(set(segs_to_remove))\n",
    "        print(f'{len(segs_to_remove)} base segments removed from {n_con_com} connected components')\n",
    "        self.cell_data['added_graph_edges'] = [x for x in self.cell_data['added_graph_edges'] if (x[0] not in segs_to_remove) and (x[1] not in segs_to_remove)]\n",
    "\n",
    "    def get_downstream_base_segs(self, base_seg):\n",
    "\n",
    "        edge_backup = [(self.pr_graph.vs[p_ix]['name'], base_seg) for p_ix in self.pr_graph.neighbors(base_seg)]\n",
    "\n",
    "        self.pr_graph.delete_vertices([base_seg])\n",
    "\n",
    "        current_cc = list(self.pr_graph.clusters(mode='weak'))\n",
    "        current_cc_seg_ids = [[self.pr_graph.vs[i]['name'] for i in c] for c in current_cc]\n",
    "        ccs_to_remove = [cc for cc in current_cc_seg_ids if self.cell_data['anchor_seg'] not in cc]\n",
    "        segs_to_remove = [str(x) for y in ccs_to_remove for x in y if str(x) != '0']\n",
    "        segs_to_remove.append(base_seg)\n",
    "\n",
    "        self.pr_graph.add_vertices([base_seg])\n",
    "        self.pr_graph.add_edges(edge_backup)\n",
    "\n",
    "        return segs_to_remove, len(current_cc)\n",
    "    \n",
    "    def add_closest_edge_to_graph(self, new_segs, seg_to_link):\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 2\n",
    "\n",
    "        # Some segments do not have locations recorded:\n",
    "        current_cell_node_list = [x['name'] for x in self.pr_graph.vs if x['name'] not in new_segs]\n",
    "        current_cell_node_list = [x for x in current_cell_node_list if x in self.cell_data['base_locations']]\n",
    "        \n",
    "        # Then determine new segments that are acceptable as partners\n",
    "        if seg_to_link in self.cell_data['base_locations'].keys():\n",
    "            new_segs = [seg_to_link]\n",
    "        else:\n",
    "            new_segs = [x for x in new_segs if x in self.cell_data['base_locations']]\n",
    "\n",
    "        sel_curr, sel_new, dist = self.get_closest_dist_between_ccs(current_cell_node_list, new_segs)\n",
    "        \n",
    "        self.pr_graph.add_edges([(sel_curr, sel_new)])\n",
    "        self.cell_data['added_graph_edges'].append([sel_curr, sel_new, dist])\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1     \n",
    "\n",
    "        return f', linked base segments {sel_curr} and {sel_new}, {round(dist)}nm apart, '\n",
    "\n",
    "    def resolving_seg_overlap(self):\n",
    "\n",
    "        for p1, p2 in combinations(self.cell_data['base_segments'].keys(), 2):\n",
    "\n",
    "            common_segments = set(self.cell_data['base_segments'][p1]) & set(self.cell_data['base_segments'][p2])\n",
    "\n",
    "            if common_segments != set():\n",
    "\n",
    "                self.update_mtab(f\"Base segments {common_segments} are present in both {p1} and {p2} layers, moving to 'unknown'\", 'Cell Reconstruction')\n",
    "\n",
    "                for dtype in p1, p2:\n",
    "                    if dtype != 'unknown':\n",
    "                        self.cell_data['base_segments'][dtype] -= common_segments\n",
    "\n",
    "                self.cell_data['base_segments']['unknown'].update(common_segments)\n",
    "\n",
    "    def mark_branch_in_colour(self, action_state):\n",
    "\n",
    "        base_seg = self.check_selected_segment('base_segs', action_state, banned_segs = [self.cell_data['anchor_seg']])\n",
    "\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        if base_seg not in [x['name'] for x in self.pr_graph.vs]:\n",
    "            print(f'Base segment {base_seg} was not in the base segment graph, updating displayed segments ...')\n",
    "            self.update_displayed_segs()\n",
    "            return\n",
    "\n",
    "        col = self.viewer.state.layers['base_segs'].segment_colors\n",
    "\n",
    "        if int(base_seg) not in col.keys(): return\n",
    "\n",
    "        current_colour = col[int(base_seg)]\n",
    "        downstream_segs = self.get_ds_segs_of_certain_col(base_seg, current_colour)\n",
    "\n",
    "        if current_colour != '#D2B48C':\n",
    "            cell_part = 'unknown'\n",
    "        else:\n",
    "            cell_part = self.cell_structures[self.cell_structure_pos]\n",
    "        \n",
    "        new_colour = self.chosen_seg_colours[cell_part]\n",
    "\n",
    "        for cs in self.cell_data['base_segments'].keys():\n",
    "\n",
    "            if cs == cell_part:\n",
    "                self.cell_data['base_segments'][cs].update(downstream_segs)\n",
    "            else:\n",
    "                self.cell_data['base_segments'][cs] -= downstream_segs\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            for bs in downstream_segs:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = new_colour\n",
    "\n",
    "    def check_selected_segment(self, layer, action, banned_segs = [], acceptable_segs='all'):\n",
    "\n",
    "        if layer not in action.selectedValues: \n",
    "            return 'None'\n",
    "\n",
    "        selected_segment = str(action.selected_values.get(layer).value)\n",
    "        banned_segs.extend(['None', '0'])\n",
    "\n",
    "        if selected_segment in banned_segs:\n",
    "            return 'None'\n",
    "        else:\n",
    "            if acceptable_segs != 'all':\n",
    "                if selected_segment not in acceptable_segs:\n",
    "                    print(f'Segment {selected_segment} not in current graph')\n",
    "                    return 'None'\n",
    "\n",
    "            return selected_segment\n",
    "        \n",
    "    def change_anchor_seg(self, action_state):  \n",
    "\n",
    "        base_seg = self.check_selected_segment('base_segs', action_state, banned_segs=[self.cell_data['anchor_seg']])\n",
    "        if base_seg == 'None': return\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "            s.layers['base_segs'].segment_colors[int(self.cell_data['anchor_seg'])] = '#D2B48C'\n",
    "            s.layers['base_segs'].segment_colors[int(base_seg)] = '#1e90ff'\n",
    "            \n",
    "        self.cell_data['anchor_seg'] = deepcopy(base_seg)\n",
    "        \n",
    "    def change_view(self, location, css=None, ps=None):\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            dimensions = neuroglancer.CoordinateSpace(\n",
    "                scales=self.vx_sizes['em'],\n",
    "                units='nm',\n",
    "                names=['x', 'y', 'z']   )\n",
    "\n",
    "            s.showSlices = False\n",
    "            s.dimensions = dimensions\n",
    "            s.position = array(location)\n",
    "\n",
    "            if css != None:\n",
    "                s.crossSectionScale = css\n",
    "            \n",
    "            if ps != None:\n",
    "                s.projectionScale = ps\n",
    "                \n",
    "    def reset_seg_pr_layers(self, two_d_intensity = 0.5):\n",
    "\n",
    "        with self.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            s.layers['em'] = neuroglancer.ImageLayer(source = self.em)\n",
    "\n",
    "            s.layers['agglo'] = neuroglancer.SegmentationLayer(source = self.agglo_seg, segment_colors={})\n",
    "            s.layers['agglo'].pick = False\n",
    "            s.layers['agglo'].visible = True\n",
    "            s.layers['agglo'].ignoreNullVisibleSet = False\n",
    "            s.layers['agglo'].selectedAlpha = two_d_intensity\n",
    "            s.layers['agglo'].objectAlpha = 1.00\n",
    "            \n",
    "            all_segs = [a for b in self.cell_data['base_segments'].values() for a in b]\n",
    "\n",
    "            s.layers['base_segs'] = neuroglancer.SegmentationLayer(source = self.base_seg, segments=all_segs, segment_colors={})\n",
    "            s.layers['base_segs'].ignoreNullVisibleSet = False\n",
    "            s.layers['base_segs'].pick = False\n",
    "            s.layers['base_segs'].selectedAlpha = two_d_intensity #For 2D\n",
    "\n",
    "            for dtype in self.cell_data['base_segments'].keys():\n",
    "\n",
    "                for seg in self.cell_data['base_segments'][dtype]:\n",
    "                    s.layers['base_segs'].segment_colors[int(seg)] = self.chosen_seg_colours[dtype]\n",
    "\n",
    "            s.layers['base_segs'].segment_colors[int(self.cell_data['anchor_seg'])] = '#1e90ff'\n",
    "\n",
    "    def import_annotations(self,neuroglancer_data, neuroglancer_layer_name, crest_layer_name):\n",
    "        \n",
    "        for n, c in zip(neuroglancer_layer_name,crest_layer_name):\n",
    "            \n",
    "            # get the 'layers' dictionary that has that name\n",
    "\n",
    "            neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == n), None)\n",
    "\n",
    "            # create the annotation list for CREST and put it into cell_data\n",
    "\n",
    "            annotation_list = []\n",
    "\n",
    "            for v in neuroglancer_layer['annotations']:\n",
    "                # print(v)\n",
    "                corrected_location = self.get_corrected_xyz(v['point'], 'seg')\n",
    "\n",
    "                if 'segments' not in v.keys():\n",
    "                    annotation_list.extend([corrected_location])\n",
    "                if 'segments' in v.keys():\n",
    "                    annotation_list.extend([corrected_location + v['segments'][0]])\n",
    "\n",
    "            self.cell_data['end_points'][c].extend(annotation_list)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a874946-0275-46e0-aec7-be6ba4271ec5",
   "metadata": {},
   "source": [
    "# Get data from neuroglancer json if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b231dc-6094-449a-a0d1-65fd47c7b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"D:\\\\electric-fish\\\\eCREST_local-files\\\\neuroglancer-json\"\n",
    "\n",
    "f = 'cell_472409584_type_MG1_v2_NS.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8aa0f7-9d41-4d94-8d1e-141f29a551bd",
   "metadata": {},
   "source": [
    "## Load the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fd4c1f28-c90c-4c2f-8888-6b7c36ff6c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have selected cell 472409584 to convert\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(p / f, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    data=myfile.read()\n",
    "neuroglancer_data = json.loads(data)\n",
    "\n",
    "base_segment_ID = f.split('_')[1] # gets the base segment ID from the name\n",
    "\n",
    "print(f'you have selected cell {base_segment_ID} to convert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bce5d5-11fb-482b-9a68-4ce4b358ea76",
   "metadata": {},
   "source": [
    "## Obtain the list of base_segments from the neuroglancer json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3372a150-e65b-4117-9f02-5ab88a6f9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segment_list_ng = neuroglancer_data['layers'][1]['segments']\n",
    "main_base_id = base_segment_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc18eab-9366-478a-bfbc-0e3bb4eef890",
   "metadata": {},
   "source": [
    "# Launch CREST\n",
    "\n",
    "## settings definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcd7d25b-4f95-4568-9d87-d6c8a192d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {\n",
    "    'save_dir' : \"D:\\\\electric-fish\\\\eCREST_local-files\\\\neuroglancer-json\\\\to-crest-json\",\n",
    "    'max_num_base_added' : 1000,\n",
    "    'cell_structures' : ['unknown','axon', 'basal dendrite', 'apical dendrite', 'dendrite', 'multiple'],\n",
    "    'annotation_points' : ['exit volume', 'natural end', 'uncertain', 'pre-synaptic', 'post-synaptic'],\n",
    "    'cred' : \"D:\\\\electric-fish\\\\eCREST_local-files\\\\Mariela_bigquery_exports_agglo_v230111c_16_crest_proofreading_database.db\",\n",
    "    'db_path' : \"D:\\\\electric-fish\\\\eCREST_local-files\\\\Mariela_bigquery_exports_agglo_v230111c_16_crest_proofreading_database.db\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ee431-675e-4a80-aa0e-f449ae8be2a2",
   "metadata": {},
   "source": [
    "## Create an instance of the crest_json class\n",
    "\n",
    "Initialize with either:\n",
    "- (main_seg_id, base_segments): the main_base_id from the neuroglancer file you are converting and a list of base_segments.\n",
    "- (main_seg_id): a \"main_base_id\"\n",
    "- (filepath): an existing CREST json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0630e21f-2aea-40f7-9ea5-2b27ada5e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a CREST instance for LOADED Reconstruction of 216129202\n",
      "updating viewer status message: Current Base Segment Counts: unknown: 672, axon: 0, basal dendrite: 0, apical dendrite: 0, dendrite: 0, multiple: 0\n",
      "3510 other base segments in the agglo segment; max number can add is 1000\n",
      "Added 1 base segments from agglomerated segment 32849286, linked base segments 214999519 and 214999452, 4401nm apart, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PerksLab\\anaconda3\\envs\\ell-crest\\lib\\site-packages\\neuroglancer\\viewer_config_state.py\", line 157, in invoke\n",
      "    handler(state)\n",
      "  File \"C:\\Users\\PerksLab\\AppData\\Local\\Temp\\ipykernel_1668\\2542017208.py\", line 768, in add_or_remove_seg\n",
      "    self.remove_downstream_base_segs(base_seg)\n",
      "  File \"C:\\Users\\PerksLab\\AppData\\Local\\Temp\\ipykernel_1668\\2542017208.py\", line 838, in remove_downstream_base_segs\n",
      "    self.focus_seg_set -= set(segs_to_remove)\n",
      "AttributeError: 'crest_json' object has no attribute 'focus_seg_set'\n"
     ]
    }
   ],
   "source": [
    "crest = crest_json(settings_dict,filepath=\"D:\\\\electric-fish\\\\eCREST_local-files\\\\neuroglancer-json\\\\to-crest-json\\\\cell_graph_216129202__2023-03-19 15.36.18.json\")\n",
    "\n",
    "## Note cloud storage address ;)\n",
    "# crest.cloud_storage_address   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ae18e48-b1df-4b4d-b99a-628b9095f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating base segment graph for cell 216129202 Cell Reconstruction\n",
      "1 clusters in graph (note should/would be only 1 if loaded base ID from agglomo fresh)\n",
      "successful assertion that graph segments and segments listed in base_segments match\n",
      "3510 other base segments in the agglo segment; max number can add is 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PerksLab\\anaconda3\\envs\\ell-crest\\lib\\site-packages\\neuroglancer\\viewer_config_state.py\", line 157, in invoke\n",
      "    handler(state)\n",
      "  File \"C:\\Users\\PerksLab\\AppData\\Local\\Temp\\ipykernel_1668\\2542017208.py\", line 809, in add_or_remove_seg\n",
      "    join_msg = self.add_closest_edge_to_graph(base_ids, base_seg)\n",
      "  File \"C:\\Users\\PerksLab\\AppData\\Local\\Temp\\ipykernel_1668\\2542017208.py\", line 872, in add_closest_edge_to_graph\n",
      "    assert len(self.pr_graph.clusters(mode='weak')) == 2\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "crest.create_pr_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "14dd1e96-0806-494b-a868-50abcd676574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 216129202 locally Cell Reconstruction\n"
     ]
    }
   ],
   "source": [
    "crest.save_cell_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6e8d60d-c927-49ae-ad13-e166d742b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.max_num_base_added=1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8751f56-5cf3-4d81-bf97-5810274d874a",
   "metadata": {},
   "source": [
    "## Get annotations from neuroglancer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fc65c-2f82-42c2-8376-1a0933dbe329",
   "metadata": {},
   "source": [
    "### First, specify the annotation layer names in neuroglancer and crest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "29dbae77-9a43-4aa5-8042-078eba8e7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the original neuroglancer layer name\n",
    "neuroglancer_layer_name = ['synapses','annotations']\n",
    "\n",
    "# Define the 'end_points' annotation layer names to populate for CREST\n",
    "crest_layer_name = ['post-synaptic','natural end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e30cd8-619d-4019-a135-8a544c755b06",
   "metadata": {},
   "source": [
    "### Then, transfer from neuroglancer to crest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "76548116-d35b-4ab6-a320-17eb3dcadfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.import_annotations(neuroglancer_data, neuroglancer_layer_name, crest_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3da8ee-f0bf-4d09-88fb-6f9fbde33d5a",
   "metadata": {},
   "source": [
    "## Save new json\n",
    "\n",
    "This step populates the cell_data graph data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "17f3d053-d4b8-494a-be87-2eda5b667097",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = Path(\"D:\\\\electric-fish\\\\eCREST_local-files\\\\neuroglancer-json\\\\to-crest-json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d500cab1-ac11-4509-9b87-ec72b46fda47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 472409584 locally Cell Reconstruction\n"
     ]
    }
   ],
   "source": [
    "crest.save_cell_graph(directory_path = directory_path) # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21516cc1-aa10-4222-b4a1-c96b30ad4777",
   "metadata": {},
   "source": [
    "## Other..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b6428-52f0-45fc-9b1b-6af275b2e335",
   "metadata": {},
   "source": [
    "Crest does something similar when reading from list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245eb4-d36d-416a-a2fa-adc0a829179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if type(self.cells_todo) == dict:\n",
    "    self.cells_todo = {str(seg_id): {cell_struc: set([str(a) for a in self.cells_todo[seg_id][cell_struc]]) for cell_struc in self.cells_todo[seg_id]} for seg_id in self.cells_todo.keys()}\n",
    "    '''\n",
    "    ###... from above (to read easier)\n",
    "    for seg_id in self.cells_todo.keys():\n",
    "        for cell_struc in self.cells_todo[seg_id]}:\n",
    "            for a in self.cells_todo[seg_id][cell_struc]]):\n",
    "                self.cells_todo = {str(seg_id): {cell_struc: set([str(a) # creates a set() of all segments in the cell structure\n",
    "    ###\n",
    "    \n",
    "    so, self.cells_todo is a dictionary of {'main_base_segment_ID'}{'unknown' : set(base_segments), ...'other cell structures' : set(base_segments)}\n",
    "    '''\n",
    "\n",
    "# Get all file names from cloud for seg_ids of interest:\n",
    "all_cloud_file_names = [x.name for x in self.proofread_files_bucket.list_blobs() if x.name.split('_')[2] in self.cells_todo]\n",
    "all_local_file_names = [x for x in listdir(self.save_dir) if 'cell' in x and x.split('_')[2] in self.cells_todo]\n",
    "\n",
    "#self.completion_message_dict = {}\n",
    "\n",
    "all_cloud_seg_ids = set([x.split('_')[2] for x in all_cloud_file_names])\n",
    "all_local_seg_ids = set([x.split('_')[2] for x in all_local_file_names])\n",
    "cells_with_files = all_cloud_seg_ids.union(all_local_seg_ids)\n",
    "cells_without_files = [x for x in self.cells_todo if x not in cells_with_files]\n",
    "\n",
    "num_fileless_cells = len(cells_without_files)\n",
    "\n",
    "if num_fileless_cells > 0:\n",
    "    self.update_mtab(f'No starting file found locally or in cloud for {num_fileless_cells} cells', 'Cell Reconstruction')\n",
    "else:\n",
    "    self.update_mtab(f'Starting files found for all cells, checking completion status of each file ...', 'Cell Reconstruction')\n",
    "\n",
    "complete_cells = []\n",
    "\n",
    "for seg_id in self.cells_todo: # if cells_todo is a dict, then seg_id will be the dict key\n",
    "\n",
    "    '''\n",
    "    This is just for if the cells already have a file... if import from neuroglancer dict, they will not\n",
    "    \n",
    "    # If a seg ID already has a file, we need to choose which one to use\n",
    "    if seg_id in cells_with_files:\n",
    "\n",
    "        if self.most_recent_file_complete(seg_id, ['local']) and specific_file == None:\n",
    "            complete_cells.append(seg_id)\n",
    "            #msg = f'Cell {seg_id} has already been completed for the selected cell structures locally'\n",
    "            #self.update_mtab(msg, 'Cell Reconstruction')\n",
    "            #self.completion_message_dict[seg_id] = msg\n",
    "            continue\n",
    "\n",
    "        # If no complete cell locally, start most recent file, whether it originates from cloud or local:\n",
    "\n",
    "        if specific_file != None:\n",
    "            most_recent_file = file_name\n",
    "        else:\n",
    "            most_recent_file = self.get_most_recent_cell_files(seg_id, ['cloud', 'local'])[0]\n",
    "\n",
    "        if most_recent_file in listdir(self.save_dir):\n",
    "\n",
    "            msg = f'Cell {seg_id} not completed for all the selected cell structures in the most recent (local) version'\n",
    "\n",
    "            file_source = 'local'\n",
    "\n",
    "        else:\n",
    "\n",
    "            this_seg_cloud_file_names = [x.name for x in self.proofread_files_bucket.list_blobs() if x.name.split('_')[2] == str(seg_id)]\n",
    "\n",
    "            assert most_recent_file in this_seg_cloud_file_names\n",
    "\n",
    "            file_source = 'cloud'\n",
    "\n",
    "            if self.most_recent_file_complete(seg_id, ['cloud']):\n",
    "                msg = f'Cell {seg_id} completed for all the selected cell structures in the most recent (cloud) version'\n",
    "            else:\n",
    "                msg = f'Cell {seg_id} not completed for all the selected cell structures in the most recent (cloud) version'\n",
    "\n",
    "        #self.update_mtab(msg, 'Cell Reconstruction')\n",
    "        #self.completion_message_dict[seg_id] = msg\n",
    "\n",
    "        if file_source == 'cloud':\n",
    "\n",
    "            try:\n",
    "                blob = self.proofread_files_bucket.blob(most_recent_file)\n",
    "                blob.download_to_filename(f'{self.save_dir}/{most_recent_file}')\n",
    "\n",
    "            except ConnectionError:\n",
    "                self.create_cloud_storage_client()\n",
    "                blob = self.proofread_files_bucket.blob(most_recent_file)\n",
    "                blob.download_to_filename(f'{self.save_dir}/{most_recent_file}')\n",
    "\n",
    "            self.update_mtab(f'Proofread cell file {most_recent_file} downloaded from cloud', 'Cell Reconstruction')\n",
    "\n",
    "        with open(f'{self.save_dir}/{most_recent_file}', 'r') as fp:\n",
    "            self.cell_data = json_load(fp)\n",
    "\n",
    "        # If agglo_id has changed from last time, add new base segments - currently disabled:\n",
    "        last_agglo_id = self.cell_data['metadata']['data_sources']['agglo']\n",
    "        changed_agglo_id = (last_agglo_id != self.agglo_seg)\n",
    "\n",
    "        changed_agglo_id = False\n",
    "\n",
    "        if changed_agglo_id:\n",
    "\n",
    "            self.add_new_base_segs_from_new_agglo(seg_id)\n",
    "\n",
    "            # Wipe clean the stored graph:\n",
    "            self.cell_data['graph_edges'] = []\n",
    "            self.cell_data['graph_nodes'] = []\n",
    "\n",
    "            self.create_pr_graph()\n",
    "            self.save_cell_graph()\n",
    "    '''\n",
    "\n",
    "    # Otherwise, it depends on whether the input cells todo is a list or dictionary:\n",
    "    else:\n",
    "        self.making_starting_cell_data(seg_id)\n",
    "        '''basically, \n",
    "            - sets up self.cell_data with default keys\n",
    "            - imports addresses\n",
    "            - takes 'unknown' key:value pair dictionary in self.cells_todo dictionary and puts that into self.cell_data['base_segments']\n",
    "                 -- self.cell_data['base_segments'] = self.cells_todo[main_base_id]\n",
    "        '''\n",
    "\n",
    "        \n",
    "        ''' \n",
    "        # self.pre_load_edges seems set to 0 and not changed\n",
    "        # and self.get_new_gen_dict_entries function definition seems commented out\n",
    "        \n",
    "        if self.pre_load_edges == 1:\n",
    "            all_base_segs = [a for b in self.cell_data['base_segments'].values() for a in b]\n",
    "            self.get_new_gen_dict_entries(all_base_segs, 0)\n",
    "        '''\n",
    "        \n",
    "        self.create_pr_graph()\n",
    "        '''\n",
    "        - gets all base segments from ['base_segments'][all keys]\n",
    "        - self.update_base_locations(all_base_segs)\n",
    "            -- populates cell_data['base_locations']\n",
    "            -- self.get_locations_from_base_segs(seg_list not already in 'base_locations')\n",
    "            -- self.cell_data['base_locations'][r] = self.get_corrected_xyz(result_dict[r], 'seg') \n",
    "                --- adjusts xyz based on resolution per voxel? coord*self.vx_sizes['seg'][x,y, or z]\n",
    "\n",
    "        possible_edges = []\n",
    "        agglo_segs_done = set()\n",
    "        base_segs_done = set()\n",
    "        \n",
    "        for base_seg in all_base_segs: # getting all of the agglomeration segments with base segments in them and getting their edges\n",
    "                                        # (keeping a list of base_seg_done to not double-do it because many base segments per agglo seg)\n",
    "\n",
    "            if base_seg in base_segs_done: continue\n",
    "\n",
    "            agglo_seg = self.get_agglo_seg_of_base_seg(base_seg) \n",
    "            children_base_segs = self.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "            base_segs_done.update(children_base_segs)\n",
    "\n",
    "            if not agglo_seg in agglo_segs_done:\n",
    "\n",
    "                edges = self.get_edges_from_agglo_seg(agglo_seg) # so edges are among base_segments within an agglomeration segment?\n",
    "                                                                # query = f\"\"\"SELECT label_a, label_b FROM agglo_to_edges WHERE agglo_id = {agglo_seg}\"\"\"\n",
    "                \n",
    "                agglo_segs_done.add(agglo_seg)\n",
    "                possible_edges.extend(edges)\n",
    "\n",
    "        all_bs_set = set(all_base_segs)\n",
    "        possible_edges = [x for x in possible_edges if x[0] in all_bs_set]  # first, make sure the first vertex is in all_base_segments\n",
    "        chosen_edges = [x for x in possible_edges if x[1] in all_bs_set]    # second, make sure the second vertex is in all_base_segments\n",
    "\n",
    "        self.pr_graph = ig_Graph(directed=False) # create a graph object\n",
    "        self.pr_graph.add_vertices(all_base_segs) # add base segments as vertices\n",
    "        self.pr_graph.add_edges(chosen_edges)  # add edges\n",
    "\n",
    "        self.add_cc_bridging_edges_pairwise()\n",
    "            -- if there is more than one connected component (so if more than one agglomo in reconstruction maybe?) then it connects them between the closes base segments among them\n",
    "            -- calculates distance between base segments in each cluster from list(self.pr_graph.clusters(mode='weak'))\\\n",
    "            -- repeats until only one cluster in graph\n",
    "            \n",
    "        self.attach_noloc_segs()\n",
    "\n",
    "        assert len(self.pr_graph.clusters(mode='weak')) == 1\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.save_cell_graph()\n",
    "        '''\n",
    "        populates 'graph_nodes' and 'graph_edges'\n",
    "        '''\n",
    "\n",
    "\n",
    "    self.cells_todo_d[seg_id] = self.cell_data['base_segments']\n",
    "\n",
    "# Save new settings file for quick completion lookup next time:\n",
    "with open(f'{self.script_directory}/CREST_settings.json', 'w') as fp:\n",
    "    json_dump(self.settings_dict, fp)\n",
    "\n",
    "# Make sure cells todo is a list:\n",
    "self.cells_todo = [x for x in self.cells_todo if x not in complete_cells]\n",
    "\n",
    "if specific_file == None:\n",
    "    self.remove_skipped_cells()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
