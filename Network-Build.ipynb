{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7053c443-29f1-4b33-b0c2-d4d9b88626ef",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2670ad87-b5c5-4b81-a59f-f190444ea0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from eCREST_cli_beta import ecrest, import_settings\n",
    "from eCREST_cli import ecrest, import_settings, get_cell_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80dbd2-d1cc-4b77-ac6a-c0d2be029283",
   "metadata": {},
   "source": [
    "The 'ecrest' class has been imported from eCREST_cli.py\n",
    "\n",
    "An instance of this object will be able to:\n",
    "- open an neuroglancer viewer for proofrieading (see \"Proofread using CREST\")\n",
    "    - add-remove segments (using graph feature for efficiency)\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "- convert from neuroglancer json (see \"Convert From Neuroglancer to eCREST\")\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84104779-a505-4e08-9fd4-1fb7407ff520",
   "metadata": {},
   "source": [
    "### Import settings\n",
    "\n",
    "If you save a copy of settings_dict.json (found in the \"under construction\" directory of eCREST repo) locally somewhere outside the repo (like in your save_dir), then you can use the following code cell to import. This avoids needing to re-type the save_dir and db_path each time you \"git pull\" updates from the repo to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e188fd4-b913-4e89-bcc2-4c083653845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bee53b-c283-4779-86b6-dace6e455d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir'])\n",
    "# dirpath = \"/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf5b84-32b7-4721-ac80-c82d1f772a5f",
   "metadata": {},
   "source": [
    "# Get all cells info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528f288-ee47-4c25-8ba5-c40d2f05a101",
   "metadata": {},
   "source": [
    "## Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faaac27a-07fd-4c0e-a187-3720d3d7ed08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodefiles = get_cell_filepaths(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751107c2-6c3f-4154-a958-690d9544ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following cells are not typed in the main network\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cell_type = {}\n",
    "not_typed = []\n",
    "for x in nodefiles.keys():\n",
    "    cell = ecrest(settings_dict,filepath = nodefiles[x],launch_viewer=False)\n",
    "    cell_type[x] = cell.get_ctype('manual') \n",
    "    if (cell.get_ctype('manual') == []) | (cell.get_ctype('manual') == ''):\n",
    "        cell_type[x]='none'\n",
    "        not_typed.append(x)# print(f'cell {x} is not cell-typed in json')\n",
    "        \n",
    "print('the following cells are not typed in the main network')\n",
    "print(not_typed)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5171b47c-8d1f-44b1-ac86-64bd90976397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([k for k,v in cell_type.items() if v in 'grc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e2f37-bd6d-4086-a92b-8d27a9fbfeed",
   "metadata": {},
   "source": [
    "## Base Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23ce080b-d192-417c-ad41-0a40ce7f5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base_segments dictionary of all reconstructed cells \n",
    "\n",
    "base_segments = {}\n",
    "for x,f in nodefiles.items():\n",
    "    # if cell_type[x] in network_types: # if do this, you can't check if the post-syn segments exist as a reconstruction\n",
    "    cell = ecrest(settings_dict,filepath = f)#,launch_viewer=False)\n",
    "    base_segments[cell.cell_data['metadata']['main_seg']['base']] = cell.cell_data['base_segments']\n",
    "    \n",
    "    try:\n",
    "        assert cell.cell_data['metadata']['main_seg']['base'] == x\n",
    "    except:\n",
    "        print(x,cell.cell_data['metadata']['main_seg']['base'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53be21-b74e-47da-b02c-844f5dc47635",
   "metadata": {},
   "source": [
    "## Cell structure labeling checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5867b8-43e0-4d75-935e-7f4470880002",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('need labeling for:')\n",
    "\n",
    "for x,segs in base_segments.items():\n",
    "    if (len(segs['unknown']) == len([s for k,v in segs.items() for s in v])) & (cell_type[x] in ['lf','lg']):\n",
    "        print(f'{x} {cell_type[x]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e5070-1940-4d94-b716-acc17460851c",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99bcd175-f3b9-462a-9308-372463f2252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_types = set([v for v in cell_type.values()])#['mg1','mg2','lg','lf','sg1','sg2','sgx','grc','aff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a62a04-9ff4-42eb-aca1-4fdbc503cb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 3526/3526 [31:51<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "synanno_type = 'post-synaptic'\n",
    "vx_sizes = [16, 16, 30]\n",
    "\n",
    "## find edges and set the cell-structure attribute of the edge based on which part of the cell the edge goes to\n",
    "edge_list = []\n",
    "\n",
    "with tqdm(total=len(nodefiles.keys())) as pbar:\n",
    "    for x_pre in nodefiles.keys():\n",
    "        pbar.update(1)\n",
    "        if cell_type[x_pre] in network_types:\n",
    "            \n",
    "            # if the node has post-synaptic annotations (the current cell is assumed pre-synaptic)\n",
    "            pre = ecrest(settings_dict,filepath = nodefiles[x_pre])#,launch_viewer=False)\n",
    "            if pre.cell_data['end_points'][synanno_type] != []:\n",
    "                # for each synapse\n",
    "                for syn_ in pre.cell_data['end_points'][synanno_type]:\n",
    "                    '''assumes that the annotation is a point annotation stored in the list as ([x,y,z,segment_id],'annotatePoint')\n",
    "                    previous ot Jan 25 2024, it was just [x,y,z,segment_id]'''\n",
    "                    syn_ = syn_[0]\n",
    "                    try:\n",
    "                        post_seg = syn_[3]\n",
    "                        syn_ = array([int(syn_[i]) for i in range(3)]) # synapses annotations exported as nanometers, so do not need to convert\n",
    "\n",
    "                        # go through each other nodes\n",
    "                        for x_post in nodefiles.keys():\n",
    "                            if cell_type[x_post] in network_types:\n",
    "                                post = base_segments[x_post] \n",
    "                                for k,v in post.items():\n",
    "                                    for v_ in list(v): #find keys (can be multiple on the same cell) for matching segment ids\n",
    "                                        if post_seg == v_: \n",
    "                                            # add edge to the graph between current node and matching node\n",
    "                                            \n",
    "                                            edge_list.append([x_pre,x_post,k,syn_[0],syn_[1],syn_[2]])\n",
    "                                            \n",
    "\n",
    "                    except IndexError as msg:\n",
    "                        cellid = x_pre\n",
    "                        print(msg, f'for cell {cellid} synapse at {array([int(syn_[i]/vx_sizes[i]) for i in range(3)])} voxels has no segment id')\n",
    "\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac52cb2-1e61-41f0-a464-4a19f57af569",
   "metadata": {},
   "source": [
    "## Specific cell(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a8fac1-c3df-4bbe-8cd4-f31cbc0af8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "cell_list = ['385434515']\n",
    "synanno_type = 'pre-synaptic'\n",
    "\n",
    "for x_pre in cell_list:\n",
    "    pre = ecrest(settings_dict,filepath = nodefiles[x_pre])\n",
    "    for syn_ in pre.cell_data['end_points'][synanno_type]:\n",
    "        try:\n",
    "            post_seg = syn_[3]\n",
    "            syn_ = array([int(syn_[i]/1000) for i in range(3)])\n",
    "\n",
    "            # go through each other nodes\n",
    "            for x_post in nodefiles.keys():\n",
    "                if cell_type[x_post] in network_types:\n",
    "                    post = base_segments[x_post] \n",
    "                    for k,v in post.items():\n",
    "                        for v_ in list(v): #find keys (can be multiple on the same cell) for matching segment ids\n",
    "                            if post_seg == v_: \n",
    "                                # add edge to the graph between current node and matching node\n",
    "\n",
    "                                edge_list.append([x_pre,x_post,k,syn_[0],syn_[1],syn_[2]])\n",
    "\n",
    "        except IndexError as msg:\n",
    "            cellid = x_pre\n",
    "            print(msg, f'for cell {cellid} synapse at {array([int(syn_[i]/vx_sizes[i]) for i in range(3)])} voxels has no segment id')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d0d9b-fae5-488a-bdcf-13b95c34ed75",
   "metadata": {},
   "source": [
    "# Synapses dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12b74970-19b2-4c79-8a1f-6615c6c27304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = pd.DataFrame(edge_list,columns = ['pre','post','structure','x','y','z'])\n",
    "\n",
    "for i,r in df_syn.iterrows():\n",
    "    df_syn.loc[i,'pre_type']=cell_type[df_syn.loc[i,'pre']]\n",
    "    df_syn.loc[i,'post_type']=cell_type[df_syn.loc[i,'post']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8323d6d-35a9-4d4d-bcc0-e4f23fb940f4",
   "metadata": {},
   "source": [
    "## If want to peak at df_Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4796a795-91f5-45c5-9595-3c005dc50fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = df_syn[['pre','post','pre_type','post_type']].value_counts().reset_index(name='weight') #'structure',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617190d-5145-408e-9c83-7d85582fc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges#[df_edges['post_type'].isin(['mg2','lg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd96d3-f54c-4628-b700-389e79f0bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_edges[['pre','post_type']].groupby('post_type')['pre'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f941c8-995a-4ad9-8397-f71f31c0da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in df_edges.iterrows():\n",
    "    df_edges.loc[i,'pre_diam']=soma_diam[str(df_edges.loc[i,'pre'])]\n",
    "    df_edges.loc[i,'post_diam']=soma_diam[str(df_edges.loc[i,'post'])]\n",
    "\n",
    "df_edges.loc[:,'diam_diff'] = (df_edges['post_diam']-df_edges['pre_diam'])/df_edges['pre_diam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd85316-ec49-44cf-a87d-55620dfa2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_edges\n",
    "\n",
    "focal_cell_id = df_edges['post'].unique()\n",
    "display(df_syn[df_syn['pre']==focal_cell_id][['post','post_type']].value_counts().reset_index(\n",
    "    name='weight')['post_type'].value_counts().reset_index(name='ncells'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5886c-f9d0-43b6-89aa-a84f85a36f0d",
   "metadata": {},
   "source": [
    "# save df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e54d001-9758-4c67-a706-7bcb2d06af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path('/Users/kperks/Library/CloudStorage/GoogleDrive-kperky@gmail.com/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/graphs')\n",
    "\n",
    "df_syn.to_csv(savepath / 'df_postsyn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea9a07-130b-4c6c-9501-82b7c0ffa461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cb3d7-16c4-44ed-aeb9-76d04d6e729e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1c801-b701-405f-815e-bd96e19e137d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
