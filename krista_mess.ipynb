{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad326bee-88d1-4c8a-b521-c31f2244dbfb",
   "metadata": {},
   "source": [
    "# Proofread in eCREST\n",
    "\n",
    "The files generated by this script will also be able to be opened in CREST original (though some information may be lost if using original CREST.py or .exe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b4d1a-b07e-40b3-a362-e3a7dcc1d64c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Do the following two setup steps regardless of how you will be using this script. \n",
    "\n",
    "### 1. Imports\n",
    "\n",
    "Run the following code cell to import the necessary packages and modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73173909-7e4c-4e66-9216-ec31ae11d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################ \n",
    "# Get the latest CREST files for each ID within the target folder (dirname)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sqlite3 import connect as sqlite3_connect\n",
    "from sqlite3 import DatabaseError\n",
    "from igraph import Graph as ig_Graph\n",
    "from igraph import plot as ig_plot\n",
    "from scipy.spatial.distance import cdist\n",
    "from random import choice as random_choice\n",
    "from itertools import combinations\n",
    "from numpy import array, unravel_index, argmin, mean,unique,nan\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import neuroglancer\n",
    "from webbrowser import open as wb_open\n",
    "from webbrowser import open_new as wb_open_new\n",
    "import neuroglancer\n",
    "\n",
    "# from eCREST_cli_beta import ecrest, import_settings\n",
    "from eCREST_cli import ecrest, import_settings, get_cell_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c555f-bd8a-4922-85e1-50aaf8ec727a",
   "metadata": {},
   "source": [
    "The 'ecrest' class has been imported from eCREST_cli.py\n",
    "\n",
    "An instance of this object will be able to:\n",
    "- open an neuroglancer viewer for proofrieading (see \"Proofread using CREST\")\n",
    "    - add-remove segments (using graph feature for efficiency)\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "- convert from neuroglancer json (see \"Convert From Neuroglancer to eCREST\")\n",
    "    - format itself and save itself as a CREST-style .json\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc18eab-9366-478a-bfbc-0e3bb4eef890",
   "metadata": {},
   "source": [
    "# USING THE CREST_JSON class\n",
    "\n",
    "## Settings definitions\n",
    "\n",
    "Whether you are converting from neuroglancer or creating a new reconstruction, the settings_dict parameters is needed to create CREST json files with correct formatting. \n",
    "- 'save_dir' : the directory where JSON files are saved \n",
    "- 'cred' and 'db_path' : specify the path to the agglomeration database file on your local computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac738a5-547a-40b9-aa5c-a606b15f690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {\n",
    "    'save_dir' : '/Users/kperks/Documents/eCREST-local-files/in-progress',\n",
    "    'db_path' : '/Users/kperks/Documents/eCREST-local-files/Mariela_bigquery_exports_agglo_v230111c_16_crest_proofreading_database.db',\n",
    "    'max_num_base_added' : 1000,\n",
    "    'cell_structures' : ['unknown','axon', 'basal dendrite', 'apical dendrite', 'dendrite', 'multiple'],\n",
    "    'annotation_points' : ['exit volume', 'natural end', 'uncertain', 'pre-synaptic', 'post-synaptic']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322d51a-097d-4f63-9ade-5dc59cb06a85",
   "metadata": {},
   "source": [
    "### Import settings\n",
    "\n",
    "If you save a copy of settings_dict.json (found in the \"under construction\" directory of eCREST repo) locally somewhere outside the repo (like in your save_dir), then you can use the following code cell to import. This avoids needing to re-type the save_dir and db_path each time you \"git pull\" updates from the repo to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9d6360-08db-4cc2-addf-07b7b17e057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27a53c-cb5c-41e1-a4e1-afed0def0c65",
   "metadata": {},
   "source": [
    "## Proofread using eCREST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8a391-2d53-4f44-be0b-a85e483820a2",
   "metadata": {},
   "source": [
    "### 1. Create a crest_json object that launches a proofreading instance of neuroglancer\n",
    "\n",
    "\n",
    "Initialize with either:\n",
    "- (segment_id, segment_list): the main_base_id from the neuroglancer file you are converting and a list of base_segments.\n",
    "- (segment_id): a \"main_base_id\"\n",
    "- (filepath): an existing CREST json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7213e13-c449-4dc8-aa01-866afa9f41f1",
   "metadata": {},
   "source": [
    "#### NEW reconstruction from segment ID\n",
    "\n",
    "If you wanted to start reconstructing a new cell from a main base segment, \n",
    "you would use the following code block to launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642dbb6c-5350-4ff2-915b-7e0c7fac799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_id = 396761854  #303103074\n",
    "crest = ecrest(settings_dict,segment_id = segment_id, launch_viewer=True)\n",
    "# viewer_object = crest.neuroglancer_viewer()\n",
    "# crest.load_to_viewer()\n",
    "\n",
    "'''\n",
    "If you want to change keybindings for functions:\n",
    "'''\n",
    "with crest.viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "    print(s.input_event_bindings.data_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36395436-5951-4246-8dee-a5ba9e100643",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### EDIT reconstruction from file\n",
    "\n",
    "If you wanted to edit a reconstruction from an existing file, \n",
    "you would use the following code block to launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "b1f3051f-8143-4a48-af15-f42fde741fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefiles = get_cell_filepaths(Path(settings_dict['save_dir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8db1b7-8f3c-4256-9e9d-3de4a2695dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "['', '', '481507678', '561579694', '561641072', '561641580', '561702549', '568432245']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "a5f3f764-6f1f-4088-842f-231cec75e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating viewer status message: Current Base Segment Counts: unknown: 181, axon: 27, basal dendrite: 29, apical dendrite: 0, dendrite: 0, multiple: 28\n",
      "Map({\"dblclick0\": \"add-or-remove-seg\", \"alt+mousedown2\": \"mark-branch-in-colour\", \"shift+mousedown2\": \"change-anchor-seg\", \"alt+mousedown0\": \"add-or-remove-seg\"})\n",
      "1 other base segments in the agglo segment; max number can add is 1500\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "Added 1 base segments from agglomerated segment 568448408, linked base segments 567303194 and 568448408, 2142nm apart, \n"
     ]
    }
   ],
   "source": [
    "cell_id = ''\n",
    "crest = ecrest(settings_dict,filepath= nodefiles[cell_id], launch_viewer=True)\n",
    "\n",
    "'''\n",
    "If you want to change keybindings for functions:\n",
    "'''\n",
    "with crest.viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "    print(s.input_event_bindings.data_view)\n",
    "\n",
    "# # crest.cell_data['removed_base_segs']=set()\n",
    "crest.max_num_base_added=1500\n",
    "\n",
    "# crest.cell_data['removed_base_segs']=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "3c52ff19-a3cb-47c1-aa3c-0c4324d193df",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.add_endpoint_annotation_layers(['soma'])\n",
    "\n",
    "# crest.del_endpoint_annotation_layers(['soma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a2be0103-3229-4d23-9f35-601e7f155e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = json_path / filename\n",
    "c_type = 'uk'\n",
    "crest.define_ctype(c_type,'manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "856d7a0a-6f37-49bd-aa26-c7d55454634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 568432245 reconstruction locally at 2023-09-14 17.29.43\n"
     ]
    }
   ],
   "source": [
    "crest.save_cell_graph(directory_path = filepath.parent, file_name=filepath.name); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06f9e5-6aa0-4a57-8fbc-7d292a1ea5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) / 'todo_afferent' #/ 'kp/385234105_dml_pre' #/'todo_presynaptic/mg2_214581797' #  #/ 'kp/482680782_grc'##/ 'todo_postsynaptic_sg' #\n",
    "filename = 'cell_graph_227256045__2023-07-19 14.12.11.json'#'cell_graph_306242528__2023-06-26 09.26.24.json'\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)\n",
    "\n",
    "'''\n",
    "If you want to change keybindings for functions:\n",
    "'''\n",
    "with crest.viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown0\"]=\"add-or-remove-seg\"\n",
    "    s.input_event_bindings.data_view[\"alt+mousedown2\"]=\"mark-branch-in-colour\"\n",
    "    print(s.input_event_bindings.data_view)\n",
    "\n",
    "# # crest.cell_data['removed_base_segs']=set()\n",
    "crest.max_num_base_added=1500\n",
    "\n",
    "# crest.cell_data['removed_base_segs']=set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3a02a-9689-4430-a46c-4bd626ef1b55",
   "metadata": {},
   "source": [
    "## check for duplicates (single cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "7cfa41ab-c574-44ad-b30b-f777aa4eeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segments_net = crest.get_base_segments_dict(Path(settings_dict['save_dir']))\n",
    "base_segments_kp = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_afferent')\n",
    "# base_segments_mg1 = crest.get_base_segments_dict(Path(settings_dict['save_dir']) / 'todo_presynaptic/mg1_299496636')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "2eef430e-8c2d-4935-aa44-0e4fda4e1a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from the main folder:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>dups</th>\n",
       "      <th>overlap-percent</th>\n",
       "      <th>number_seg_lap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, dups, overlap-percent, number_seg_lap]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from the kp folder:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>dups</th>\n",
       "      <th>overlap-percent</th>\n",
       "      <th>number_seg_lap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223850024</td>\n",
       "      <td>227256045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        self       dups  overlap-percent  number_seg_lap\n",
       "1  223850024  227256045              1.0             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('from the main folder:')\n",
    "df = crest.check_duplicates(base_segments_net)\n",
    "display(df)\n",
    "print('from the kp folder:')\n",
    "df = crest.check_duplicates(base_segments_kp)\n",
    "display(df)\n",
    "# print('from the mg1 folder:')\n",
    "# df = crest.check_duplicates(base_segments_mg1)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "2b46a5ad-a7c0-42d4-94bc-e7de55174f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cell type then run the code cell\n",
    "cell_type = 'grc-d'\n",
    "\n",
    "## Do not edit\n",
    "method = 'manual' # define which method you are using (manual or auto)\n",
    "crest.define_ctype(cell_type,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cf970-8572-46f8-aa3e-b216394161e5",
   "metadata": {},
   "source": [
    "## 2. SAVE YOUR WORK BEFORE CLOSING NEUROGLANCER! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "3ea50386-cc2f-428d-84bc-50495132bc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 223850024 reconstruction locally at 2023-09-14 17.57.45\n"
     ]
    }
   ],
   "source": [
    "crest.save_cell_graph(directory_path = Path(settings_dict['save_dir']))# / 'todo_postsynaptic_sg/check-duplicates')#/'volume-subsample-all/in-progress')# / 'todo_presynaptic/sg1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a059d6-8f62-4fff-a695-9078af0098f3",
   "metadata": {},
   "source": [
    "If you want to re-write the file you opened instead of saving with a new timestamp in the filename, run the following code cell instead of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b8429-ccf4-4961-861a-69b238710930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = json_path / filename\n",
    "crest.save_cell_graph(directory_path = filepath.parent, file_name=filepath.name); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c23b45-e993-42ff-9718-4f1a9ab8ade3",
   "metadata": {},
   "source": [
    "## open a new cell in the same neuroglancer tab as is already opened\n",
    "\n",
    "**DOES NOT WORK YET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c8fd5-8ce2-4048-bbb7-9e367806d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_path = Path(settings_dict['save_dir']) / 'todo_post-synaptic'\n",
    "# filename = 'cell_graph_302637877__2023-04-09 19.21.28.json'\n",
    "\n",
    "# crest = ecrest(settings_dict,filepath= json_path / filename)\n",
    "# crest.neuroglancer_viewer(viewer_object)\n",
    "# crest.load_to_viewer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667c90f9-ff7e-46cd-965f-c3735d12fc3a",
   "metadata": {},
   "source": [
    "### 3. CELL TYPING\n",
    "\n",
    "If part of your job as a reconstructor is to identify cell types, then you can use the following blocks of code.  \n",
    "First, check if it is already defined (and what the cell type was defined as).  \n",
    "\n",
    "\n",
    "After you are finished defining the cell type:  \n",
    "**DONT FORGET TO SAVE YOUR WORK!**. \n",
    "(step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1da9e3c8-a310-4331-bfa7-e24a1acd93eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sg2'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign which method you are using (manual or auto)\n",
    "method = 'manual'\n",
    "\n",
    "## Do not edit\n",
    "crest.get_ctype(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48efbe57-08ed-4547-8037-a960d72c15f8",
   "metadata": {},
   "source": [
    "If not defined (or defined incorrectly), then define it.\n",
    "> OPTIONS: mg1, mg2, mgx, lg, lf, lx, mli, gc, gran, sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8ee8e-c2f0-4468-8741-cd7bf84b539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the cell type and which method you are using (manual or auto)\n",
    "cell_type = 'lf'\n",
    "method = 'manual'\n",
    "\n",
    "## Do not edit\n",
    "crest.define_ctype(cell_type,method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d49bc-9fbb-49b4-9717-6eb065d2d991",
   "metadata": {},
   "source": [
    "## check for duplicates ... filename unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33f4dfb1-239b-4397-a299-c390bda8f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_segments_dict(dirpath):\n",
    "\n",
    "    nodefiles = [child.name for child in sorted(dirpath.iterdir()) if (child.name[0]!='.') & (child.is_file()) & (\"desktop\" not in child.name)]\n",
    "\n",
    "    # Create a base_segments dictionary of all cells in the directory\n",
    "    base_segments = {}\n",
    "    for x in nodefiles:\n",
    "        # print(x)\n",
    "        with open(dirpath / x, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "            cell_data=myfile.read()\n",
    "            cell_data = json.loads(cell_data)\n",
    "        base_segments[x] = set([a for b in cell_data['base_segments'].values() for a in b]) #cell.cell_data['base_segments']\n",
    "        # base_segments[x] = set([a for b in cell_data['base_segments'].values() for a in b]) #cell.cell_data['base_segments']\n",
    "\n",
    "    return base_segments\n",
    "\n",
    "def check_duplicates(base_segments):\n",
    "    '''\n",
    "    base_segments is a dictionary of all segments that this script checks among\n",
    "    '''\n",
    "    df_all = pd.DataFrame()\n",
    "    for _,this_cell in base_segments.items():\n",
    "        overlap = []\n",
    "        num_dup = []\n",
    "        for x in base_segments.keys():\n",
    "            overlap.append(len(this_cell&base_segments[x])/len(base_segments[x]))\n",
    "            num_dup.append(len(this_cell&base_segments[x]))\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"self\": _,\n",
    "            \"dups\": list(base_segments.keys()),\n",
    "            \"overlap-percent\": overlap,\n",
    "            \"number_seg_lap\": num_dup\n",
    "            }).replace(0, nan, inplace=False).dropna()\n",
    "        df = df[df['dups'] != _]\n",
    "        if not df.empty:\n",
    "            df_all = pd.concat([df_all,df]) \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1c87cfce-3145-4848-ac8f-a9283d23d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_segments = get_base_segments_dict(Path(settings_dict['save_dir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3755774-48d1-4d9d-9ad6-384e8798eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "newer file cell_graph_210187178__2024-01-04 16.27.32.json exists for cell_graph_210187178__2023-07-24 12.46.20.json\n",
      "newer file contains 100% or more overlap with old file\n",
      "old file is 0.9319371727748691 of new\n",
      "synapse annotations same\n",
      "\n",
      "newer file cell_graph_211178337__2024-02-01 17.14.23.json exists for cell_graph_211178337__2023-08-23 11.31.34.json\n",
      "newer file contains 100% or more overlap with old file\n",
      "old file is 0.08571428571428572 of new\n",
      "synapse annotations same\n",
      "\n",
      "newer file cell_graph_59014144__2024-01-11 10.50.44.json exists for cell_graph_59014144__2024-01-10 09.58.30.json\n",
      "do not erase old file cell_graph_59014144__2024-01-10 09.58.30.json\n",
      "new file only contains 0.4594594594594595 percent of it\n",
      "old file contains 0.3695652173913043 percent of it\n"
     ]
    }
   ],
   "source": [
    "# dirname = 'C:/Users/mpetkova/Dropbox/U19_zebrafish/EMfullres/LateralLineCurlDetector/CREST/right_afferents/'\n",
    "# # os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:/Users/EngertLab/Dropbox/CREST/mariela_fish_credentials.json'\n",
    "\n",
    "\n",
    "dirpath = Path(settings_dict['save_dir'])#/'todo_presynaptic/mg1_299496636'\n",
    "\n",
    "cellid_filename = [child.name for child in sorted(dirpath.iterdir()) \n",
    "         if (child.name[0]!='.') & (child.is_file())] # ignore hidden files]\n",
    "\n",
    "d={}\n",
    "for name in cellid_filename:\n",
    "    ID,content_type,date=name.split('_')[2], name.split('_')[0], name.split('_')[-1]\n",
    "    date=date[:-5]\n",
    "    #create entry in dict which holds ID, file type (ex: cell_graph) and file path\n",
    "    if ID not in d:\n",
    "        d[ID]=[date, name]\n",
    "    \n",
    "    #if there are multiple files with the same ID, keep the info for the newest one\n",
    "    else:\n",
    "        if date>d[ID][0]:\n",
    "            print('')\n",
    "            print(f'newer file {name} exists for {d[ID][1]}')\n",
    "            if len(base_segments[name]&base_segments[d[ID][1]])/len(base_segments[d[ID][1]]) >= 1:\n",
    "                print(f'newer file contains 100% or more overlap with old file')\n",
    "                print(f'old file is {len(base_segments[name]&base_segments[d[ID][1]])/len(base_segments[name])} of new')\n",
    "                \n",
    "                old_ = ecrest(settings_dict,filepath= dirpath / name, launch_viewer=False)\n",
    "                old_ends = old_.cell_data['end_points']\n",
    "                \n",
    "                new_ = ecrest(settings_dict,filepath= dirpath / d[ID][1], launch_viewer=False)\n",
    "                new_ends = new_.cell_data['end_points']\n",
    "                \n",
    "                if (len(new_ends['post-synaptic']) != len(old_ends['post-synaptic'])) | (len(new_ends['pre-synaptic']) != len(old_ends['pre-synaptic'])):\n",
    "                    print('SYNAPSE ANNOTATIONS NOT SAME')\n",
    "                    \n",
    "                if (len(new_ends['post-synaptic']) == len(old_ends['post-synaptic'])) | (len(new_ends['pre-synaptic']) == len(old_ends['pre-synaptic'])):\n",
    "                    print('synapse annotations same')\n",
    "            \n",
    "            if len(base_segments[name]&base_segments[d[ID][1]])/len(base_segments[d[ID][1]]) < 1:\n",
    "                print(f'do not erase old file {d[ID][1]}')\n",
    "                print(f'new file only contains {len(base_segments[name]&base_segments[d[ID][1]])/len(base_segments[d[ID][1]])} percent of it')\n",
    "                print(f'old file contains {len(base_segments[name]&base_segments[d[ID][1]])/len(base_segments[name])} percent of it')\n",
    "            \n",
    "#             cell_older = ecrest(settings_dict,filepath= dirpath / d[ID][1], launch_viewer=False)\n",
    "#             cell_newer = ecrest(settings_dict,filepath= dirpath / name, launch_viewer=False)\n",
    "            \n",
    "#             d[ID][0]=date\n",
    "#             d[ID][1]=name\n",
    "            \n",
    "# ############################################################################################################################ \n",
    "# # Collect all the base segments for each ID\n",
    "# import json\n",
    "\n",
    "# base_segs = {}\n",
    "\n",
    "# for key in d.keys():\n",
    "#     f = open(dirname+d[key][1])\n",
    "#     data = json.load(f)\n",
    "#     base_segs[key]=sum(data['base_segments'].values(),[])\n",
    "#     f.close()\n",
    "\n",
    "# ############################################################################################################################ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbbdfb69-9206-4218-8cd5-4a04336e4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = check_duplicates(base_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ede9b91-7535-4ca5-bbda-54bcf1cf72e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>dups</th>\n",
       "      <th>overlap-percent</th>\n",
       "      <th>number_seg_lap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>cell_graph_223880142__2023-11-28 11.56.08.json</td>\n",
       "      <td>cell_graph_223880142__2023-12-07 13.15.56.json</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>cell_graph_223880142__2023-12-07 13.15.56.json</td>\n",
       "      <td>cell_graph_223880142__2023-11-28 11.56.08.json</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>cell_graph_285761792__2023-10-25 20.53.45.json</td>\n",
       "      <td>cell_graph_307360204__2023-08-08 10.14.45.json</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>cell_graph_474357461__2023-08-23 20.47.03.json</td>\n",
       "      <td>cell_graph_474373577__2023-12-13 14.33.17.json</td>\n",
       "      <td>0.971770</td>\n",
       "      <td>2031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>cell_graph_474373577__2023-12-13 14.33.17.json</td>\n",
       "      <td>cell_graph_474357461__2023-08-23 20.47.03.json</td>\n",
       "      <td>0.929945</td>\n",
       "      <td>2031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>cell_graph_53276093__2023-08-08 14.40.09.json</td>\n",
       "      <td>cell_graph_137991443__2023-09-28 20.37.05.json</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                self  \\\n",
       "634   cell_graph_223880142__2023-11-28 11.56.08.json   \n",
       "633   cell_graph_223880142__2023-12-07 13.15.56.json   \n",
       "1028  cell_graph_285761792__2023-10-25 20.53.45.json   \n",
       "1926  cell_graph_474357461__2023-08-23 20.47.03.json   \n",
       "1925  cell_graph_474373577__2023-12-13 14.33.17.json   \n",
       "238    cell_graph_53276093__2023-08-08 14.40.09.json   \n",
       "\n",
       "                                                dups  overlap-percent  \\\n",
       "634   cell_graph_223880142__2023-12-07 13.15.56.json         1.000000   \n",
       "633   cell_graph_223880142__2023-11-28 11.56.08.json         1.000000   \n",
       "1028  cell_graph_307360204__2023-08-08 10.14.45.json         0.565217   \n",
       "1926  cell_graph_474373577__2023-12-13 14.33.17.json         0.971770   \n",
       "1925  cell_graph_474357461__2023-08-23 20.47.03.json         0.929945   \n",
       "238   cell_graph_137991443__2023-09-28 20.37.05.json         0.281250   \n",
       "\n",
       "      number_seg_lap  \n",
       "634             29.0  \n",
       "633             29.0  \n",
       "1028            13.0  \n",
       "1926          2031.0  \n",
       "1925          2031.0  \n",
       "238              9.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_all[df_all['overlap-percent']>0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e66a6-4336-4602-a51a-a38fb6e8d66a",
   "metadata": {},
   "source": [
    "## Check for duplicates across directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7747c62-07c7-4727-ad09-e8574409f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodefiles = get_cell_filepaths(Path(settings_dict['save_dir']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328728b4-e60d-4f75-b2e7-a2ea41bec52b",
   "metadata": {},
   "source": [
    "For each of the previous files,\n",
    "Check against the following directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb4486f7-0574-4699-8032-21b4970826c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for directory /Users/kperks/Library/CloudStorage/GoogleDrive-kperky@gmail.com/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/todo_postsynaptic_mg/glia the following are duplicates with cells in main folder\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>dups</th>\n",
       "      <th>overlap-percent</th>\n",
       "      <th>number_seg_lap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>134138712</td>\n",
       "      <td>219982184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>306492892</td>\n",
       "      <td>305346000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>693.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         self       dups  overlap-percent  number_seg_lap\n",
       "17  134138712  219982184              1.0           891.0\n",
       "22  306492892  305346000              1.0           693.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_list = [\n",
    "    # Path(settings_dict['save_dir']),\n",
    "    # Path(settings_dict['save_dir'])/'todo_presynaptic/lf_393325331',\n",
    "    Path(settings_dict['save_dir'])/ 'todo_postsynaptic_mg/glia'\n",
    "]\n",
    "\n",
    "for d_ in directory_list:\n",
    "    df_all = pd.DataFrame()\n",
    "    crest = ecrest(settings_dict,launch_viewer=False)\n",
    "    base_segments = crest.get_base_segments_dict(d_)# / 'todo_postsynaptic_sg/check-duplicates')\n",
    "\n",
    "\n",
    "    for k,f in nodefiles.items():\n",
    "        cell = ecrest(settings_dict,filepath = f,launch_viewer=False)\n",
    "        df = cell.check_duplicates(base_segments)\n",
    "        if not df.empty:\n",
    "            df_all = pd.concat([df_all,df]) \n",
    "    \n",
    "    if not df_all.empty:\n",
    "        print(f'for directory {d_} the following are duplicates with cells in main folder')\n",
    "        display(df_all[df_all['overlap-percent']==1]) #df_all)#\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d70d2-2efa-4f06-a618-d76a5288e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellf = 'cell_graph_310752287__2023-07-26 19.49.58.json'\n",
    "cell = ecrest(settings_dict,filepath = dirpath/cellf, launch_viewer=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf9e67-0898-4373-9c30-97e794b61fd8",
   "metadata": {},
   "source": [
    "### visualize overlapping segments for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "344b2440-8128-456e-bdb7-4a2ebe31a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)\n",
    "dirpath = Path(settings_dict['save_dir'])\n",
    "                  \n",
    "# First, where is the \"main\" cell?\n",
    "    # This will create a base_segments dictionary of all cells in this main directory\n",
    "cell = ecrest(settings_dict,launch_viewer=False)\n",
    "base_segments =  cell.get_base_segments_dict(dirpath)\n",
    "\n",
    "# base_segments_dup = cell.get_base_segments_dict(Path('/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/todo_presynaptic/needs-cell-type'))# cell.get_base_segments_dict(dirpath / 'todo_postsynaptic_sg/check-duplicates')#'todo_postsynaptic_mg/check-duplicates') #base_segments #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e403e1-6639-4eda-8fb4-fcf7067f2fbd",
   "metadata": {},
   "source": [
    "or use the following for multiple file versions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c10f4a18-3bc8-4615-8fed-21f0f22ff99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_segments = get_base_segments_dict(Path(settings_dict['save_dir']))\n",
    "\n",
    "base_segments_dup = base_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a37ec755-1496-4873-8f08-080cee0912cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodefiles = get_cell_filepaths(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a17a6e58-c7d7-4c80-afdb-b7966823fca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 segments in main that are not in dup\n",
      "20 segments in dup that are not in main\n",
      "17 segments in both\n"
     ]
    }
   ],
   "source": [
    "main = '59015377'\n",
    "dup = '59014144'\n",
    "\t\n",
    "\t\t\n",
    "overlap_segs={}\n",
    "overlap_segs['main']=base_segments[main].difference(base_segments_dup[dup])\n",
    "overlap_segs['dup']=base_segments_dup[dup].difference(base_segments[main])\n",
    "\n",
    "# print(f'{len(overlap_segs[\"main\"])} segments in main on {nodefiles[main].name.split(\"_\")[-1][:-5]} that are not in dup')\n",
    "# print(f'{len(overlap_segs[\"dup\"])} segments in dup on {nodefiles[dup].name.split(\"_\")[-1][:-5]} that are not in main')\n",
    "print(f'{len(overlap_segs[\"main\"])} segments in main that are not in dup')\n",
    "print(f'{len(overlap_segs[\"dup\"])} segments in dup that are not in main')\n",
    "\n",
    "overlap_seg_list = base_segments[main] & base_segments_dup[dup]#base_segments_dup[dup]\n",
    "print(f'{len(overlap_seg_list)} segments in both')\n",
    "\n",
    "# overlap_segs[\"dup\"]\n",
    "# overlap_segs[\"dup\"] = overlap_segs[\"dup\"].difference(set(['642149703']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f03dea1d-5de2-4437-badd-a4e7d32e89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap_segs[\"dup\"] = overlap_segs[\"dup\"]-set(['633873057'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcffa5-71dc-49ae-a5e4-fb540c68f638",
   "metadata": {},
   "source": [
    "### Create viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "74bcac4e-c5f7-4e41-8e0f-44b6d6a4c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = neuroglancer.Viewer()\n",
    "viewer.set_state({})\n",
    "\n",
    "location=[17000,17000,1500]\n",
    "\n",
    "with viewer.config_state.txn() as s:\n",
    "    s.show_layer_panel = True ###\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    dimensions = neuroglancer.CoordinateSpace(\n",
    "        scales=[16, 16, 30],# self.vx_sizes['em'],\n",
    "        units='nm',\n",
    "        names=['x', 'y', 'z']   )\n",
    "    s.showSlices = False\n",
    "    s.dimensions = dimensions\n",
    "    s.position = array(location)\n",
    "    s.layout = \"3d\"\n",
    "    s.projectionScale = 30000\n",
    "    s.projection_background_color= \"#000000\"\n",
    "\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    wb_open(str(viewer))\n",
    "\n",
    "db_cursors = sqlite3_connect(settings_dict['db_path'], check_same_thread=False).cursor()\n",
    "a = ', '.join(['base_address'])\n",
    "db_cursors.execute(f'''SELECT {a} FROM addresses_table LIMIT 1''')\n",
    "[base_seg] = db_cursors.fetchall()[0]\n",
    "two_d_intensity = 0.5\n",
    "\n",
    "for layer_name in ['main','dup','overlap']:\n",
    "    with viewer.txn(overwrite=True) as s:\n",
    "        s.layers[layer_name] = neuroglancer.SegmentationLayer(source = base_seg, segments=[], segment_colors={})\n",
    "        s.layers[layer_name].ignoreNullVisibleSet = False\n",
    "        s.layers[layer_name].pick = False\n",
    "        s.layers[layer_name].selectedAlpha = two_d_intensity #For 2D\n",
    "\n",
    "### load cells and color overlap\n",
    "cell_color={'main':'#33cc33','dup':'#cc33ff'}\n",
    "\n",
    "for k in ['main','dup']:\n",
    "    with viewer.txn(overwrite=True) as s:\n",
    "        color_structure = cell_color[k] # blue\n",
    "        for bs in overlap_segs[k]:\n",
    "            s.layers[k].segments.add(int(bs))\n",
    "            s.layers[k].segment_colors[int(bs)] = color_structure # blue\n",
    "\n",
    "color_structure='#ff0000'\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    for bs in list(overlap_seg_list):\n",
    "        s.layers['overlap'].segments.add(int(bs))\n",
    "        s.layers['overlap'].segment_colors[int(bs)] = color_structure # blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e370599a-b7d2-44b0-94f8-0a3bf9ebb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'brainmaps://10393113184:ell:roi450um_xyz'\n",
    "with viewer.txn(overwrite=True) as s:\n",
    "    s.layers['em'] = neuroglancer.ImageLayer(source = source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063f394-b735-47c3-a747-15fc0683237d",
   "metadata": {},
   "source": [
    "### Load main cell so can add segments from duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "efad9af8-3f2f-4c41-8cd1-979dd5124cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating viewer status message: Current Base Segment Counts: unknown: 46, axon: 0, basal dendrite: 0, apical dendrite: 0, dendrite: 0, multiple: 0\n"
     ]
    }
   ],
   "source": [
    "dirpath = Path(settings_dict['save_dir']) #/ 'todo_postsynaptic_sg/check-duplicates'\n",
    "f_list = [f.name for f in dirpath.glob('*' + main + '*')]#[main]#[f.name for f in dirpath.glob('*' + main + '*')]\n",
    "try: \n",
    "    len(f_list)==1\n",
    "    main_cell = ecrest(settings_dict,filepath= dirpath / f_list[-1], launch_viewer=True)\n",
    "except:\n",
    "    print(f'more than one file for {main}')\n",
    "    print(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "795b55e3-1c40-4054-80ff-5e85a4c38d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cell_graph_283548237__2023-11-28 09.52.49.json'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36929b5e-2d1d-4e96-9d6f-341f5c3e936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_segs['dup']-set(['629540714'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5127cad2-fffa-47cd-acf0-e5f2633eb02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mli'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main_cell.save_cell_graph()\n",
    "main_cell.get_ctype(\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0359ce27-e6cd-417b-b7ac-d6fd97cdb654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 216870958 reconstruction locally at 2023-10-25 13.36.59\n"
     ]
    }
   ],
   "source": [
    "main_cell.save_cell_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d4464-d371-4a6f-a004-79bb8543b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_cell.cell_data['removed_base_segs']=set()\n",
    "main_cell.max_num_base_added=1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6fcf011c-8ff7-4392-81cf-73dc8379dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55569540']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55568519']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55568704', '55568716', '55568731', '55568600']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55568760']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['54423547']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['139150195']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55569859']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['59016850']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['139149816']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['140294479']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['140295522']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['56713335']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55569114']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['139149428']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['56697068']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55569314']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['55569695']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "THIS VERSION OF HOW TO DO THIS IS CURRENTLY WORKING BEST\n",
    "'''\n",
    "anchor_cell = main_cell\n",
    "base_ids_added = set()\n",
    "\n",
    "for base_seg in overlap_segs['dup']-set([]):#overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): #overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): # dup diff main adds segments in dup that were not in main\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != anchor_cell.cell_data['metadata']['main_seg']['base']): \n",
    "        \n",
    "        displayed_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = anchor_cell.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = anchor_cell.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in anchor_cell.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > anchor_cell.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # anchor_cell.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {anchor_cell.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        print(base_ids)\n",
    "        anchor_cell.update_base_locations(base_ids)\n",
    "        anchor_cell.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = anchor_cell.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            anchor_cell.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = anchor_cell.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        anchor_cell.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with anchor_cell.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        anchor_cell.update_displayed_segs() \n",
    "        anchor_cell.assert_segs_in_sync()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d006dce8-79f6-434e-b84b-d7e7750a6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.define_ctype(\"tsd\",\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8ce5997c-edaa-4563-adf2-7fa5c4c4f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 59015377 reconstruction locally at 2024-02-09 11.22.06\n"
     ]
    }
   ],
   "source": [
    "anchor_cell.save_cell_graph(directory_path = dirpath)# , file_name = f_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69e4e184-eb2a-46b7-adce-ad591668180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cell_graph_285761792__2023-10-25 20.53.45.json']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80024b08-c093-45db-ba2e-5a2bfa95701b",
   "metadata": {},
   "source": [
    "### get annotations from duplicate cell into main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "571c1921-3243-4ac5-a070-afa0cfacf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'kp'#/'todo_presynaptic/mg1_299496636' #/ 'todo_postsynaptic_sg/47366615' #\n",
    "filename = 'cell_graph_38099496__2024-01-12 13.27.26.json'#'cell_graph_306242528__2023-06-26 09.26.24.json'\n",
    "\n",
    "crest_ann = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "70ff275f-1947-414b-a903-f1a81ed2219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['exit volume', 'natural end', 'uncertain', 'pre-synaptic', 'post-synaptic', 'soma'])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crest_ann.cell_data['end_points'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d90595e1-2404-4bcf-b02c-9a202c8c41a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['exit volume', 'natural end', 'uncertain', 'pre-synaptic', 'post-synaptic', 'soma'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_cell.cell_data['end_points'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d2b760-b409-48a8-a5f1-1982026b38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.add_endpoint_annotation_layers(['soma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3e9c00a9-14b1-4019-93f2-8258c3ea8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.cell_data['end_points']['uncertain'] = crest_ann.cell_data['end_points']['uncertain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e8b74e90-000e-49df-ba11-cabf20104e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0e148fd6-04b3-4e41-9701-d647295eb55b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SegmentationLayer' object has no attribute 'annotations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4n/x3rls3t16fn723p1tbd7w7fr0000gn/T/ipykernel_1189/1916668960.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0manchor_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrest_ann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0manchor_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_annotation_layer_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ell-connectome/eCREST/eCREST_cli.py\u001b[0m in \u001b[0;36mload_annotation_layer_points\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpoint_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# first, clear any existing in viewer so that points can be deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;31m# If data already exists for this point type:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ell/lib/python3.8/site-packages/neuroglancer/viewer_state.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SegmentationLayer' object has no attribute 'annotations'"
     ]
    }
   ],
   "source": [
    "\n",
    "layer_names = list(crest_ann.cell_data['end_points'].keys())#['natural end','exit volume','pre-synaptic','post-synaptic']\n",
    "\n",
    "for l_ in ['uncertain']:#layer_names:\n",
    "    anchor_cell.cell_data['end_points'][l_] = crest_ann.cell_data['end_points'][l_]\n",
    "\n",
    "    anchor_cell.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "793e2b9b-462c-4a71-b802-52fa7cbe2122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 137787960 reconstruction locally at 2024-01-04 10.27.42\n"
     ]
    }
   ],
   "source": [
    "anchor_cell.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a874946-0275-46e0-aec7-be6ba4271ec5",
   "metadata": {},
   "source": [
    "# Convert From Neuroglancer to eCREST\n",
    "\n",
    "Run the following code cell to convert neuroglancer json files to eCREST json files. \n",
    "\n",
    "Uses \"conversion_specs.json\" to batch process conversion.\n",
    "\n",
    "Conversion using \"conversion_specs.json\" expects:\n",
    "- a folder of neuroglancer json files (with filenames standardized like in Google Drive)\n",
    "- \"dirname\" is the folder containing neuroglancer json files to be converted\n",
    "- that the \"conversion_specs.json\" is in the ```settings_dict['save_dir']``` key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803f3fd-ce8a-4a2d-9ab4-e7f865cd2ff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Just annotations layer\n",
    "\n",
    "If starting from scratch on a reconstruction is faster than converting the base_segs into a graph... but you want the annotations preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10506a09-0cad-409a-978a-a549f762191f",
   "metadata": {},
   "source": [
    "### From another crest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12b495b1-074c-47dc-b6be-c40cf1a1bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir'])\n",
    "\n",
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78159a1e-e284-4abd-b352-01407caef552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating viewer status message: Current Base Segment Counts: unknown: 4071, axon: 0, basal dendrite: 0, apical dendrite: 0, dendrite: 0, multiple: 0\n"
     ]
    }
   ],
   "source": [
    "filepath = nodefiles['221358318']\n",
    "crest = ecrest(settings_dict,filepath= filepath, launch_viewer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8d0d186-da46-4a9c-a3b1-19b4d9e725cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating viewer status message: Current Base Segment Counts: unknown: 807, axon: 125, basal dendrite: 150, apical dendrite: 378, dendrite: 0, multiple: 1\n"
     ]
    }
   ],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'todo_post-synaptic'\n",
    "filename = 'cell_graph_220213102__2023-05-09 15.11.44.json'\n",
    "\n",
    "crest_ = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db7b04f6-63ce-44c4-b13d-eec201f4609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in crest_.cell_data['end_points'].keys():\n",
    "    crest.cell_data['end_points'][layer_name] = crest_.cell_data['end_points'][layer_name]\n",
    "\n",
    "    crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d425593c-5bd4-4975-bc79-0e011aa64429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 221358318 reconstruction locally at 2023-12-19 13.02.53\n"
     ]
    }
   ],
   "source": [
    "# SAVE YOUR WORK!\n",
    "\n",
    "crest.save_cell_graph() # Default location is Path(settings_dict['save_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693dd2c-2554-41be-b2b5-93724e30f53c",
   "metadata": {},
   "source": [
    "### from neuroglancer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4de1e121-a887-45f5-b94d-3ecf761b70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir'])\n",
    "\n",
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "08be2600-dbbe-4f61-b9f8-5631327fe02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating viewer status message: Current Base Segment Counts: unknown: 4054, axon: 34, basal dendrite: 94, apical dendrite: 856, dendrite: 0, multiple: 0\n"
     ]
    }
   ],
   "source": [
    "filepath = nodefiles['301787806']\n",
    "crest = ecrest(settings_dict,filepath= filepath, launch_viewer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e22bf1fc-3b85-44fb-989d-ff792cdea197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported - post-synaptic - layer from neuroglancer annotations tabs for cell 301787806 as - post-synaptic -.\n",
      "Imported - pre-synaptic - layer from neuroglancer annotations tabs for cell 301787806 as - pre-synaptic -.\n"
     ]
    }
   ],
   "source": [
    "neuroglancer_layer_name = ['post-synaptic','pre-synaptic']#,\n",
    "crest_layer_name = ['post-synaptic','pre-synaptic']#,\n",
    "neuroglancer_path = '/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer_synapses/finished'\n",
    "neuroglancer_path = Path(neuroglancer_path) / '301787806_lg_nbs.json'\n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)\n",
    "# for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "    # get the 'layers' dictionary that has that name\n",
    "    neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "\n",
    "    if neuroglancer_layer != None:\n",
    "        if cl_ in crest.point_types:\n",
    "            # add annotation layer\n",
    "            crest.import_annotations(neuroglancer_data, [nl_], [cl_])\n",
    "            print(f\"Imported - {nl_} - layer from neuroglancer annotations tabs for cell {crest.cell_data['metadata']['main_seg']['base']} as - {cl_} -.\")\n",
    "        else: \n",
    "            msg = f\"CREST layer name - {cl_} - incorrect for cell {crest.cell_data['metadata']['main_seg']['base']} in conversion_json\"\n",
    "            print(msg)\n",
    "\n",
    "    else:\n",
    "        msg = f\"no layer by the name - {nl_} - in neuroglancer json for cell {crest.cell_data['metadata']['main_seg']['base']}\"\n",
    "        print(msg)\n",
    "\n",
    "crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b3653ad1-9cf9-456a-b295-1e82f47484bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "base_segment_list_ng = segmentation_layer['segments']\n",
    "\n",
    "base_ids_added = set()\n",
    "\n",
    "anchor_seg = crest.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "segs_to_add = set(base_segment_list_ng).difference(set([a for b in crest.cell_data['base_segments'].values() for a in b]))\n",
    "\n",
    "\n",
    "segs_to_add = [s for s in segs_to_add if '!' not in s]\n",
    "\n",
    "print(len(segs_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "07ebb342-a2bd-4dd5-9509-0fe8a5d542f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['304079999', '304060544', '304060650']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b1bcd50d-00eb-4b3a-a383-1260de498480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving cell /Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer_synapses/finished/301787806_lg_nbs.json with annotations layers imported\n",
      "Saved cell 301787806 reconstruction locally at 2023-09-14 10.50.41\n"
     ]
    }
   ],
   "source": [
    "## Save the cell_data as json\n",
    "print(f'saving cell {neuroglancer_path} with annotations layers imported')\n",
    "crest.save_cell_graph() # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f328ab76-abee-4c55-8604-72b40e04db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['304079999']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['304060544']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n",
      "['304060650']\n",
      "1 clusters of connected components. Connecting these clusters with nearest base segments.\n"
     ]
    }
   ],
   "source": [
    "base_ids_added = set()\n",
    "\n",
    "for base_seg in segs_to_add: #overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]): # dup diff main adds segments in dup that were not in main\n",
    "    \n",
    "    if (base_ids_added&set(base_seg)==set()) & (base_seg != crest.cell_data['metadata']['main_seg']['base']): \n",
    "        \n",
    "        displayed_segs = crest.assert_segs_in_sync(return_segs=True)\n",
    "        if base_seg in displayed_segs:\n",
    "            # print(f'{base_seg} already in cell, continueing')\n",
    "            continue\n",
    "\n",
    "        # print(i,base_seg)\n",
    "        agglo_seg = crest.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "        constituent_base_ids = crest.get_base_segs_of_agglo_seg(agglo_seg)        \n",
    "        current_segs = crest.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "        num_base_segs_this_agglo_seg = len(constituent_base_ids)\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in current_segs]\n",
    "        constituent_base_ids = [x for x in constituent_base_ids if x not in crest.cell_data['removed_base_segs']]\n",
    "        num_base_segs_not_already_included = len(constituent_base_ids)\n",
    "        \n",
    "        if len(constituent_base_ids) > crest.max_num_base_added:\n",
    "            base_ids = [base_seg]\n",
    "            # crest.large_agglo_segs.add(agglo_seg)\n",
    "            print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {crest.max_num_base_added}')\n",
    "            # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "        else:\n",
    "            base_ids = constituent_base_ids\n",
    "\n",
    "        if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "            if not base_seg in base_ids:\n",
    "                base_ids.append(base_seg)\n",
    "        print(base_ids)\n",
    "        crest.update_base_locations(base_ids)\n",
    "        crest.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "        if len(base_ids) > 1:\n",
    "            edges = crest.get_edges_from_agglo_seg(agglo_seg)\n",
    "            edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "            crest.pr_graph.add_edges(edges)\n",
    "\n",
    "        join_msg = crest.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "        # Update lists of base segments and displayed segs:\n",
    "        crest.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "        with crest.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "            for bs in base_ids:\n",
    "                s.layers['base_segs'].segment_colors[int(bs)] = '#d2b48c'\n",
    "                s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "        base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "        crest.update_displayed_segs() \n",
    "        crest.assert_segs_in_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c0940-9886-4c81-b9f9-d75e97b8d2f0",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848ec1f-7cdd-4f7c-93a2-2025c79806ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_specs_filename = \"conversion_specs.json\"\n",
    "\n",
    "with open(Path(settings_dict['save_dir']) / conversion_specs_filename) as f:\n",
    "    conversion_specs = json.load(f)\n",
    "\n",
    "p = Path(conversion_specs['dirname'])\n",
    "\n",
    "for cell_id, info in conversion_specs['cell_info'].items():\n",
    "   \n",
    "    f = info['filename']\n",
    "    neuroglancer_layer_name = info['neuroglancer_layer_name']\n",
    "    crest_layer_name = info['crest_layer_name']\n",
    "  \n",
    "    ## Get main_base_seg_ID from filename or from list of segment IDs\n",
    "    main_base_id = f.split('_')[1] # gets the base segment ID from the name\n",
    "    \n",
    "    try:\n",
    "        assert cell_id == main_base_id, f'cell id and filename do not match in conversion json; moving on to next cell without completing this one'\n",
    "    except AssertionError as msg:\n",
    "        print(msg)\n",
    "        #add error message to json\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "        loaded['cell_info'][cell_id]['errors'].append(str(msg))\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"w\") as f:\n",
    "            json.dump(loaded, f, indent=4)\n",
    "        continue\n",
    "    \n",
    "    ## Load the neuroglancer json\n",
    "    print(f'you have selected cell {cell_id} to convert')\n",
    "    \n",
    "    with open(p / f, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "        neuroglancer_data = json.load(myfile)\n",
    "\n",
    "    print(f'Obtaining base_seg IDs from segmentation layer of neuroglancer json.')\n",
    "\n",
    "    ## Obtain the list of base_segments from the neuroglancer json\n",
    "    segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "    try:\n",
    "        # add annotation layer\n",
    "        \n",
    "        base_segment_list_ng = segmentation_layer['segments']\n",
    "    except TypeError as msg:\n",
    "        print(msg, f': segmentation layer source is different; moving on to next cell without completing this one')\n",
    "        #add error message to json\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"r\") as f:\n",
    "            loaded = json.load(f)\n",
    "        loaded['cell_info'][cell_id]['errors'].append(str(msg) + f': segmentation layer source is different; moving on to next cell without completing this one')\n",
    "        with open(settings_dict['save_dir'] / conversion_specs_filename, \"w\") as f:\n",
    "            json.dump(loaded, f, indent=4)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    print(f'creating a crest_json object with no viewer for this cell')\n",
    "    ## Create CREST instance with no viewer, segment_list, and segment_id\n",
    "    crest = ecrest(settings_dict, segment_id = main_base_id, segment_list = base_segment_list_ng, launch_viewer=False)\n",
    "\n",
    "    print(f'importing annotation layers from neuroglancer')\n",
    "    ## Get annotations from neuroglancer -- iterate through one layer at a time to check for errors in layer names\n",
    "    for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "        # get the 'layers' dictionary that has that name\n",
    "        neuroglancer_layer = next((item for item in neuroglancer_data['layers'] if item[\"name\"] == nl_), None)\n",
    "\n",
    "        if neuroglancer_layer != None:\n",
    "            if cl_ in crest.point_types:\n",
    "                # add annotation layer\n",
    "                crest.import_annotations(neuroglancer_data, [nl_], [cl_])\n",
    "                print(f\"Imported - {nl_} - layer from neuroglancer annotations tabs for cell {crest.cell_data['metadata']['main_seg']['base']} as - {cl_} -.\")\n",
    "            else: \n",
    "                msg = f\"CREST layer name - {cl_} - incorrect for cell {crest.cell_data['metadata']['main_seg']['base']} in conversion_json\"\n",
    "                print(msg)\n",
    "                #add error message to json\n",
    "                with open(crest.save_dir / conversion_specs_filename, \"r\") as f:\n",
    "                    loaded = json.load(f)\n",
    "                loaded['cell_info'][cell_id]['errors'].append(str(msg))\n",
    "                with open(crest.save_dir / conversion_specs_filename, \"w\") as f:\n",
    "                    json.dump(loaded, f, indent=4)\n",
    "        else:\n",
    "            msg = f\"no layer by the name - {nl_} - in neuroglancer json for cell {crest.cell_data['metadata']['main_seg']['base']}\"\n",
    "            print(msg)\n",
    "            #add error message to json\n",
    "            with open(crest.save_dir / conversion_specs_filename, \"r\") as f:\n",
    "                loaded = json.load(f)\n",
    "            loaded['cell_info'][cell_id]['errors'].append(str(msg))\n",
    "            with open(crest.save_dir / conversion_specs_filename, \"w\") as f:\n",
    "                json.dump(loaded, f, indent=4)\n",
    "\n",
    "\n",
    "    ## Save the cell_data as json\n",
    "    print(f'saving cell {cell_id} with completed graph and annotations layers imported')\n",
    "    crest.save_cell_graph() # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471abac-fd9d-4bba-8b86-777a7549c4e0",
   "metadata": {},
   "source": [
    "## Single file\n",
    "\n",
    "Just make the \"conversion_specs\" file have one cell in it. The \"batch\" loop will still run on one cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1910ccc-c196-4053-a537-36bbf9c92a9d",
   "metadata": {},
   "source": [
    "### dictionary of just one annotation layer \n",
    "\n",
    "(the json file would be a list of dicts.... each dict is an annotation point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f7201-5b0f-4370-a95f-73af8bd5a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = json_path / 'tmp' /'annotations.json'\n",
    "\n",
    "with open(annotations_path, 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    annotate_data = json.load(myfile)\n",
    "# for nl_, cl_ in zip(neuroglancer_layer_name, crest_layer_name):\n",
    "\n",
    "# annotate_data\n",
    "annotation_list = []\n",
    "for v in annotate_data:\n",
    "\n",
    "\n",
    "    # for v in neuroglancer_layer['annotations']:\n",
    "    corrected_location = crest.get_corrected_xyz(v['point'], 'seg')\n",
    "\n",
    "    if 'segments' not in v.keys():\n",
    "        annotation_list.extend([corrected_location])\n",
    "    if 'segments' in v.keys():\n",
    "        annotation_list.extend([corrected_location + v['segments'][0]])\n",
    "\n",
    "# self.cell_data['end_points'][c].extend(annotation_list)\n",
    "\n",
    "crest.cell_data['end_points']['post-synaptic'] = annotation_list\n",
    "\n",
    "crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcf80d-58a6-4c55-8141-39429f268315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the cell_data as json\n",
    "print(f'saving cell {neuroglancer_path} with annotations layers imported')\n",
    "crest.save_cell_graph() # If do not give file_path, then it will auto-generate one like CREST produces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501822aa-784f-4db5-9952-30c13eae85c8",
   "metadata": {},
   "source": [
    "## segments from an NG json into an existing CREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639eaef-165b-4feb-a1c4-aac1d028cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = Path(settings_dict['save_dir']) #/ 'todo_post-synaptic'\n",
    "filename = 'cell_graph_476801247__2023-06-04 20.32.28.json'\n",
    "\n",
    "crest = ecrest(settings_dict,filepath= json_path / filename, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cfa38-5007-42c8-8ab2-355347a6dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer_path = '/Users/kperks/Documents/gdrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/Nate_neuroglancer_synapses/finished'\n",
    "neuroglancer_path = Path(neuroglancer_path) / '304356725_nbs.json'\n",
    "\n",
    "with open(Path(neuroglancer_path), 'r') as myfile: # 'p' is the dirpath and 'f' is the filename from the created 'd' dictionary\n",
    "    neuroglancer_data = json.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbfdd0-5f07-45ad-bfdb-96a382c33791",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_layer = next((item for item in neuroglancer_data['layers'] if item[\"source\"] == 'brainmaps://10393113184:ell:roi450um_seg32fb16fb_220930'), None)\n",
    "base_segment_list_ng = segmentation_layer['segments']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd251f07-07bf-4f99-adf7-7fb84e9fbc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ids_added = set()\n",
    "anchor_cell = crest\n",
    "anchor_seg = anchor_cell.cell_data['metadata']['main_seg']['base']\n",
    "\n",
    "segs_to_add = set(base_segment_list_ng).difference(set([a for b in anchor_cell.cell_data['base_segments'].values() for a in b]))\n",
    "print(len(segs_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075aed08-f4f2-450c-92a5-0214313f05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_to_add = set([x for x in list(segs_to_add) if \"!\" not in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6790ac-097b-4b9b-a443-36078a55c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''this might be a version that does not work so well, see visualize overlapping segments section for one that does?'''\n",
    "# for base_seg in segs_to_add:\n",
    "#     # if this segment has not already been added and it is not the anchor seg_ (should not be if not already part of cell)\n",
    "#     if (base_ids_added&set(base_seg)==set()) & (base_seg != anchor_seg): \n",
    "        \n",
    "#         displayed_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "#         if base_seg in displayed_segs:\n",
    "#             # print(f'{base_seg} already in cell, continueing')\n",
    "#             continue\n",
    "\n",
    "#         # print(i,base_seg)\n",
    "#         agglo_seg = anchor_cell.get_agglo_seg_of_base_seg(base_seg)\n",
    "\n",
    "#         constituent_base_ids = anchor_cell.get_base_segs_of_agglo_seg(agglo_seg)\n",
    "#         print(f'{len(constituent_base_ids)} other base segments in the agglo segment; max number can add is {crest.max_num_base_added}')\n",
    "\n",
    "\n",
    "#         if len(constituent_base_ids) > anchor_cell.max_num_base_added:\n",
    "#             base_ids = [base_seg]\n",
    "#             # anchor_cell.large_agglo_segs.add(agglo_seg)\n",
    "#             # print(f'{base_seg} part of an agglo seg {agglo_seg} that is too large to add, so just adding the one segment')\n",
    "#         else:\n",
    "#             base_ids = constituent_base_ids\n",
    "        \n",
    "#         current_segs = anchor_cell.assert_segs_in_sync(return_segs=True)\n",
    "\n",
    "#         num_base_segs_this_agglo_seg = len(base_ids)\n",
    "#         base_ids = [x for x in base_ids if x not in current_segs]\n",
    "#         num_base_segs_not_already_included = len(base_ids)\n",
    "        \n",
    "#         # if there were segments from this agglo seg that were not in current graph, make sure you don't actually want them excluded\n",
    "#         if num_base_segs_this_agglo_seg > num_base_segs_not_already_included:\n",
    "\n",
    "#             base_ids = [x for x in base_ids if x not in anchor_cell.cell_data['removed_base_segs']]\n",
    "\n",
    "#             if not base_seg in base_ids:\n",
    "#                 base_ids.append(base_seg)\n",
    "        \n",
    "#         anchor_cell.update_base_locations(base_ids)\n",
    "#         anchor_cell.pr_graph.add_vertices(base_ids)\n",
    "\n",
    "#         if len(base_ids) > 1:\n",
    "#             edges = anchor_cell.get_edges_from_agglo_seg(agglo_seg)\n",
    "#             edges = [x for x in edges if (x[0] in base_ids and x[1] in base_ids)]\n",
    "#             anchor_cell.pr_graph.add_edges(edges)\n",
    "\n",
    "#         join_msg = anchor_cell.add_closest_edge_to_graph(base_ids, base_seg) \n",
    "        \n",
    "\n",
    "#         # Update lists of base segments and displayed segs:\n",
    "#         anchor_cell.cell_data['base_segments']['unknown'].update(set(base_ids))\n",
    "\n",
    "#         with anchor_cell.viewer.txn(overwrite=True) as s:\n",
    "\n",
    "#             for bs in base_ids:\n",
    "#                 s.layers['base_segs'].segment_colors[int(bs)] = '#ff0000' #'#d2b48c'\n",
    "#                 s.layers['base_segs'].segments.add(int(bs))\n",
    "                \n",
    "#         base_ids_added.update(base_ids)\n",
    "\n",
    "\n",
    "#         anchor_cell.update_displayed_segs() \n",
    "#         anchor_cell.assert_segs_in_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb36244-d283-40ad-ae7a-edc59eab4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc91a44-d0de-46b3-bddd-ede5fa141617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "anchor_cell.save_cell_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "6da77b1d-bdd4-46c6-a87e-00ce33dd9f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grc-s'"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_cell.get_ctype(\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72059f3-b6c2-447c-a016-ae144f39bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cell.define_ctype(\"sg1\",\"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "6864771f-2897-4c0e-a0af-a82713adc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_base_segs = [str(a) for b in main_cell.cell_data['base_segments'].values() for a in b]\n",
    "\n",
    "# self.update_base_locations(all_base_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "3dc79032-23cb-4771-8223-48abc4ff897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_base_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "8f4a0dbb-6fc7-42c7-b730-e8093f04f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_base_segs = list(overlap_segs[\"dup\"].difference(overlap_segs[\"main\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb89e3-04e7-4fe0-9309-f6f4122c3a47",
   "metadata": {},
   "source": [
    "# Base segment locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d4fb1-ab91-4e01-94fc-aa04d52751a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "batch_size=1000\n",
    "base_segs = all_base_segs[0:10]\n",
    "\n",
    "if len(base_segs) > 0:\n",
    "\n",
    "    num_batches = int(len(base_segs)/batch_size)\n",
    "\n",
    "    for batch in range(num_batches+1):\n",
    "\n",
    "        q = ','.join([str(x) for x in base_segs[batch*batch_size:(batch+1)*batch_size]])\n",
    "\n",
    "        # query = f\"\"\"SELECT seg_id, x, y, z FROM base_location WHERE seg_id IN ({q})\"\"\"\n",
    "        QUERY = f\"\"\"\n",
    "        SELECT\n",
    "            cast(objects.id as INT64) as seg_id,\n",
    "            sample_voxel.x as x,\n",
    "            sample_voxel.y as y,\n",
    "            sample_voxel.z as z,\n",
    "        FROM\n",
    "            `lcht-goog-connectomics.ell_roi450um_seg32fb16fb_220930.objinfo` as objects\n",
    "        WHERE objects.id IN ({q})\n",
    "        \"\"\"\n",
    "        main_cell.db_cursors.execute(QUERY)\n",
    "\n",
    "        this_batch = {str(x[0]): (int(x[1]), int(x[2]), int(x[3])) for x in main_cell.db_cursors.fetchall()}\n",
    "\n",
    "        results.update(this_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "0976627e-72af-410f-ba39-9a30df2950be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'302142481,526457094,636529690,634227097,51370565,302158618,623858775,608849235,622727716,384569128'"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "f3f21628-8270-4c8b-99ea-e3db49c2df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = Path(settings_dict['db_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "6a556beb-1a21-49b3-b885-540a8a76f4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/kperks/Documents/ell-connectome/eCREST-local-files/Mariela_bigquery_exports_agglo_v230111c_16_crest_proofreading_database.db')"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "a2b87341-8f45-487a-8ab3-e2c14dfd754f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'bigquery' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4n/x3rls3t16fn723p1tbd7w7fr0000gn/T/ipykernel_1108/1786800133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbigquery_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lcht-goog-connectomics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'bigquery' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client(project='lcht-goog-connectomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "b8f47d02-f5a6-4bfd-8d53-153f9ed53cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "QUERY = f\"\"\"\n",
    "SELECT cast(objects.id as INT64) as seg_id, sample_voxel.x as x, sample_voxel.y as y, sample_voxel.z as z \n",
    "FROM `lcht-goog-connectomics.ell_roi450um_seg32fb16fb_220930.objinfo` as objects \n",
    "WHERE objects.id in '302142481,526457094'\n",
    "\"\"\"\n",
    "\n",
    "# sql = 'SELECT ship1,ship2,ship3,ship4,ship5 FROM SHIPS WHERE playerid = ?'\n",
    "args = (q,)\n",
    "# cursor.execute(sql, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "8d645229-d520-4cf5-b82d-ecb2d796d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"SELECT seg_id, x, y, z FROM base_location WHERE seg_id IN ({q})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "6726f37f-e232-4ca6-b053-bc26a00e4bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT cast(objects.id as INT64) as seg_id, sample_voxel.x as x, sample_voxel.y as y, sample_voxel.z as z \\nFROM `lcht-goog-connectomics.ell_roi450um_seg32fb16fb_220930.objinfo` as objects \\nWHERE objects.id in '302142481,526457094'\\n\""
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "73833888-c9b8-4231-ba4f-8482f9578db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: lcht-goog-connectomics.ell_roi450um_seg32fb16fb_220930.objinfo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4n/x3rls3t16fn723p1tbd7w7fr0000gn/T/ipykernel_1108/399261453.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_cursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: lcht-goog-connectomics.ell_roi450um_seg32fb16fb_220930.objinfo"
     ]
    }
   ],
   "source": [
    "main_cell.db_cursors.execute(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "9f463cd4-9cd7-4590-a22b-9fa0e69cac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(51370565, 28084.5, 19543, 37.5),\n",
       " (302142481, 28477.5, 16966, 1451.5),\n",
       " (302158618, 28946.5, 17039, 1536.5),\n",
       " (384569128, 28175, 15436, 2084.5),\n",
       " (526457094, 25591.5, 4034, 2833),\n",
       " (608849235, 24205.5, 2865, 3186),\n",
       " (622727716, 28100, 8135, 3168.5),\n",
       " (623858775, 27716, 8678.5, 3294.5),\n",
       " (634227097, 29294, 12349.5, 3396.5),\n",
       " (636529690, 29729, 13266.5, 3197)]"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_cell.db_cursors.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ec179-196f-46e6-938b-fb5c47ed3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd894d8c-9b42-4687-b1d4-715e3c1b1a2f",
   "metadata": {},
   "source": [
    "# Create new crest file from the union segment list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefe865-4961-490c-9b6d-6e3a449ad730",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_list = segs_1.union(segs_2)\n",
    "segment_id = crest_1.cell_data['metadata']['main_seg']['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b32bd-891e-4521-8e67-13f6c2c645f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest = ecrest(settings_dict, segment_id = segment_id, segment_list = new_seg_list, launch_viewer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9119a5-b7f9-4635-980b-4a6f6b60ef56",
   "metadata": {},
   "source": [
    "Add annotations from one of the cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5323527-07af-4829-8dd9-daaf7c1af105",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest.cell_data['end_points'] = crest_1.cell_data['end_points']\n",
    "\n",
    "combo_crest.load_annotation_layer_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78281383-0cd2-479e-93d2-451728671c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest.define_ctype('uk','manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621e038-c237-40b9-ad4e-044628557f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_crest.save_cell_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ed1ea-c0da-412e-bd44-c52c7fbf0b4d",
   "metadata": {},
   "source": [
    "#### DONT FORGET TO SAVE YOUR WORK! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21516cc1-aa10-4222-b4a1-c96b30ad4777",
   "metadata": {},
   "source": [
    "# Other..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d1353-a6a3-41d5-87e3-5b0ca0f46bdf",
   "metadata": {},
   "source": [
    "## Add vertex if missing (if can't remove a segment, sometimes this is the reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d6494-401d-4923-b3c8-a3e400a2b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('479295220')\n",
    "crest.cell_data['base_segments']['unknown'].add('565168297')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c334e-4d74-4824-abf9-ff15a438aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.pr_graph.vs.find(\"459940426\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe282d93-d754-4cdf-b3ea-1ba87b4928ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.pr_graph.add_vertex(name='459940426')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7fdb0-af9a-4aa9-815e-0956813b5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "crest.pr_graph.add_edges([(4966,323)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014faae-0438-4798-a635-b57e4af868c6",
   "metadata": {},
   "source": [
    "## define cell type for a crest file\n",
    "\n",
    "resaves as original file name (not with an updated timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "id": "72386a65-eb64-460c-92fe-f1987af2651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = Path(settings_dict['save_dir'])\n",
    "\n",
    "nodefiles = dict()\n",
    "for child in sorted(dirpath.iterdir()):\n",
    "    if (child.name[0]!='.') & (child.is_file()):\n",
    "        nodefiles[child.name.split('_')[2]] = child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "id": "79bf3d7e-decf-4d33-b3b2-abeaffbe473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cell 204450570 reconstruction locally at 2023-08-28 20.46.04\n",
      "Saved cell 291390559 reconstruction locally at 2023-08-28 20.46.04\n"
     ]
    }
   ],
   "source": [
    "cell_id = ['204450570', '291390559']\n",
    "cell_type = 'dml'\n",
    "\n",
    "for c_ in cell_id:\n",
    "\n",
    "    filepath = dirpath / nodefiles[c_]\n",
    "\n",
    "    ### \n",
    "    crest = ecrest(settings_dict, filepath = filepath, launch_viewer=False);\n",
    "    crest.define_ctype(cell_type,'manual')\n",
    "    crest.get_ctype('manual') == cell_type\n",
    "    crest.save_cell_graph(directory_path = filepath.parent, file_name=filepath.name, save_to_cloud=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b412c94-b9e0-44bd-8997-f389f5493ce1",
   "metadata": {},
   "source": [
    "## get cell types of neuroglancer reconstructions into crest json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcf6bc-1654-4043-abfe-8bd81985bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_settings_json = '/Users/kperks/Documents/ell-connectome/eCREST-local-files/settings_dict.json'\n",
    "settings_dict = import_settings(path_to_settings_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb2a8f-c3f6-4234-aa15-2698e9b12ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "crestpath = \"/Volumes/GoogleDrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network\"\n",
    "ngpath = \"/Volumes/GoogleDrive/.shortcut-targets-by-id/16q1BuOMfD2ta0Cwq8CjMlRe4rDvbuWC5/ELL_connectome/CREST_reconstructions/mg-network/files_for_names\"\n",
    "ngfiles = [x.name for x in Path(ngpath).iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac558f6-df50-48c2-8e4d-d800b9488cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctype_list = []\n",
    "has_ctype = set()\n",
    "all_cells = set()\n",
    "\n",
    "for fname in sorted(list(Path(crestpath).iterdir())):\n",
    "    if (fname.name[0]!='.') & (fname.is_file()):\n",
    "        # display(fname.name)\n",
    "        crest = ecrest(settings_dict, filepath = fname, launch_viewer=False);\n",
    "        ngfile = list(filter(lambda x: cell.cell_data['metadata']['main_seg']['base'] in x, ngfiles))\n",
    "        \n",
    "        all_cells = all_cells | set({cell.cell_data['metadata']['main_seg']['base']})\n",
    "        \n",
    "        if len(ngfile)==1:\n",
    "            ctype = ngfile[0].split('_')[3].lower()\n",
    "            has_ctype = has_ctype | set({cell.cell_data['metadata']['main_seg']['base']})\n",
    "        ctype_list.append(ctype)\n",
    "        crest.define_ctype(ctype,'manual');\n",
    "        crest.save_cell_graph(directory_path = fname.parent, file_name=fname.name, save_to_cloud=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc61be-b897-4d59-9115-b6fa609694d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all crest cells have cell type definition from neuroglancer file name\n",
    "all_cells-has_ctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946bdd21-d4e1-4ae2-b80e-fc98faa378cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cell type labels\n",
    "list(unique(ctype_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c60dec-c910-4c18-99f4-a75d908f5dd6",
   "metadata": {},
   "source": [
    "## resave a json file with formatting for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189f733-6892-4e71-875b-bddfcbaa4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path(\"D:\\electric-fish\\eCREST\\CREST_settings.json\")\n",
    "with open(filepath, \"r\") as f:\n",
    "    loaded = json.load(f)\n",
    "\n",
    "with open(filepath, \"w\") as f:\n",
    "    json.dump(loaded, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
